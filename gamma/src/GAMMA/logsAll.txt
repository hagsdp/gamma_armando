1. Using architecture PEs=4, L1=16, L2=128
    1. Model mnasnet with 52 layers: 2.847e+00
    2. Model ncf_m with 12 layers: 2.286e+00
    3. Model mobilenet_v2 with 52 layers: 2.851e+00
    4. Model googlenet with 59 layers: 3.132e+00
    5. Model dlrmRMC1_m with 6 layers: 2.031e+00
    6. Model alexnet with 5 layers: 2.627e+00
    7. Model transformer with 96 layers: 2.106e+00
    8. Model resnet50 with 53 layers: 2.883e+00
    9. Model wide_resnet50 with 53 layers: 2.879e+00
    10. Model manual with 3 layers: 2.519e+00
    11. Model shufflenet_v2 with 56 layers: 2.880e+00
    12. Model squeezenet with 26 layers: 2.859e+00
    13. Model try with 3 layers: 2.686e+00
    14. Model resnet18 with 20 layers: 2.783e+00
    15. Model vgg16 with 13 layers: 2.384e+00
    16. Model densenet with 160 layers: 2.917e+00
    17. Model T5_m with 6 layers: 2.222e+00
    18. Model resnext50_32x4d with 53 layers: 2.903e+00
    19. Model BERT_m with 6 layers: 1.750e+00
    20. Model ALBERT_m with 5 layers: 1.440e+00

Final result with all models and fixed hardware = 2.748180963464141

2. Using architecture PEs=4, L1=16, L2=256
    1. Model mnasnet with 52 layers: 3.258e+00
    2. Model ncf_m with 12 layers: 2.410e+00
    3. Model mobilenet_v2 with 52 layers: 3.227e+00
    4. Model googlenet with 59 layers: 3.386e+00
    5. Model dlrmRMC1_m with 6 layers: 3.025e+00
    6. Model alexnet with 5 layers: 3.190e+00
    7. Model transformer with 96 layers: 2.382e+00
    8. Model resnet50 with 53 layers: 3.307e+00
    9. Model wide_resnet50 with 53 layers: 3.202e+00
    10. Model manual with 3 layers: 3.137e+00
    11. Model shufflenet_v2 with 56 layers: 3.330e+00
    12. Model squeezenet with 26 layers: 3.317e+00
    13. Model try with 3 layers: 3.693e+00
    14. Model resnet18 with 20 layers: 3.444e+00
    15. Model vgg16 with 13 layers: 3.292e+00
    16. Model densenet with 160 layers: 3.245e+00
    17. Model T5_m with 6 layers: 2.660e+00
    18. Model resnext50_32x4d with 53 layers: 3.242e+00
    19. Model BERT_m with 6 layers: 2.583e+00
    20. Model ALBERT_m with 5 layers: 1.492e+00

Final result with all models and fixed hardware = 3.1237466102841673

3. Using architecture PEs=4, L1=16, L2=512
    1. Model mnasnet with 52 layers: 3.501e+00
    2. Model ncf_m with 12 layers: 3.368e+00
    3. Model mobilenet_v2 with 52 layers: 3.291e+00
    4. Model googlenet with 59 layers: 3.455e+00
    5. Model dlrmRMC1_m with 6 layers: 2.972e+00
    6. Model alexnet with 5 layers: 3.264e+00
    7. Model transformer with 96 layers: 2.675e+00
    8. Model resnet50 with 53 layers: 3.427e+00
    9. Model wide_resnet50 with 53 layers: 3.291e+00
    10. Model manual with 3 layers: 3.234e+00
    11. Model shufflenet_v2 with 56 layers: 3.545e+00
    12. Model squeezenet with 26 layers: 3.568e+00
    13. Model try with 3 layers: 3.422e+00
    14. Model resnet18 with 20 layers: 3.730e+00
    15. Model vgg16 with 13 layers: 3.564e+00
    16. Model densenet with 160 layers: 3.389e+00
    17. Model T5_m with 6 layers: 2.848e+00
    18. Model resnext50_32x4d with 53 layers: 3.434e+00
    19. Model BERT_m with 6 layers: 2.892e+00
    20. Model ALBERT_m with 5 layers: 1.819e+00

Final result with all models and fixed hardware = 3.3077183761840323

4. Using architecture PEs=4, L1=16, L2=1024
    1. Model mnasnet with 52 layers: 3.619e+00
    2. Model ncf_m with 12 layers: 3.234e+00
    3. Model mobilenet_v2 with 52 layers: 3.557e+00
    4. Model googlenet with 59 layers: 3.678e+00
    5. Model dlrmRMC1_m with 6 layers: 3.433e+00
    6. Model alexnet with 5 layers: 3.181e+00
    7. Model transformer with 96 layers: 3.133e+00
    8. Model resnet50 with 53 layers: 3.522e+00
    9. Model wide_resnet50 with 53 layers: 3.488e+00
    10. Model manual with 3 layers: 3.866e+00
    11. Model shufflenet_v2 with 56 layers: 3.569e+00
    12. Model squeezenet with 26 layers: 3.782e+00
    13. Model try with 3 layers: 3.061e+00
    14. Model resnet18 with 20 layers: 3.814e+00
    15. Model vgg16 with 13 layers: 3.463e+00
    16. Model densenet with 160 layers: 3.650e+00
    17. Model T5_m with 6 layers: 3.247e+00
    18. Model resnext50_32x4d with 53 layers: 3.475e+00
    19. Model BERT_m with 6 layers: 3.604e+00
    20. Model ALBERT_m with 5 layers: 1.878e+00

Final result with all models and fixed hardware = 3.513963617050068

5. Using architecture PEs=4, L1=16, L2=2048
    1. Model mnasnet with 52 layers: 3.714e+00
    2. Model ncf_m with 12 layers: 3.588e+00
    3. Model mobilenet_v2 with 52 layers: 3.701e+00
    4. Model googlenet with 59 layers: 3.743e+00
    5. Model dlrmRMC1_m with 6 layers: 3.825e+00
    6. Model alexnet with 5 layers: 3.717e+00
    7. Model transformer with 96 layers: 3.651e+00
    8. Model resnet50 with 53 layers: 3.743e+00
    9. Model wide_resnet50 with 53 layers: 3.676e+00
    10. Model manual with 3 layers: 3.894e+00
    11. Model shufflenet_v2 with 56 layers: 3.685e+00
    12. Model squeezenet with 26 layers: 3.719e+00
    13. Model try with 3 layers: 3.629e+00
    14. Model resnet18 with 20 layers: 3.547e+00
    15. Model vgg16 with 13 layers: 3.875e+00
    16. Model densenet with 160 layers: 3.702e+00
    17. Model T5_m with 6 layers: 3.431e+00
    18. Model resnext50_32x4d with 53 layers: 3.520e+00
    19. Model BERT_m with 6 layers: 3.624e+00
    20. Model ALBERT_m with 5 layers: 1.975e+00

Final result with all models and fixed hardware = 3.6707982138024353

6. Using architecture PEs=4, L1=32, L2=128
    1. Model mnasnet with 52 layers: 2.983e+00
    2. Model ncf_m with 12 layers: 2.395e+00
    3. Model mobilenet_v2 with 52 layers: 2.970e+00
    4. Model googlenet with 59 layers: 3.027e+00
    5. Model dlrmRMC1_m with 6 layers: 2.018e+00
    6. Model alexnet with 5 layers: 3.038e+00
    7. Model transformer with 96 layers: 2.085e+00
    8. Model resnet50 with 53 layers: 2.999e+00
    9. Model wide_resnet50 with 53 layers: 3.053e+00
    10. Model manual with 3 layers: 2.440e+00
    11. Model shufflenet_v2 with 56 layers: 2.946e+00
    12. Model squeezenet with 26 layers: 2.855e+00
    13. Model try with 3 layers: 2.870e+00
    14. Model resnet18 with 20 layers: 2.872e+00
    15. Model vgg16 with 13 layers: 2.878e+00
    16. Model densenet with 160 layers: 2.935e+00
    17. Model T5_m with 6 layers: 2.200e+00
    18. Model resnext50_32x4d with 53 layers: 2.819e+00
    19. Model BERT_m with 6 layers: 2.000e+00
    20. Model ALBERT_m with 5 layers: 1.440e+00

Final result with all models and fixed hardware = 2.7961766847090663

7. Using architecture PEs=4, L1=32, L2=256
    1. Model mnasnet with 52 layers: 3.372e+00
    2. Model ncf_m with 12 layers: 2.202e+00
    3. Model mobilenet_v2 with 52 layers: 3.312e+00
    4. Model googlenet with 59 layers: 3.367e+00
    5. Model dlrmRMC1_m with 6 layers: 2.872e+00
    6. Model alexnet with 5 layers: 3.206e+00
    7. Model transformer with 96 layers: 2.498e+00
    8. Model resnet50 with 53 layers: 3.114e+00
    9. Model wide_resnet50 with 53 layers: 3.239e+00
    10. Model manual with 3 layers: 2.954e+00
    11. Model shufflenet_v2 with 56 layers: 3.282e+00
    12. Model squeezenet with 26 layers: 3.313e+00
    13. Model try with 3 layers: 3.214e+00
    14. Model resnet18 with 20 layers: 3.231e+00
    15. Model vgg16 with 13 layers: 2.950e+00
    16. Model densenet with 160 layers: 3.225e+00
    17. Model T5_m with 6 layers: 2.644e+00
    18. Model resnext50_32x4d with 53 layers: 3.284e+00
    19. Model BERT_m with 6 layers: 2.228e+00
    20. Model ALBERT_m with 5 layers: 1.613e+00

Final result with all models and fixed hardware = 3.1138428673883625

8. Using architecture PEs=4, L1=32, L2=512
    1. Model mnasnet with 52 layers: 3.552e+00
    2. Model ncf_m with 12 layers: 3.080e+00
    3. Model mobilenet_v2 with 52 layers: 3.412e+00
    4. Model googlenet with 59 layers: 3.551e+00
    5. Model dlrmRMC1_m with 6 layers: 3.504e+00
    6. Model alexnet with 5 layers: 3.500e+00
    7. Model transformer with 96 layers: 2.829e+00
    8. Model resnet50 with 53 layers: 3.420e+00
    9. Model wide_resnet50 with 53 layers: 3.392e+00
    10. Model manual with 3 layers: 3.150e+00
    11. Model shufflenet_v2 with 56 layers: 3.503e+00
    12. Model squeezenet with 26 layers: 3.581e+00
    13. Model try with 3 layers: 3.293e+00
    14. Model resnet18 with 20 layers: 3.452e+00
    15. Model vgg16 with 13 layers: 3.523e+00
    16. Model densenet with 160 layers: 3.369e+00
    17. Model T5_m with 6 layers: 2.717e+00
    18. Model resnext50_32x4d with 53 layers: 3.319e+00
    19. Model BERT_m with 6 layers: 2.941e+00
    20. Model ALBERT_m with 5 layers: 1.673e+00

Final result with all models and fixed hardware = 3.329525686062246

9. Using architecture PEs=4, L1=32, L2=1024
    1. Model mnasnet with 52 layers: 3.625e+00
    2. Model ncf_m with 12 layers: 3.354e+00
    3. Model mobilenet_v2 with 52 layers: 3.647e+00
    4. Model googlenet with 59 layers: 3.652e+00
    5. Model dlrmRMC1_m with 6 layers: 3.036e+00
    6. Model alexnet with 5 layers: 3.557e+00
    7. Model transformer with 96 layers: 3.346e+00
    8. Model resnet50 with 53 layers: 3.650e+00
    9. Model wide_resnet50 with 53 layers: 3.561e+00
    10. Model manual with 3 layers: 3.241e+00
    11. Model shufflenet_v2 with 56 layers: 3.662e+00
    12. Model squeezenet with 26 layers: 3.750e+00
    13. Model try with 3 layers: 3.675e+00
    14. Model resnet18 with 20 layers: 3.524e+00
    15. Model vgg16 with 13 layers: 3.701e+00
    16. Model densenet with 160 layers: 3.547e+00
    17. Model T5_m with 6 layers: 3.225e+00
    18. Model resnext50_32x4d with 53 layers: 3.671e+00
    19. Model BERT_m with 6 layers: 3.163e+00
    20. Model ALBERT_m with 5 layers: 1.792e+00

Final result with all models and fixed hardware = 3.5515559797023

10. Using architecture PEs=4, L1=32, L2=2048
    1. Model mnasnet with 52 layers: 3.701e+00
    2. Model ncf_m with 12 layers: 3.537e+00
    3. Model mobilenet_v2 with 52 layers: 3.648e+00
    4. Model googlenet with 59 layers: 3.935e+00
    5. Model dlrmRMC1_m with 6 layers: 3.550e+00
    6. Model alexnet with 5 layers: 3.752e+00
    7. Model transformer with 96 layers: 3.578e+00
    8. Model resnet50 with 53 layers: 3.698e+00
    9. Model wide_resnet50 with 53 layers: 3.505e+00
    10. Model manual with 3 layers: 3.910e+00
    11. Model shufflenet_v2 with 56 layers: 3.670e+00
    12. Model squeezenet with 26 layers: 3.773e+00
    13. Model try with 3 layers: 3.377e+00
    14. Model resnet18 with 20 layers: 3.739e+00
    15. Model vgg16 with 13 layers: 3.884e+00
    16. Model densenet with 160 layers: 3.697e+00
    17. Model T5_m with 6 layers: 3.795e+00
    18. Model resnext50_32x4d with 53 layers: 3.642e+00
    19. Model BERT_m with 6 layers: 3.942e+00
    20. Model ALBERT_m with 5 layers: 1.975e+00

Final result with all models and fixed hardware = 3.672132572395128

11. Using architecture PEs=4, L1=64, L2=128
    1. Model mnasnet with 52 layers: 2.972e+00
    2. Model ncf_m with 12 layers: 2.549e+00
    3. Model mobilenet_v2 with 52 layers: 2.863e+00
    4. Model googlenet with 59 layers: 2.954e+00
    5. Model dlrmRMC1_m with 6 layers: 2.718e+00
    6. Model alexnet with 5 layers: 2.404e+00
    7. Model transformer with 96 layers: 2.128e+00
    8. Model resnet50 with 53 layers: 2.928e+00
    9. Model wide_resnet50 with 53 layers: 2.710e+00
    10. Model manual with 3 layers: 2.891e+00
    11. Model shufflenet_v2 with 56 layers: 3.118e+00
    12. Model squeezenet with 26 layers: 2.940e+00
    13. Model try with 3 layers: 3.020e+00
    14. Model resnet18 with 20 layers: 2.816e+00
    15. Model vgg16 with 13 layers: 2.906e+00
    16. Model densenet with 160 layers: 2.955e+00
    17. Model T5_m with 6 layers: 2.000e+00
    18. Model resnext50_32x4d with 53 layers: 2.846e+00
    19. Model BERT_m with 6 layers: 2.000e+00
    20. Model ALBERT_m with 5 layers: 1.200e+00

Final result with all models and fixed hardware = 2.7823813152909342

12. Using architecture PEs=4, L1=64, L2=256
    1. Model mnasnet with 52 layers: 3.200e+00
    2. Model ncf_m with 12 layers: 2.434e+00
    3. Model mobilenet_v2 with 52 layers: 3.354e+00
    4. Model googlenet with 59 layers: 3.270e+00
    5. Model dlrmRMC1_m with 6 layers: 2.578e+00
    6. Model alexnet with 5 layers: 3.050e+00
    7. Model transformer with 96 layers: 2.487e+00
    8. Model resnet50 with 53 layers: 3.164e+00
    9. Model wide_resnet50 with 53 layers: 3.122e+00
    10. Model manual with 3 layers: 2.538e+00
    11. Model shufflenet_v2 with 56 layers: 3.286e+00
    12. Model squeezenet with 26 layers: 3.352e+00
    13. Model try with 3 layers: 3.402e+00
    14. Model resnet18 with 20 layers: 3.243e+00
    15. Model vgg16 with 13 layers: 3.042e+00
    16. Model densenet with 160 layers: 3.215e+00
    17. Model T5_m with 6 layers: 2.000e+00
    18. Model resnext50_32x4d with 53 layers: 3.185e+00
    19. Model BERT_m with 6 layers: 2.518e+00
    20. Model ALBERT_m with 5 layers: 2.044e+00

Final result with all models and fixed hardware = 3.084562410013532

13. Using architecture PEs=4, L1=64, L2=512
    1. Model mnasnet with 52 layers: 3.552e+00
    2. Model ncf_m with 12 layers: 2.911e+00
    3. Model mobilenet_v2 with 52 layers: 3.495e+00
    4. Model googlenet with 59 layers: 3.601e+00
    5. Model dlrmRMC1_m with 6 layers: 3.134e+00
    6. Model alexnet with 5 layers: 2.991e+00
    7. Model transformer with 96 layers: 2.797e+00
    8. Model resnet50 with 53 layers: 3.405e+00
    9. Model wide_resnet50 with 53 layers: 3.452e+00
    10. Model manual with 3 layers: 3.969e+00
    11. Model shufflenet_v2 with 56 layers: 3.489e+00
    12. Model squeezenet with 26 layers: 3.660e+00
    13. Model try with 3 layers: 3.397e+00
    14. Model resnet18 with 20 layers: 3.496e+00
    15. Model vgg16 with 13 layers: 3.573e+00
    16. Model densenet with 160 layers: 3.423e+00
    17. Model T5_m with 6 layers: 2.600e+00
    18. Model resnext50_32x4d with 53 layers: 3.394e+00
    19. Model BERT_m with 6 layers: 2.597e+00
    20. Model ALBERT_m with 5 layers: 2.279e+00

Final result with all models and fixed hardware = 3.3540932625169146

14. Using architecture PEs=4, L1=64, L2=1024
    1. Model mnasnet with 52 layers: 3.569e+00
    2. Model ncf_m with 12 layers: 3.315e+00
    3. Model mobilenet_v2 with 52 layers: 3.513e+00
    4. Model googlenet with 59 layers: 3.610e+00
    5. Model dlrmRMC1_m with 6 layers: 3.473e+00
    6. Model alexnet with 5 layers: 3.780e+00
    7. Model transformer with 96 layers: 3.174e+00
    8. Model resnet50 with 53 layers: 3.655e+00
    9. Model wide_resnet50 with 53 layers: 3.585e+00
    10. Model manual with 3 layers: 3.904e+00
    11. Model shufflenet_v2 with 56 layers: 3.638e+00
    12. Model squeezenet with 26 layers: 3.530e+00
    13. Model try with 3 layers: 3.632e+00
    14. Model resnet18 with 20 layers: 3.695e+00
    15. Model vgg16 with 13 layers: 3.825e+00
    16. Model densenet with 160 layers: 3.562e+00
    17. Model T5_m with 6 layers: 3.266e+00
    18. Model resnext50_32x4d with 53 layers: 3.526e+00
    19. Model BERT_m with 6 layers: 3.179e+00
    20. Model ALBERT_m with 5 layers: 1.974e+00

Final result with all models and fixed hardware = 3.513091709066306

15. Using architecture PEs=4, L1=64, L2=2048
    1. Model mnasnet with 52 layers: 3.707e+00
    2. Model ncf_m with 12 layers: 3.537e+00
    3. Model mobilenet_v2 with 52 layers: 3.636e+00
    4. Model googlenet with 59 layers: 3.712e+00
    5. Model dlrmRMC1_m with 6 layers: 3.736e+00
    6. Model alexnet with 5 layers: 3.731e+00
    7. Model transformer with 96 layers: 3.549e+00
    8. Model resnet50 with 53 layers: 3.630e+00
    9. Model wide_resnet50 with 53 layers: 3.648e+00
    10. Model manual with 3 layers: 3.606e+00
    11. Model shufflenet_v2 with 56 layers: 3.687e+00
    12. Model squeezenet with 26 layers: 3.821e+00
    13. Model try with 3 layers: 3.900e+00
    14. Model resnet18 with 20 layers: 3.685e+00
    15. Model vgg16 with 13 layers: 3.869e+00
    16. Model densenet with 160 layers: 3.753e+00
    17. Model T5_m with 6 layers: 3.248e+00
    18. Model resnext50_32x4d with 53 layers: 3.671e+00
    19. Model BERT_m with 6 layers: 3.286e+00
    20. Model ALBERT_m with 5 layers: 1.975e+00

Final result with all models and fixed hardware = 3.6635036576454665

16. Using architecture PEs=4, L1=128, L2=128
    1. Model mnasnet with 52 layers: 3.009e+00
    2. Model ncf_m with 12 layers: 2.243e+00
    3. Model mobilenet_v2 with 52 layers: 2.859e+00
    4. Model googlenet with 59 layers: 3.007e+00
    5. Model dlrmRMC1_m with 6 layers: 2.651e+00
    6. Model alexnet with 5 layers: 2.773e+00
    7. Model transformer with 96 layers: 2.118e+00
    8. Model resnet50 with 53 layers: 2.820e+00
    9. Model wide_resnet50 with 53 layers: 2.768e+00
    10. Model manual with 3 layers: 2.654e+00
    11. Model shufflenet_v2 with 56 layers: 2.962e+00
    12. Model squeezenet with 26 layers: 3.018e+00
    13. Model try with 3 layers: 2.507e+00
    14. Model resnet18 with 20 layers: 2.986e+00
    15. Model vgg16 with 13 layers: 2.581e+00
    16. Model densenet with 160 layers: 2.997e+00
    17. Model T5_m with 6 layers: 2.100e+00
    18. Model resnext50_32x4d with 53 layers: 2.966e+00
    19. Model BERT_m with 6 layers: 2.688e+00
    20. Model ALBERT_m with 5 layers: 1.200e+00

Final result with all models and fixed hardware = 2.792113447902571

17. Using architecture PEs=4, L1=128, L2=256
    1. Model mnasnet with 52 layers: 3.180e+00
    2. Model ncf_m with 12 layers: 2.494e+00
    3. Model mobilenet_v2 with 52 layers: 3.217e+00
    4. Model googlenet with 59 layers: 3.206e+00
    5. Model dlrmRMC1_m with 6 layers: 2.727e+00
    6. Model alexnet with 5 layers: 3.581e+00
    7. Model transformer with 96 layers: 2.396e+00
    8. Model resnet50 with 53 layers: 3.156e+00
    9. Model wide_resnet50 with 53 layers: 3.310e+00
    10. Model manual with 3 layers: 3.573e+00
    11. Model shufflenet_v2 with 56 layers: 3.285e+00
    12. Model squeezenet with 26 layers: 3.509e+00
    13. Model try with 3 layers: 3.115e+00
    14. Model resnet18 with 20 layers: 3.266e+00
    15. Model vgg16 with 13 layers: 3.260e+00
    16. Model densenet with 160 layers: 3.364e+00
    17. Model T5_m with 6 layers: 2.824e+00
    18. Model resnext50_32x4d with 53 layers: 3.234e+00
    19. Model BERT_m with 6 layers: 2.575e+00
    20. Model ALBERT_m with 5 layers: 1.198e+00

Final result with all models and fixed hardware = 3.1254907753721244

18. Using architecture PEs=4, L1=128, L2=512
    1. Model mnasnet with 52 layers: 3.488e+00
    2. Model ncf_m with 12 layers: 2.827e+00
    3. Model mobilenet_v2 with 52 layers: 3.333e+00
    4. Model googlenet with 59 layers: 3.483e+00
    5. Model dlrmRMC1_m with 6 layers: 3.038e+00
    6. Model alexnet with 5 layers: 3.163e+00
    7. Model transformer with 96 layers: 2.866e+00
    8. Model resnet50 with 53 layers: 3.390e+00
    9. Model wide_resnet50 with 53 layers: 3.403e+00
    10. Model manual with 3 layers: 3.831e+00
    11. Model shufflenet_v2 with 56 layers: 3.486e+00
    12. Model squeezenet with 26 layers: 3.684e+00
    13. Model try with 3 layers: 2.803e+00
    14. Model resnet18 with 20 layers: 3.576e+00
    15. Model vgg16 with 13 layers: 3.588e+00
    16. Model densenet with 160 layers: 3.430e+00
    17. Model T5_m with 6 layers: 3.144e+00
    18. Model resnext50_32x4d with 53 layers: 3.392e+00
    19. Model BERT_m with 6 layers: 3.060e+00
    20. Model ALBERT_m with 5 layers: 2.281e+00

Final result with all models and fixed hardware = 3.341814985115021

19. Using architecture PEs=4, L1=128, L2=1024
    1. Model mnasnet with 52 layers: 3.554e+00
    2. Model ncf_m with 12 layers: 3.381e+00
    3. Model mobilenet_v2 with 52 layers: 3.714e+00
    4. Model googlenet with 59 layers: 3.749e+00
    5. Model dlrmRMC1_m with 6 layers: 3.385e+00
    6. Model alexnet with 5 layers: 3.003e+00
    7. Model transformer with 96 layers: 3.237e+00
    8. Model resnet50 with 53 layers: 3.563e+00
    9. Model wide_resnet50 with 53 layers: 3.544e+00
    10. Model manual with 3 layers: 3.662e+00
    11. Model shufflenet_v2 with 56 layers: 3.631e+00
    12. Model squeezenet with 26 layers: 3.701e+00
    13. Model try with 3 layers: 3.870e+00
    14. Model resnet18 with 20 layers: 3.497e+00
    15. Model vgg16 with 13 layers: 3.730e+00
    16. Model densenet with 160 layers: 3.589e+00
    17. Model T5_m with 6 layers: 3.588e+00
    18. Model resnext50_32x4d with 53 layers: 3.608e+00
    19. Model BERT_m with 6 layers: 3.276e+00
    20. Model ALBERT_m with 5 layers: 1.938e+00

Final result with all models and fixed hardware = 3.544493599458728

20. Using architecture PEs=4, L1=128, L2=2048
    1. Model mnasnet with 52 layers: 3.773e+00
    2. Model ncf_m with 12 layers: 3.551e+00
    3. Model mobilenet_v2 with 52 layers: 3.680e+00
    4. Model googlenet with 59 layers: 3.794e+00
    5. Model dlrmRMC1_m with 6 layers: 3.737e+00
    6. Model alexnet with 5 layers: 3.920e+00
    7. Model transformer with 96 layers: 3.506e+00
    8. Model resnet50 with 53 layers: 3.754e+00
    9. Model wide_resnet50 with 53 layers: 3.791e+00
    10. Model manual with 3 layers: 3.868e+00
    11. Model shufflenet_v2 with 56 layers: 3.715e+00
    12. Model squeezenet with 26 layers: 3.867e+00
    13. Model try with 3 layers: 3.888e+00
    14. Model resnet18 with 20 layers: 3.872e+00
    15. Model vgg16 with 13 layers: 3.812e+00
    16. Model densenet with 160 layers: 3.665e+00
    17. Model T5_m with 6 layers: 3.873e+00
    18. Model resnext50_32x4d with 53 layers: 3.788e+00
    19. Model BERT_m with 6 layers: 3.721e+00
    20. Model ALBERT_m with 5 layers: 2.359e+00

Final result with all models and fixed hardware = 3.702122219215156

21. Using architecture PEs=8, L1=16, L2=128
    1. Model mnasnet with 52 layers: 4.824e+00
    2. Model ncf_m with 12 layers: 4.142e+00
    3. Model mobilenet_v2 with 52 layers: 4.921e+00
    4. Model googlenet with 59 layers: 4.940e+00
    5. Model dlrmRMC1_m with 6 layers: 4.182e+00
    6. Model alexnet with 5 layers: 5.156e+00
    7. Model transformer with 96 layers: 4.024e+00
    8. Model resnet50 with 53 layers: 4.528e+00
    9. Model wide_resnet50 with 53 layers: 4.721e+00
    10. Model manual with 3 layers: 4.800e+00
    11. Model shufflenet_v2 with 56 layers: 4.901e+00
    12. Model squeezenet with 26 layers: 4.906e+00
    13. Model try with 3 layers: 4.533e+00
    14. Model resnet18 with 20 layers: 4.790e+00
    15. Model vgg16 with 13 layers: 4.222e+00
    16. Model densenet with 160 layers: 4.908e+00
    17. Model T5_m with 6 layers: 3.494e+00
    18. Model resnext50_32x4d with 53 layers: 4.689e+00
    19. Model BERT_m with 6 layers: 4.000e+00
    20. Model ALBERT_m with 5 layers: 2.585e+00

Final result with all models and fixed hardware = 4.665300516914749

22. Using architecture PEs=8, L1=16, L2=256
    1. Model mnasnet with 52 layers: 5.772e+00
    2. Model ncf_m with 12 layers: 4.822e+00
    3. Model mobilenet_v2 with 52 layers: 5.649e+00
    4. Model googlenet with 59 layers: 6.192e+00
    5. Model dlrmRMC1_m with 6 layers: 4.727e+00
    6. Model alexnet with 5 layers: 5.548e+00
    7. Model transformer with 96 layers: 3.936e+00
    8. Model resnet50 with 53 layers: 5.859e+00
    9. Model wide_resnet50 with 53 layers: 5.298e+00
    10. Model manual with 3 layers: 4.635e+00
    11. Model shufflenet_v2 with 56 layers: 5.146e+00
    12. Model squeezenet with 26 layers: 5.854e+00
    13. Model try with 3 layers: 5.962e+00
    14. Model resnet18 with 20 layers: 5.497e+00
    15. Model vgg16 with 13 layers: 5.154e+00
    16. Model densenet with 160 layers: 5.620e+00
    17. Model T5_m with 6 layers: 2.914e+00
    18. Model resnext50_32x4d with 53 layers: 5.716e+00
    19. Model BERT_m with 6 layers: 4.331e+00
    20. Model ALBERT_m with 5 layers: 3.022e+00

Final result with all models and fixed hardware = 5.348025981055479

23. Using architecture PEs=8, L1=16, L2=512
    1. Model mnasnet with 52 layers: 5.886e+00
    2. Model ncf_m with 12 layers: 5.207e+00
    3. Model mobilenet_v2 with 52 layers: 6.273e+00
    4. Model googlenet with 59 layers: 6.429e+00
    5. Model dlrmRMC1_m with 6 layers: 4.049e+00
    6. Model alexnet with 5 layers: 5.858e+00
    7. Model transformer with 96 layers: 5.054e+00
    8. Model resnet50 with 53 layers: 6.358e+00
    9. Model wide_resnet50 with 53 layers: 5.829e+00
    10. Model manual with 3 layers: 7.022e+00
    11. Model shufflenet_v2 with 56 layers: 6.267e+00
    12. Model squeezenet with 26 layers: 6.483e+00
    13. Model try with 3 layers: 6.337e+00
    14. Model resnet18 with 20 layers: 5.910e+00
    15. Model vgg16 with 13 layers: 5.973e+00
    16. Model densenet with 160 layers: 6.091e+00
    17. Model T5_m with 6 layers: 4.180e+00
    18. Model resnext50_32x4d with 53 layers: 5.948e+00
    19. Model BERT_m with 6 layers: 4.768e+00
    20. Model ALBERT_m with 5 layers: 3.496e+00

Final result with all models and fixed hardware = 5.920331860622463

24. Using architecture PEs=8, L1=16, L2=1024
    1. Model mnasnet with 52 layers: 6.494e+00
    2. Model ncf_m with 12 layers: 5.871e+00
    3. Model mobilenet_v2 with 52 layers: 6.808e+00
    4. Model googlenet with 59 layers: 6.649e+00
    5. Model dlrmRMC1_m with 6 layers: 6.751e+00
    6. Model alexnet with 5 layers: 6.147e+00
    7. Model transformer with 96 layers: 6.053e+00
    8. Model resnet50 with 53 layers: 6.785e+00
    9. Model wide_resnet50 with 53 layers: 6.420e+00
    10. Model manual with 3 layers: 5.829e+00
    11. Model shufflenet_v2 with 56 layers: 6.519e+00
    12. Model squeezenet with 26 layers: 6.980e+00
    13. Model try with 3 layers: 6.179e+00
    14. Model resnet18 with 20 layers: 6.810e+00
    15. Model vgg16 with 13 layers: 6.742e+00
    16. Model densenet with 160 layers: 6.597e+00
    17. Model T5_m with 6 layers: 5.556e+00
    18. Model resnext50_32x4d with 53 layers: 6.338e+00
    19. Model BERT_m with 6 layers: 5.266e+00
    20. Model ALBERT_m with 5 layers: 3.154e+00

Final result with all models and fixed hardware = 6.475183369418131

25. Using architecture PEs=8, L1=16, L2=2048
    1. Model mnasnet with 52 layers: 6.991e+00
    2. Model ncf_m with 12 layers: 5.890e+00
    3. Model mobilenet_v2 with 52 layers: 6.840e+00
    4. Model googlenet with 59 layers: 6.808e+00
    5. Model dlrmRMC1_m with 6 layers: 7.232e+00
    6. Model alexnet with 5 layers: 7.153e+00
    7. Model transformer with 96 layers: 6.357e+00
    8. Model resnet50 with 53 layers: 6.734e+00
    9. Model wide_resnet50 with 53 layers: 6.728e+00
    10. Model manual with 3 layers: 7.684e+00
    11. Model shufflenet_v2 with 56 layers: 6.815e+00
    12. Model squeezenet with 26 layers: 7.100e+00
    13. Model try with 3 layers: 6.869e+00
    14. Model resnet18 with 20 layers: 6.820e+00
    15. Model vgg16 with 13 layers: 6.996e+00
    16. Model densenet with 160 layers: 6.860e+00
    17. Model T5_m with 6 layers: 4.552e+00
    18. Model resnext50_32x4d with 53 layers: 6.957e+00
    19. Model BERT_m with 6 layers: 6.553e+00
    20. Model ALBERT_m with 5 layers: 4.605e+00

Final result with all models and fixed hardware = 6.749184248985115

26. Using architecture PEs=8, L1=32, L2=128
    1. Model mnasnet with 52 layers: 4.741e+00
    2. Model ncf_m with 12 layers: 3.785e+00
    3. Model mobilenet_v2 with 52 layers: 4.747e+00
    4. Model googlenet with 59 layers: 4.915e+00
    5. Model dlrmRMC1_m with 6 layers: 4.336e+00
    6. Model alexnet with 5 layers: 5.240e+00
    7. Model transformer with 96 layers: 3.961e+00
    8. Model resnet50 with 53 layers: 4.718e+00
    9. Model wide_resnet50 with 53 layers: 4.564e+00
    10. Model manual with 3 layers: 4.444e+00
    11. Model shufflenet_v2 with 56 layers: 4.738e+00
    12. Model squeezenet with 26 layers: 4.647e+00
    13. Model try with 3 layers: 4.363e+00
    14. Model resnet18 with 20 layers: 4.847e+00
    15. Model vgg16 with 13 layers: 4.459e+00
    16. Model densenet with 160 layers: 4.917e+00
    17. Model T5_m with 6 layers: 4.000e+00
    18. Model resnext50_32x4d with 53 layers: 4.495e+00
    19. Model BERT_m with 6 layers: 3.417e+00
    20. Model ALBERT_m with 5 layers: 2.725e+00

Final result with all models and fixed hardware = 4.605831694181326

27. Using architecture PEs=8, L1=32, L2=256
    1. Model mnasnet with 52 layers: 5.246e+00
    2. Model ncf_m with 12 layers: 4.542e+00
    3. Model mobilenet_v2 with 52 layers: 5.725e+00
    4. Model googlenet with 59 layers: 5.809e+00
    5. Model dlrmRMC1_m with 6 layers: 4.759e+00
    6. Model alexnet with 5 layers: 5.529e+00
    7. Model transformer with 96 layers: 4.384e+00
    8. Model resnet50 with 53 layers: 5.307e+00
    9. Model wide_resnet50 with 53 layers: 5.471e+00
    10. Model manual with 3 layers: 4.800e+00
    11. Model shufflenet_v2 with 56 layers: 5.533e+00
    12. Model squeezenet with 26 layers: 6.098e+00
    13. Model try with 3 layers: 5.657e+00
    14. Model resnet18 with 20 layers: 5.770e+00
    15. Model vgg16 with 13 layers: 5.377e+00
    16. Model densenet with 160 layers: 5.762e+00
    17. Model T5_m with 6 layers: 3.417e+00
    18. Model resnext50_32x4d with 53 layers: 5.590e+00
    19. Model BERT_m with 6 layers: 5.184e+00
    20. Model ALBERT_m with 5 layers: 2.927e+00

Final result with all models and fixed hardware = 5.393030932341

28. Using architecture PEs=8, L1=32, L2=512
    1. Model mnasnet with 52 layers: 6.416e+00
    2. Model ncf_m with 12 layers: 5.933e+00
    3. Model mobilenet_v2 with 52 layers: 6.235e+00
    4. Model googlenet with 59 layers: 6.451e+00
    5. Model dlrmRMC1_m with 6 layers: 4.680e+00
    6. Model alexnet with 5 layers: 6.639e+00
    7. Model transformer with 96 layers: 5.119e+00
    8. Model resnet50 with 53 layers: 5.862e+00
    9. Model wide_resnet50 with 53 layers: 6.128e+00
    10. Model manual with 3 layers: 7.424e+00
    11. Model shufflenet_v2 with 56 layers: 6.083e+00
    12. Model squeezenet with 26 layers: 6.375e+00
    13. Model try with 3 layers: 4.844e+00
    14. Model resnet18 with 20 layers: 6.376e+00
    15. Model vgg16 with 13 layers: 5.992e+00
    16. Model densenet with 160 layers: 6.416e+00
    17. Model T5_m with 6 layers: 5.665e+00
    18. Model resnext50_32x4d with 53 layers: 6.360e+00
    19. Model BERT_m with 6 layers: 4.551e+00
    20. Model ALBERT_m with 5 layers: 3.871e+00

Final result with all models and fixed hardware = 6.076724752368063

29. Using architecture PEs=8, L1=32, L2=1024
    1. Model mnasnet with 52 layers: 6.707e+00
    2. Model ncf_m with 12 layers: 5.979e+00
    3. Model mobilenet_v2 with 52 layers: 6.769e+00
    4. Model googlenet with 59 layers: 6.666e+00
    5. Model dlrmRMC1_m with 6 layers: 5.517e+00
    6. Model alexnet with 5 layers: 6.109e+00
    7. Model transformer with 96 layers: 5.729e+00
    8. Model resnet50 with 53 layers: 6.691e+00
    9. Model wide_resnet50 with 53 layers: 6.590e+00
    10. Model manual with 3 layers: 7.455e+00
    11. Model shufflenet_v2 with 56 layers: 6.391e+00
    12. Model squeezenet with 26 layers: 6.563e+00
    13. Model try with 3 layers: 6.302e+00
    14. Model resnet18 with 20 layers: 6.866e+00
    15. Model vgg16 with 13 layers: 6.213e+00
    16. Model densenet with 160 layers: 6.713e+00
    17. Model T5_m with 6 layers: 4.026e+00
    18. Model resnext50_32x4d with 53 layers: 6.692e+00
    19. Model BERT_m with 6 layers: 6.131e+00
    20. Model ALBERT_m with 5 layers: 3.869e+00

Final result with all models and fixed hardware = 6.468584152909336

30. Using architecture PEs=8, L1=32, L2=2048
    1. Model mnasnet with 52 layers: 7.080e+00
    2. Model ncf_m with 12 layers: 6.186e+00
    3. Model mobilenet_v2 with 52 layers: 7.045e+00
    4. Model googlenet with 59 layers: 6.928e+00
    5. Model dlrmRMC1_m with 6 layers: 6.676e+00
    6. Model alexnet with 5 layers: 7.100e+00
    7. Model transformer with 96 layers: 6.175e+00
    8. Model resnet50 with 53 layers: 6.892e+00
    9. Model wide_resnet50 with 53 layers: 6.971e+00
    10. Model manual with 3 layers: 6.407e+00
    11. Model shufflenet_v2 with 56 layers: 6.974e+00
    12. Model squeezenet with 26 layers: 7.082e+00
    13. Model try with 3 layers: 5.782e+00
    14. Model resnet18 with 20 layers: 7.311e+00
    15. Model vgg16 with 13 layers: 6.538e+00
    16. Model densenet with 160 layers: 6.894e+00
    17. Model T5_m with 6 layers: 6.478e+00
    18. Model resnext50_32x4d with 53 layers: 6.793e+00
    19. Model BERT_m with 6 layers: 6.517e+00
    20. Model ALBERT_m with 5 layers: 3.946e+00

Final result with all models and fixed hardware = 6.798139824086604

31. Using architecture PEs=8, L1=64, L2=128
    1. Model mnasnet with 52 layers: 4.607e+00
    2. Model ncf_m with 12 layers: 3.444e+00
    3. Model mobilenet_v2 with 52 layers: 4.640e+00
    4. Model googlenet with 59 layers: 4.930e+00
    5. Model dlrmRMC1_m with 6 layers: 4.197e+00
    6. Model alexnet with 5 layers: 4.799e+00
    7. Model transformer with 96 layers: 3.922e+00
    8. Model resnet50 with 53 layers: 4.740e+00
    9. Model wide_resnet50 with 53 layers: 4.489e+00
    10. Model manual with 3 layers: 4.635e+00
    11. Model shufflenet_v2 with 56 layers: 4.497e+00
    12. Model squeezenet with 26 layers: 5.022e+00
    13. Model try with 3 layers: 4.363e+00
    14. Model resnet18 with 20 layers: 5.124e+00
    15. Model vgg16 with 13 layers: 4.139e+00
    16. Model densenet with 160 layers: 4.807e+00
    17. Model T5_m with 6 layers: 3.888e+00
    18. Model resnext50_32x4d with 53 layers: 4.855e+00
    19. Model BERT_m with 6 layers: 4.443e+00
    20. Model ALBERT_m with 5 layers: 2.400e+00

Final result with all models and fixed hardware = 4.576519468200271

32. Using architecture PEs=8, L1=64, L2=256
    1. Model mnasnet with 52 layers: 5.631e+00
    2. Model ncf_m with 12 layers: 4.260e+00
    3. Model mobilenet_v2 with 52 layers: 5.669e+00
    4. Model googlenet with 59 layers: 6.036e+00
    5. Model dlrmRMC1_m with 6 layers: 4.812e+00
    6. Model alexnet with 5 layers: 5.951e+00
    7. Model transformer with 96 layers: 4.401e+00
    8. Model resnet50 with 53 layers: 5.486e+00
    9. Model wide_resnet50 with 53 layers: 5.614e+00
    10. Model manual with 3 layers: 6.320e+00
    11. Model shufflenet_v2 with 56 layers: 5.743e+00
    12. Model squeezenet with 26 layers: 5.886e+00
    13. Model try with 3 layers: 4.315e+00
    14. Model resnet18 with 20 layers: 5.994e+00
    15. Model vgg16 with 13 layers: 5.032e+00
    16. Model densenet with 160 layers: 5.830e+00
    17. Model T5_m with 6 layers: 4.393e+00
    18. Model resnext50_32x4d with 53 layers: 5.940e+00
    19. Model BERT_m with 6 layers: 4.308e+00
    20. Model ALBERT_m with 5 layers: 2.791e+00

Final result with all models and fixed hardware = 5.507418169147496

33. Using architecture PEs=8, L1=64, L2=512
    1. Model mnasnet with 52 layers: 6.379e+00
    2. Model ncf_m with 12 layers: 5.121e+00
    3. Model mobilenet_v2 with 52 layers: 6.378e+00
    4. Model googlenet with 59 layers: 6.410e+00
    5. Model dlrmRMC1_m with 6 layers: 5.408e+00
    6. Model alexnet with 5 layers: 6.906e+00
    7. Model transformer with 96 layers: 5.035e+00
    8. Model resnet50 with 53 layers: 5.884e+00
    9. Model wide_resnet50 with 53 layers: 6.133e+00
    10. Model manual with 3 layers: 6.112e+00
    11. Model shufflenet_v2 with 56 layers: 6.395e+00
    12. Model squeezenet with 26 layers: 6.491e+00
    13. Model try with 3 layers: 6.185e+00
    14. Model resnet18 with 20 layers: 6.091e+00
    15. Model vgg16 with 13 layers: 6.326e+00
    16. Model densenet with 160 layers: 6.365e+00
    17. Model T5_m with 6 layers: 5.225e+00
    18. Model resnext50_32x4d with 53 layers: 6.335e+00
    19. Model BERT_m with 6 layers: 4.638e+00
    20. Model ALBERT_m with 5 layers: 2.418e+00

Final result with all models and fixed hardware = 6.0669668403247625

34. Using architecture PEs=8, L1=64, L2=1024
    1. Model mnasnet with 52 layers: 6.665e+00
    2. Model ncf_m with 12 layers: 5.827e+00
    3. Model mobilenet_v2 with 52 layers: 6.389e+00
    4. Model googlenet with 59 layers: 6.488e+00
    5. Model dlrmRMC1_m with 6 layers: 5.411e+00
    6. Model alexnet with 5 layers: 6.769e+00
    7. Model transformer with 96 layers: 5.398e+00
    8. Model resnet50 with 53 layers: 6.850e+00
    9. Model wide_resnet50 with 53 layers: 6.603e+00
    10. Model manual with 3 layers: 7.303e+00
    11. Model shufflenet_v2 with 56 layers: 6.832e+00
    12. Model squeezenet with 26 layers: 6.831e+00
    13. Model try with 3 layers: 5.858e+00
    14. Model resnet18 with 20 layers: 7.243e+00
    15. Model vgg16 with 13 layers: 6.531e+00
    16. Model densenet with 160 layers: 6.718e+00
    17. Model T5_m with 6 layers: 5.919e+00
    18. Model resnext50_32x4d with 53 layers: 6.569e+00
    19. Model BERT_m with 6 layers: 6.629e+00
    20. Model ALBERT_m with 5 layers: 3.169e+00

Final result with all models and fixed hardware = 6.458365263870095

35. Using architecture PEs=8, L1=64, L2=2048
    1. Model mnasnet with 52 layers: 6.567e+00
    2. Model ncf_m with 12 layers: 5.596e+00
    3. Model mobilenet_v2 with 52 layers: 6.931e+00
    4. Model googlenet with 59 layers: 7.000e+00
    5. Model dlrmRMC1_m with 6 layers: 7.298e+00
    6. Model alexnet with 5 layers: 7.116e+00
    7. Model transformer with 96 layers: 6.163e+00
    8. Model resnet50 with 53 layers: 7.029e+00
    9. Model wide_resnet50 with 53 layers: 6.933e+00
    10. Model manual with 3 layers: 7.569e+00
    11. Model shufflenet_v2 with 56 layers: 6.763e+00
    12. Model squeezenet with 26 layers: 7.300e+00
    13. Model try with 3 layers: 6.706e+00
    14. Model resnet18 with 20 layers: 7.317e+00
    15. Model vgg16 with 13 layers: 7.576e+00
    16. Model densenet with 160 layers: 6.921e+00
    17. Model T5_m with 6 layers: 7.353e+00
    18. Model resnext50_32x4d with 53 layers: 6.866e+00
    19. Model BERT_m with 6 layers: 7.493e+00
    20. Model ALBERT_m with 5 layers: 3.356e+00

Final result with all models and fixed hardware = 6.801509023004061

36. Using architecture PEs=8, L1=128, L2=128
    1. Model mnasnet with 52 layers: 4.720e+00
    2. Model ncf_m with 12 layers: 3.749e+00
    3. Model mobilenet_v2 with 52 layers: 4.724e+00
    4. Model googlenet with 59 layers: 5.022e+00
    5. Model dlrmRMC1_m with 6 layers: 3.360e+00
    6. Model alexnet with 5 layers: 5.844e+00
    7. Model transformer with 96 layers: 4.065e+00
    8. Model resnet50 with 53 layers: 4.687e+00
    9. Model wide_resnet50 with 53 layers: 4.501e+00
    10. Model manual with 3 layers: 4.049e+00
    11. Model shufflenet_v2 with 56 layers: 4.690e+00
    12. Model squeezenet with 26 layers: 4.632e+00
    13. Model try with 3 layers: 4.100e+00
    14. Model resnet18 with 20 layers: 4.613e+00
    15. Model vgg16 with 13 layers: 4.698e+00
    16. Model densenet with 160 layers: 4.923e+00
    17. Model T5_m with 6 layers: 4.000e+00
    18. Model resnext50_32x4d with 53 layers: 4.711e+00
    19. Model BERT_m with 6 layers: 4.222e+00
    20. Model ALBERT_m with 5 layers: 2.400e+00

Final result with all models and fixed hardware = 4.625707554803789

37. Using architecture PEs=8, L1=128, L2=256
    1. Model mnasnet with 52 layers: 5.610e+00
    2. Model ncf_m with 12 layers: 4.346e+00
    3. Model mobilenet_v2 with 52 layers: 5.734e+00
    4. Model googlenet with 59 layers: 5.765e+00
    5. Model dlrmRMC1_m with 6 layers: 5.309e+00
    6. Model alexnet with 5 layers: 6.479e+00
    7. Model transformer with 96 layers: 4.268e+00
    8. Model resnet50 with 53 layers: 5.429e+00
    9. Model wide_resnet50 with 53 layers: 5.196e+00
    10. Model manual with 3 layers: 5.115e+00
    11. Model shufflenet_v2 with 56 layers: 5.364e+00
    12. Model squeezenet with 26 layers: 5.900e+00
    13. Model try with 3 layers: 5.929e+00
    14. Model resnet18 with 20 layers: 6.228e+00
    15. Model vgg16 with 13 layers: 5.319e+00
    16. Model densenet with 160 layers: 5.760e+00
    17. Model T5_m with 6 layers: 4.429e+00
    18. Model resnext50_32x4d with 53 layers: 5.296e+00
    19. Model BERT_m with 6 layers: 4.570e+00
    20. Model ALBERT_m with 5 layers: 2.720e+00

Final result with all models and fixed hardware = 5.37182195669824

38. Using architecture PEs=8, L1=128, L2=512
    1. Model mnasnet with 52 layers: 6.514e+00
    2. Model ncf_m with 12 layers: 5.214e+00
    3. Model mobilenet_v2 with 52 layers: 6.295e+00
    4. Model googlenet with 59 layers: 6.656e+00
    5. Model dlrmRMC1_m with 6 layers: 6.085e+00
    6. Model alexnet with 5 layers: 6.281e+00
    7. Model transformer with 96 layers: 5.100e+00
    8. Model resnet50 with 53 layers: 6.307e+00
    9. Model wide_resnet50 with 53 layers: 5.916e+00
    10. Model manual with 3 layers: 6.402e+00
    11. Model shufflenet_v2 with 56 layers: 5.978e+00
    12. Model squeezenet with 26 layers: 6.613e+00
    13. Model try with 3 layers: 5.833e+00
    14. Model resnet18 with 20 layers: 6.064e+00
    15. Model vgg16 with 13 layers: 5.809e+00
    16. Model densenet with 160 layers: 6.478e+00
    17. Model T5_m with 6 layers: 5.224e+00
    18. Model resnext50_32x4d with 53 layers: 6.337e+00
    19. Model BERT_m with 6 layers: 5.144e+00
    20. Model ALBERT_m with 5 layers: 2.791e+00

Final result with all models and fixed hardware = 6.1101693058186735

39. Using architecture PEs=8, L1=128, L2=1024
    1. Model mnasnet with 52 layers: 6.928e+00
    2. Model ncf_m with 12 layers: 5.684e+00
    3. Model mobilenet_v2 with 52 layers: 7.030e+00
    4. Model googlenet with 59 layers: 6.674e+00
    5. Model dlrmRMC1_m with 6 layers: 6.981e+00
    6. Model alexnet with 5 layers: 5.973e+00
    7. Model transformer with 96 layers: 5.653e+00
    8. Model resnet50 with 53 layers: 6.718e+00
    9. Model wide_resnet50 with 53 layers: 6.697e+00
    10. Model manual with 3 layers: 7.476e+00
    11. Model shufflenet_v2 with 56 layers: 6.679e+00
    12. Model squeezenet with 26 layers: 7.194e+00
    13. Model try with 3 layers: 5.512e+00
    14. Model resnet18 with 20 layers: 6.795e+00
    15. Model vgg16 with 13 layers: 6.044e+00
    16. Model densenet with 160 layers: 6.760e+00
    17. Model T5_m with 6 layers: 5.271e+00
    18. Model resnext50_32x4d with 53 layers: 6.469e+00
    19. Model BERT_m with 6 layers: 6.194e+00
    20. Model ALBERT_m with 5 layers: 3.163e+00

Final result with all models and fixed hardware = 6.544960439783491

40. Using architecture PEs=8, L1=128, L2=2048
    1. Model mnasnet with 52 layers: 6.965e+00
    2. Model ncf_m with 12 layers: 6.741e+00
    3. Model mobilenet_v2 with 52 layers: 7.029e+00
    4. Model googlenet with 59 layers: 6.941e+00
    5. Model dlrmRMC1_m with 6 layers: 6.186e+00
    6. Model alexnet with 5 layers: 6.430e+00
    7. Model transformer with 96 layers: 6.493e+00
    8. Model resnet50 with 53 layers: 6.903e+00
    9. Model wide_resnet50 with 53 layers: 6.678e+00
    10. Model manual with 3 layers: 7.738e+00
    11. Model shufflenet_v2 with 56 layers: 7.031e+00
    12. Model squeezenet with 26 layers: 6.988e+00
    13. Model try with 3 layers: 5.466e+00
    14. Model resnet18 with 20 layers: 7.409e+00
    15. Model vgg16 with 13 layers: 6.992e+00
    16. Model densenet with 160 layers: 7.149e+00
    17. Model T5_m with 6 layers: 6.208e+00
    18. Model resnext50_32x4d with 53 layers: 7.063e+00
    19. Model BERT_m with 6 layers: 7.215e+00
    20. Model ALBERT_m with 5 layers: 3.275e+00

Final result with all models and fixed hardware = 6.900778213802435

41. Using architecture PEs=16, L1=16, L2=128
    1. Model mnasnet with 52 layers: 7.810e+00
    2. Model ncf_m with 12 layers: 7.456e+00
    3. Model mobilenet_v2 with 52 layers: 7.763e+00
    4. Model googlenet with 59 layers: 7.833e+00
    5. Model dlrmRMC1_m with 6 layers: 7.729e+00
    6. Model alexnet with 5 layers: 6.712e+00
    7. Model transformer with 96 layers: 7.699e+00
    8. Model resnet50 with 53 layers: 7.861e+00
    9. Model wide_resnet50 with 53 layers: 7.823e+00
    10. Model manual with 3 layers: 6.667e+00
    11. Model shufflenet_v2 with 56 layers: 7.383e+00
    12. Model squeezenet with 26 layers: 8.189e+00
    13. Model try with 3 layers: 7.999e+00
    14. Model resnet18 with 20 layers: 8.163e+00
    15. Model vgg16 with 13 layers: 8.060e+00
    16. Model densenet with 160 layers: 8.097e+00
    17. Model T5_m with 6 layers: 8.000e+00
    18. Model resnext50_32x4d with 53 layers: 7.852e+00
    19. Model BERT_m with 6 layers: 8.000e+00
    20. Model ALBERT_m with 5 layers: 8.000e+00

Final result with all models and fixed hardware = 7.845453416779431

42. Using architecture PEs=16, L1=16, L2=256
    1. Model mnasnet with 52 layers: 8.893e+00
    2. Model ncf_m with 12 layers: 7.821e+00
    3. Model mobilenet_v2 with 52 layers: 9.299e+00
    4. Model googlenet with 59 layers: 8.987e+00
    5. Model dlrmRMC1_m with 6 layers: 7.520e+00
    6. Model alexnet with 5 layers: 8.812e+00
    7. Model transformer with 96 layers: 8.016e+00
    8. Model resnet50 with 53 layers: 9.760e+00
    9. Model wide_resnet50 with 53 layers: 8.690e+00
    10. Model manual with 3 layers: 1.228e+01
    11. Model shufflenet_v2 with 56 layers: 8.588e+00
    12. Model squeezenet with 26 layers: 9.903e+00
    13. Model try with 3 layers: 9.528e+00
    14. Model resnet18 with 20 layers: 8.608e+00
    15. Model vgg16 with 13 layers: 8.883e+00
    16. Model densenet with 160 layers: 9.603e+00
    17. Model T5_m with 6 layers: 9.025e+00
    18. Model resnext50_32x4d with 53 layers: 8.764e+00
    19. Model BERT_m with 6 layers: 8.505e+00
    20. Model ALBERT_m with 5 layers: 7.884e+00

Final result with all models and fixed hardware = 8.989975690121783

43. Using architecture PEs=16, L1=16, L2=512
    1. Model mnasnet with 52 layers: 1.101e+01
    2. Model ncf_m with 12 layers: 8.444e+00
    3. Model mobilenet_v2 with 52 layers: 1.117e+01
    4. Model googlenet with 59 layers: 1.170e+01
    5. Model dlrmRMC1_m with 6 layers: 1.078e+01
    6. Model alexnet with 5 layers: 1.176e+01
    7. Model transformer with 96 layers: 8.816e+00
    8. Model resnet50 with 53 layers: 1.029e+01
    9. Model wide_resnet50 with 53 layers: 1.087e+01
    10. Model manual with 3 layers: 1.321e+01
    11. Model shufflenet_v2 with 56 layers: 1.113e+01
    12. Model squeezenet with 26 layers: 1.056e+01
    13. Model try with 3 layers: 1.026e+01
    14. Model resnet18 with 20 layers: 1.013e+01
    15. Model vgg16 with 13 layers: 1.123e+01
    16. Model densenet with 160 layers: 1.131e+01
    17. Model T5_m with 6 layers: 8.444e+00
    18. Model resnext50_32x4d with 53 layers: 1.081e+01
    19. Model BERT_m with 6 layers: 9.863e+00
    20. Model ALBERT_m with 5 layers: 8.714e+00

Final result with all models and fixed hardware = 10.675649772665764

44. Using architecture PEs=16, L1=16, L2=1024
    1. Model mnasnet with 52 layers: 1.125e+01
    2. Model ncf_m with 12 layers: 9.328e+00
    3. Model mobilenet_v2 with 52 layers: 1.189e+01
    4. Model googlenet with 59 layers: 1.235e+01
    5. Model dlrmRMC1_m with 6 layers: 8.325e+00
    6. Model alexnet with 5 layers: 1.204e+01
    7. Model transformer with 96 layers: 1.031e+01
    8. Model resnet50 with 53 layers: 1.185e+01
    9. Model wide_resnet50 with 53 layers: 1.231e+01
    10. Model manual with 3 layers: 1.360e+01
    11. Model shufflenet_v2 with 56 layers: 1.146e+01
    12. Model squeezenet with 26 layers: 1.240e+01
    13. Model try with 3 layers: 1.269e+01
    14. Model resnet18 with 20 layers: 1.246e+01
    15. Model vgg16 with 13 layers: 1.125e+01
    16. Model densenet with 160 layers: 1.216e+01
    17. Model T5_m with 6 layers: 1.064e+01
    18. Model resnext50_32x4d with 53 layers: 1.141e+01
    19. Model BERT_m with 6 layers: 1.108e+01
    20. Model ALBERT_m with 5 layers: 8.332e+00

Final result with all models and fixed hardware = 11.616522407307171

45. Using architecture PEs=16, L1=16, L2=2048
    1. Model mnasnet with 52 layers: 1.275e+01
    2. Model ncf_m with 12 layers: 1.127e+01
    3. Model mobilenet_v2 with 52 layers: 1.304e+01
    4. Model googlenet with 59 layers: 1.328e+01
    5. Model dlrmRMC1_m with 6 layers: 8.571e+00
    6. Model alexnet with 5 layers: 1.442e+01
    7. Model transformer with 96 layers: 1.131e+01
    8. Model resnet50 with 53 layers: 1.294e+01
    9. Model wide_resnet50 with 53 layers: 1.282e+01
    10. Model manual with 3 layers: 1.336e+01
    11. Model shufflenet_v2 with 56 layers: 1.201e+01
    12. Model squeezenet with 26 layers: 1.416e+01
    13. Model try with 3 layers: 1.072e+01
    14. Model resnet18 with 20 layers: 1.291e+01
    15. Model vgg16 with 13 layers: 1.268e+01
    16. Model densenet with 160 layers: 1.300e+01
    17. Model T5_m with 6 layers: 1.370e+01
    18. Model resnext50_32x4d with 53 layers: 1.252e+01
    19. Model BERT_m with 6 layers: 1.242e+01
    20. Model ALBERT_m with 5 layers: 1.255e+01

Final result with all models and fixed hardware = 12.631005322056835

46. Using architecture PEs=16, L1=32, L2=128
    1. Model mnasnet with 52 layers: 7.915e+00
    2. Model ncf_m with 12 layers: 7.065e+00
    3. Model mobilenet_v2 with 52 layers: 7.818e+00
    4. Model googlenet with 59 layers: 8.007e+00
    5. Model dlrmRMC1_m with 6 layers: 7.986e+00
    6. Model alexnet with 5 layers: 7.755e+00
    7. Model transformer with 96 layers: 8.039e+00
    8. Model resnet50 with 53 layers: 7.773e+00
    9. Model wide_resnet50 with 53 layers: 7.592e+00
    10. Model manual with 3 layers: 7.667e+00
    11. Model shufflenet_v2 with 56 layers: 7.815e+00
    12. Model squeezenet with 26 layers: 7.751e+00
    13. Model try with 3 layers: 7.666e+00
    14. Model resnet18 with 20 layers: 6.941e+00
    15. Model vgg16 with 13 layers: 7.859e+00
    16. Model densenet with 160 layers: 7.724e+00
    17. Model T5_m with 6 layers: 7.524e+00
    18. Model resnext50_32x4d with 53 layers: 7.613e+00
    19. Model BERT_m with 6 layers: 6.833e+00
    20. Model ALBERT_m with 5 layers: 8.000e+00

Final result with all models and fixed hardware = 7.766804872801083

47. Using architecture PEs=16, L1=32, L2=256
    1. Model mnasnet with 52 layers: 9.449e+00
    2. Model ncf_m with 12 layers: 8.121e+00
    3. Model mobilenet_v2 with 52 layers: 8.836e+00
    4. Model googlenet with 59 layers: 9.807e+00
    5. Model dlrmRMC1_m with 6 layers: 8.063e+00
    6. Model alexnet with 5 layers: 1.049e+01
    7. Model transformer with 96 layers: 7.809e+00
    8. Model resnet50 with 53 layers: 9.541e+00
    9. Model wide_resnet50 with 53 layers: 9.053e+00
    10. Model manual with 3 layers: 7.667e+00
    11. Model shufflenet_v2 with 56 layers: 9.180e+00
    12. Model squeezenet with 26 layers: 8.873e+00
    13. Model try with 3 layers: 9.954e+00
    14. Model resnet18 with 20 layers: 9.183e+00
    15. Model vgg16 with 13 layers: 8.563e+00
    16. Model densenet with 160 layers: 9.544e+00
    17. Model T5_m with 6 layers: 9.108e+00
    18. Model resnext50_32x4d with 53 layers: 8.995e+00
    19. Model BERT_m with 6 layers: 7.268e+00
    20. Model ALBERT_m with 5 layers: 9.085e+00

Final result with all models and fixed hardware = 9.070358694181326

48. Using architecture PEs=16, L1=32, L2=512
    1. Model mnasnet with 52 layers: 1.090e+01
    2. Model ncf_m with 12 layers: 8.257e+00
    3. Model mobilenet_v2 with 52 layers: 1.092e+01
    4. Model googlenet with 59 layers: 1.102e+01
    5. Model dlrmRMC1_m with 6 layers: 9.077e+00
    6. Model alexnet with 5 layers: 1.068e+01
    7. Model transformer with 96 layers: 8.800e+00
    8. Model resnet50 with 53 layers: 1.136e+01
    9. Model wide_resnet50 with 53 layers: 1.130e+01
    10. Model manual with 3 layers: 1.137e+01
    11. Model shufflenet_v2 with 56 layers: 1.086e+01
    12. Model squeezenet with 26 layers: 1.163e+01
    13. Model try with 3 layers: 8.055e+00
    14. Model resnet18 with 20 layers: 1.193e+01
    15. Model vgg16 with 13 layers: 1.068e+01
    16. Model densenet with 160 layers: 1.122e+01
    17. Model T5_m with 6 layers: 9.037e+00
    18. Model resnext50_32x4d with 53 layers: 1.111e+01
    19. Model BERT_m with 6 layers: 9.187e+00
    20. Model ALBERT_m with 5 layers: 9.444e+00

Final result with all models and fixed hardware = 10.722824860622465

49. Using architecture PEs=16, L1=32, L2=1024
    1. Model mnasnet with 52 layers: 1.215e+01
    2. Model ncf_m with 12 layers: 1.134e+01
    3. Model mobilenet_v2 with 52 layers: 1.222e+01
    4. Model googlenet with 59 layers: 1.178e+01
    5. Model dlrmRMC1_m with 6 layers: 9.305e+00
    6. Model alexnet with 5 layers: 1.034e+01
    7. Model transformer with 96 layers: 9.726e+00
    8. Model resnet50 with 53 layers: 1.223e+01
    9. Model wide_resnet50 with 53 layers: 1.177e+01
    10. Model manual with 3 layers: 1.201e+01
    11. Model shufflenet_v2 with 56 layers: 1.184e+01
    12. Model squeezenet with 26 layers: 1.297e+01
    13. Model try with 3 layers: 1.155e+01
    14. Model resnet18 with 20 layers: 1.193e+01
    15. Model vgg16 with 13 layers: 1.088e+01
    16. Model densenet with 160 layers: 1.217e+01
    17. Model T5_m with 6 layers: 1.187e+01
    18. Model resnext50_32x4d with 53 layers: 1.242e+01
    19. Model BERT_m with 6 layers: 9.696e+00
    20. Model ALBERT_m with 5 layers: 9.305e+00

Final result with all models and fixed hardware = 11.697608703653588

50. Using architecture PEs=16, L1=32, L2=2048
    1. Model mnasnet with 52 layers: 1.278e+01
    2. Model ncf_m with 12 layers: 1.116e+01
    3. Model mobilenet_v2 with 52 layers: 1.305e+01
    4. Model googlenet with 59 layers: 1.295e+01
    5. Model dlrmRMC1_m with 6 layers: 1.194e+01
    6. Model alexnet with 5 layers: 1.313e+01
    7. Model transformer with 96 layers: 1.174e+01
    8. Model resnet50 with 53 layers: 1.271e+01
    9. Model wide_resnet50 with 53 layers: 1.304e+01
    10. Model manual with 3 layers: 1.211e+01
    11. Model shufflenet_v2 with 56 layers: 1.265e+01
    12. Model squeezenet with 26 layers: 1.284e+01
    13. Model try with 3 layers: 1.033e+01
    14. Model resnet18 with 20 layers: 1.261e+01
    15. Model vgg16 with 13 layers: 1.404e+01
    16. Model densenet with 160 layers: 1.251e+01
    17. Model T5_m with 6 layers: 1.247e+01
    18. Model resnext50_32x4d with 53 layers: 1.260e+01
    19. Model BERT_m with 6 layers: 1.079e+01
    20. Model ALBERT_m with 5 layers: 1.074e+01

Final result with all models and fixed hardware = 12.553997968876862

51. Using architecture PEs=16, L1=64, L2=128
    1. Model mnasnet with 52 layers: 7.664e+00
    2. Model ncf_m with 12 layers: 7.039e+00
    3. Model mobilenet_v2 with 52 layers: 8.162e+00
    4. Model googlenet with 59 layers: 7.865e+00
    5. Model dlrmRMC1_m with 6 layers: 7.848e+00
    6. Model alexnet with 5 layers: 7.720e+00
    7. Model transformer with 96 layers: 7.535e+00
    8. Model resnet50 with 53 layers: 7.799e+00
    9. Model wide_resnet50 with 53 layers: 7.902e+00
    10. Model manual with 3 layers: 5.833e+00
    11. Model shufflenet_v2 with 56 layers: 7.692e+00
    12. Model squeezenet with 26 layers: 8.270e+00
    13. Model try with 3 layers: 7.999e+00
    14. Model resnet18 with 20 layers: 7.383e+00
    15. Model vgg16 with 13 layers: 7.846e+00
    16. Model densenet with 160 layers: 7.917e+00
    17. Model T5_m with 6 layers: 5.776e+00
    18. Model resnext50_32x4d with 53 layers: 7.908e+00
    19. Model BERT_m with 6 layers: 6.833e+00
    20. Model ALBERT_m with 5 layers: 8.000e+00

Final result with all models and fixed hardware = 7.782396420838974

52. Using architecture PEs=16, L1=64, L2=256
    1. Model mnasnet with 52 layers: 9.054e+00
    2. Model ncf_m with 12 layers: 7.990e+00
    3. Model mobilenet_v2 with 52 layers: 9.488e+00
    4. Model googlenet with 59 layers: 9.955e+00
    5. Model dlrmRMC1_m with 6 layers: 8.187e+00
    6. Model alexnet with 5 layers: 9.752e+00
    7. Model transformer with 96 layers: 7.832e+00
    8. Model resnet50 with 53 layers: 8.936e+00
    9. Model wide_resnet50 with 53 layers: 8.605e+00
    10. Model manual with 3 layers: 8.444e+00
    11. Model shufflenet_v2 with 56 layers: 8.839e+00
    12. Model squeezenet with 26 layers: 9.331e+00
    13. Model try with 3 layers: 9.398e+00
    14. Model resnet18 with 20 layers: 9.584e+00
    15. Model vgg16 with 13 layers: 9.307e+00
    16. Model densenet with 160 layers: 9.621e+00
    17. Model T5_m with 6 layers: 8.591e+00
    18. Model resnext50_32x4d with 53 layers: 9.222e+00
    19. Model BERT_m with 6 layers: 8.000e+00
    20. Model ALBERT_m with 5 layers: 8.992e+00

Final result with all models and fixed hardware = 9.070883221921516

53. Using architecture PEs=16, L1=64, L2=512
    1. Model mnasnet with 52 layers: 1.115e+01
    2. Model ncf_m with 12 layers: 8.945e+00
    3. Model mobilenet_v2 with 52 layers: 1.014e+01
    4. Model googlenet with 59 layers: 1.145e+01
    5. Model dlrmRMC1_m with 6 layers: 7.556e+00
    6. Model alexnet with 5 layers: 1.068e+01
    7. Model transformer with 96 layers: 8.807e+00
    8. Model resnet50 with 53 layers: 1.141e+01
    9. Model wide_resnet50 with 53 layers: 1.120e+01
    10. Model manual with 3 layers: 7.667e+00
    11. Model shufflenet_v2 with 56 layers: 1.061e+01
    12. Model squeezenet with 26 layers: 1.166e+01
    13. Model try with 3 layers: 9.722e+00
    14. Model resnet18 with 20 layers: 1.120e+01
    15. Model vgg16 with 13 layers: 1.220e+01
    16. Model densenet with 160 layers: 1.159e+01
    17. Model T5_m with 6 layers: 7.040e+00
    18. Model resnext50_32x4d with 53 layers: 1.145e+01
    19. Model BERT_m with 6 layers: 9.202e+00
    20. Model ALBERT_m with 5 layers: 6.600e+00

Final result with all models and fixed hardware = 10.76586205548038

54. Using architecture PEs=16, L1=64, L2=1024
    1. Model mnasnet with 52 layers: 1.163e+01
    2. Model ncf_m with 12 layers: 9.342e+00
    3. Model mobilenet_v2 with 52 layers: 1.248e+01
    4. Model googlenet with 59 layers: 1.202e+01
    5. Model dlrmRMC1_m with 6 layers: 1.329e+01
    6. Model alexnet with 5 layers: 1.243e+01
    7. Model transformer with 96 layers: 1.014e+01
    8. Model resnet50 with 53 layers: 1.234e+01
    9. Model wide_resnet50 with 53 layers: 1.204e+01
    10. Model manual with 3 layers: 1.035e+01
    11. Model shufflenet_v2 with 56 layers: 1.225e+01
    12. Model squeezenet with 26 layers: 1.266e+01
    13. Model try with 3 layers: 1.194e+01
    14. Model resnet18 with 20 layers: 1.280e+01
    15. Model vgg16 with 13 layers: 1.331e+01
    16. Model densenet with 160 layers: 1.220e+01
    17. Model T5_m with 6 layers: 9.837e+00
    18. Model resnext50_32x4d with 53 layers: 1.242e+01
    19. Model BERT_m with 6 layers: 1.100e+01
    20. Model ALBERT_m with 5 layers: 1.076e+01

Final result with all models and fixed hardware = 11.885713270635993

55. Using architecture PEs=16, L1=64, L2=2048
    1. Model mnasnet with 52 layers: 1.308e+01
    2. Model ncf_m with 12 layers: 1.131e+01
    3. Model mobilenet_v2 with 52 layers: 1.318e+01
    4. Model googlenet with 59 layers: 1.320e+01
    5. Model dlrmRMC1_m with 6 layers: 9.199e+00
    6. Model alexnet with 5 layers: 1.404e+01
    7. Model transformer with 96 layers: 1.179e+01
    8. Model resnet50 with 53 layers: 1.292e+01
    9. Model wide_resnet50 with 53 layers: 1.302e+01
    10. Model manual with 3 layers: 1.303e+01
    11. Model shufflenet_v2 with 56 layers: 1.203e+01
    12. Model squeezenet with 26 layers: 1.399e+01
    13. Model try with 3 layers: 1.351e+01
    14. Model resnet18 with 20 layers: 1.306e+01
    15. Model vgg16 with 13 layers: 1.383e+01
    16. Model densenet with 160 layers: 1.296e+01
    17. Model T5_m with 6 layers: 1.141e+01
    18. Model resnext50_32x4d with 53 layers: 1.255e+01
    19. Model BERT_m with 6 layers: 1.055e+01
    20. Model ALBERT_m with 5 layers: 1.165e+01

Final result with all models and fixed hardware = 12.717002771312584

56. Using architecture PEs=16, L1=128, L2=128
    1. Model mnasnet with 52 layers: 7.447e+00
    2. Model ncf_m with 12 layers: 6.539e+00
    3. Model mobilenet_v2 with 52 layers: 7.947e+00
    4. Model googlenet with 59 layers: 7.887e+00
    5. Model dlrmRMC1_m with 6 layers: 7.848e+00
    6. Model alexnet with 5 layers: 7.700e+00
    7. Model transformer with 96 layers: 7.802e+00
    8. Model resnet50 with 53 layers: 7.754e+00
    9. Model wide_resnet50 with 53 layers: 7.987e+00
    10. Model manual with 3 layers: 4.667e+00
    11. Model shufflenet_v2 with 56 layers: 7.664e+00
    12. Model squeezenet with 26 layers: 8.073e+00
    13. Model try with 3 layers: 7.999e+00
    14. Model resnet18 with 20 layers: 8.138e+00
    15. Model vgg16 with 13 layers: 8.041e+00
    16. Model densenet with 160 layers: 7.784e+00
    17. Model T5_m with 6 layers: 8.000e+00
    18. Model resnext50_32x4d with 53 layers: 7.901e+00
    19. Model BERT_m with 6 layers: 8.000e+00
    20. Model ALBERT_m with 5 layers: 8.107e+00

Final result with all models and fixed hardware = 7.792024315290934

57. Using architecture PEs=16, L1=128, L2=256
    1. Model mnasnet with 52 layers: 9.068e+00
    2. Model ncf_m with 12 layers: 6.154e+00
    3. Model mobilenet_v2 with 52 layers: 9.091e+00
    4. Model googlenet with 59 layers: 9.344e+00
    5. Model dlrmRMC1_m with 6 layers: 8.943e+00
    6. Model alexnet with 5 layers: 8.819e+00
    7. Model transformer with 96 layers: 8.003e+00
    8. Model resnet50 with 53 layers: 9.172e+00
    9. Model wide_resnet50 with 53 layers: 9.193e+00
    10. Model manual with 3 layers: 8.772e+00
    11. Model shufflenet_v2 with 56 layers: 8.946e+00
    12. Model squeezenet with 26 layers: 9.725e+00
    13. Model try with 3 layers: 8.888e+00
    14. Model resnet18 with 20 layers: 8.807e+00
    15. Model vgg16 with 13 layers: 8.819e+00
    16. Model densenet with 160 layers: 9.598e+00
    17. Model T5_m with 6 layers: 8.444e+00
    18. Model resnext50_32x4d with 53 layers: 8.639e+00
    19. Model BERT_m with 6 layers: 8.800e+00
    20. Model ALBERT_m with 5 layers: 8.000e+00

Final result with all models and fixed hardware = 8.989761480378888

58. Using architecture PEs=16, L1=128, L2=512
    1. Model mnasnet with 52 layers: 1.093e+01
    2. Model ncf_m with 12 layers: 8.162e+00
    3. Model mobilenet_v2 with 52 layers: 1.052e+01
    4. Model googlenet with 59 layers: 1.118e+01
    5. Model dlrmRMC1_m with 6 layers: 8.182e+00
    6. Model alexnet with 5 layers: 1.264e+01
    7. Model transformer with 96 layers: 8.717e+00
    8. Model resnet50 with 53 layers: 1.068e+01
    9. Model wide_resnet50 with 53 layers: 1.123e+01
    10. Model manual with 3 layers: 1.375e+01
    11. Model shufflenet_v2 with 56 layers: 1.094e+01
    12. Model squeezenet with 26 layers: 1.173e+01
    13. Model try with 3 layers: 1.083e+01
    14. Model resnet18 with 20 layers: 1.151e+01
    15. Model vgg16 with 13 layers: 1.166e+01
    16. Model densenet with 160 layers: 1.118e+01
    17. Model T5_m with 6 layers: 9.103e+00
    18. Model resnext50_32x4d with 53 layers: 1.057e+01
    19. Model BERT_m with 6 layers: 1.029e+01
    20. Model ALBERT_m with 5 layers: 9.368e+00

Final result with all models and fixed hardware = 10.649197849797023

59. Using architecture PEs=16, L1=128, L2=1024
    1. Model mnasnet with 52 layers: 1.245e+01
    2. Model ncf_m with 12 layers: 1.081e+01
    3. Model mobilenet_v2 with 52 layers: 1.253e+01
    4. Model googlenet with 59 layers: 1.262e+01
    5. Model dlrmRMC1_m with 6 layers: 1.149e+01
    6. Model alexnet with 5 layers: 9.943e+00
    7. Model transformer with 96 layers: 1.022e+01
    8. Model resnet50 with 53 layers: 1.207e+01
    9. Model wide_resnet50 with 53 layers: 1.194e+01
    10. Model manual with 3 layers: 8.733e+00
    11. Model shufflenet_v2 with 56 layers: 1.170e+01
    12. Model squeezenet with 26 layers: 1.227e+01
    13. Model try with 3 layers: 8.726e+00
    14. Model resnet18 with 20 layers: 1.304e+01
    15. Model vgg16 with 13 layers: 1.231e+01
    16. Model densenet with 160 layers: 1.216e+01
    17. Model T5_m with 6 layers: 9.662e+00
    18. Model resnext50_32x4d with 53 layers: 1.184e+01
    19. Model BERT_m with 6 layers: 9.826e+00
    20. Model ALBERT_m with 5 layers: 1.067e+01

Final result with all models and fixed hardware = 11.822331691474966

60. Using architecture PEs=16, L1=128, L2=2048
    1. Model mnasnet with 52 layers: 1.256e+01
    2. Model ncf_m with 12 layers: 9.961e+00
    3. Model mobilenet_v2 with 52 layers: 1.250e+01
    4. Model googlenet with 59 layers: 1.301e+01
    5. Model dlrmRMC1_m with 6 layers: 9.118e+00
    6. Model alexnet with 5 layers: 1.477e+01
    7. Model transformer with 96 layers: 1.103e+01
    8. Model resnet50 with 53 layers: 1.341e+01
    9. Model wide_resnet50 with 53 layers: 1.322e+01
    10. Model manual with 3 layers: 1.437e+01
    11. Model shufflenet_v2 with 56 layers: 1.236e+01
    12. Model squeezenet with 26 layers: 1.399e+01
    13. Model try with 3 layers: 1.192e+01
    14. Model resnet18 with 20 layers: 1.234e+01
    15. Model vgg16 with 13 layers: 1.302e+01
    16. Model densenet with 160 layers: 1.269e+01
    17. Model T5_m with 6 layers: 1.037e+01
    18. Model resnext50_32x4d with 53 layers: 1.286e+01
    19. Model BERT_m with 6 layers: 1.077e+01
    20. Model ALBERT_m with 5 layers: 1.221e+01

Final result with all models and fixed hardware = 12.503878535859268

61. Using architecture PEs=32, L1=16, L2=128
    1. Model mnasnet with 52 layers: 7.881e+00
    2. Model ncf_m with 12 layers: 1.909e+00
    3. Model mobilenet_v2 with 52 layers: 8.771e+00
    4. Model googlenet with 59 layers: 8.506e+00
    5. Model dlrmRMC1_m with 6 layers: 3.731e+00
    6. Model alexnet with 5 layers: 8.248e+00
    7. Model transformer with 96 layers: 2.718e+00
    8. Model resnet50 with 53 layers: 7.806e+00
    9. Model wide_resnet50 with 53 layers: 8.339e+00
    10. Model manual with 3 layers: 5.897e+00
    11. Model shufflenet_v2 with 56 layers: 7.847e+00
    12. Model squeezenet with 26 layers: 9.793e+00
    13. Model try with 3 layers: 3.814e+00
    14. Model resnet18 with 20 layers: 6.574e+00
    15. Model vgg16 with 13 layers: 7.250e+00
    16. Model densenet with 160 layers: 7.589e+00
    17. Model T5_m with 6 layers: 1.077e+00
    18. Model resnext50_32x4d with 53 layers: 7.255e+00
    19. Model BERT_m with 6 layers: 1.576e+00
    20. Model ALBERT_m with 5 layers: 3.960e+00

Final result with all models and fixed hardware = 6.974585525033829

62. Using architecture PEs=32, L1=16, L2=256
    1. Model mnasnet with 52 layers: 1.464e+01
    2. Model ncf_m with 12 layers: 1.478e+01
    3. Model mobilenet_v2 with 52 layers: 1.474e+01
    4. Model googlenet with 59 layers: 1.421e+01
    5. Model dlrmRMC1_m with 6 layers: 1.563e+01
    6. Model alexnet with 5 layers: 1.079e+01
    7. Model transformer with 96 layers: 1.520e+01
    8. Model resnet50 with 53 layers: 1.520e+01
    9. Model wide_resnet50 with 53 layers: 1.454e+01
    10. Model manual with 3 layers: 1.600e+01
    11. Model shufflenet_v2 with 56 layers: 1.454e+01
    12. Model squeezenet with 26 layers: 1.476e+01
    13. Model try with 3 layers: 1.377e+01
    14. Model resnet18 with 20 layers: 1.575e+01
    15. Model vgg16 with 13 layers: 1.491e+01
    16. Model densenet with 160 layers: 1.421e+01
    17. Model T5_m with 6 layers: 1.600e+01
    18. Model resnext50_32x4d with 53 layers: 1.437e+01
    19. Model BERT_m with 6 layers: 1.124e+01
    20. Model ALBERT_m with 5 layers: 1.600e+01

Final result with all models and fixed hardware = 14.616643537212447

63. Using architecture PEs=32, L1=16, L2=512
    1. Model mnasnet with 52 layers: 1.697e+01
    2. Model ncf_m with 12 layers: 1.566e+01
    3. Model mobilenet_v2 with 52 layers: 1.772e+01
    4. Model googlenet with 59 layers: 1.825e+01
    5. Model dlrmRMC1_m with 6 layers: 1.473e+01
    6. Model alexnet with 5 layers: 1.741e+01
    7. Model transformer with 96 layers: 1.595e+01
    8. Model resnet50 with 53 layers: 1.822e+01
    9. Model wide_resnet50 with 53 layers: 1.868e+01
    10. Model manual with 3 layers: 1.600e+01
    11. Model shufflenet_v2 with 56 layers: 1.758e+01
    12. Model squeezenet with 26 layers: 1.847e+01
    13. Model try with 3 layers: 1.873e+01
    14. Model resnet18 with 20 layers: 1.880e+01
    15. Model vgg16 with 13 layers: 1.495e+01
    16. Model densenet with 160 layers: 1.737e+01
    17. Model T5_m with 6 layers: 1.740e+01
    18. Model resnext50_32x4d with 53 layers: 1.845e+01
    19. Model BERT_m with 6 layers: 1.766e+01
    20. Model ALBERT_m with 5 layers: 1.769e+01

Final result with all models and fixed hardware = 17.492089212449255

64. Using architecture PEs=32, L1=16, L2=1024
    1. Model mnasnet with 52 layers: 2.016e+01
    2. Model ncf_m with 12 layers: 1.670e+01
    3. Model mobilenet_v2 with 52 layers: 2.130e+01
    4. Model googlenet with 59 layers: 1.963e+01
    5. Model dlrmRMC1_m with 6 layers: 1.845e+01
    6. Model alexnet with 5 layers: 1.982e+01
    7. Model transformer with 96 layers: 1.719e+01
    8. Model resnet50 with 53 layers: 2.199e+01
    9. Model wide_resnet50 with 53 layers: 2.170e+01
    10. Model manual with 3 layers: 2.457e+01
    11. Model shufflenet_v2 with 56 layers: 2.011e+01
    12. Model squeezenet with 26 layers: 2.171e+01
    13. Model try with 3 layers: 2.075e+01
    14. Model resnet18 with 20 layers: 2.130e+01
    15. Model vgg16 with 13 layers: 2.181e+01
    16. Model densenet with 160 layers: 2.102e+01
    17. Model T5_m with 6 layers: 1.955e+01
    18. Model resnext50_32x4d with 53 layers: 2.220e+01
    19. Model BERT_m with 6 layers: 1.881e+01
    20. Model ALBERT_m with 5 layers: 1.956e+01

Final result with all models and fixed hardware = 20.425440067659

65. Using architecture PEs=32, L1=16, L2=2048
    1. Model mnasnet with 52 layers: 2.304e+01
    2. Model ncf_m with 12 layers: 1.733e+01
    3. Model mobilenet_v2 with 52 layers: 2.291e+01
    4. Model googlenet with 59 layers: 2.335e+01
    5. Model dlrmRMC1_m with 6 layers: 1.942e+01
    6. Model alexnet with 5 layers: 2.406e+01
    7. Model transformer with 96 layers: 1.947e+01
    8. Model resnet50 with 53 layers: 2.328e+01
    9. Model wide_resnet50 with 53 layers: 2.310e+01
    10. Model manual with 3 layers: 2.351e+01
    11. Model shufflenet_v2 with 56 layers: 2.209e+01
    12. Model squeezenet with 26 layers: 2.285e+01
    13. Model try with 3 layers: 2.615e+01
    14. Model resnet18 with 20 layers: 2.539e+01
    15. Model vgg16 with 13 layers: 2.347e+01
    16. Model densenet with 160 layers: 2.168e+01
    17. Model T5_m with 6 layers: 2.440e+01
    18. Model resnext50_32x4d with 53 layers: 2.370e+01
    19. Model BERT_m with 6 layers: 1.984e+01
    20. Model ALBERT_m with 5 layers: 2.048e+01

Final result with all models and fixed hardware = 22.225587265223275

66. Using architecture PEs=32, L1=32, L2=128
    1. Model mnasnet with 52 layers: 7.786e+00
    2. Model ncf_m with 12 layers: 3.913e+00
    3. Model mobilenet_v2 with 52 layers: 7.620e+00
    4. Model googlenet with 59 layers: 8.703e+00
    5. Model dlrmRMC1_m with 6 layers: 4.096e+00
    6. Model alexnet with 5 layers: 7.454e+00
    7. Model transformer with 96 layers: 2.772e+00
    8. Model resnet50 with 53 layers: 7.651e+00
    9. Model wide_resnet50 with 53 layers: 8.050e+00
    10. Model manual with 3 layers: 3.367e+00
    11. Model shufflenet_v2 with 56 layers: 8.233e+00
    12. Model squeezenet with 26 layers: 9.410e+00
    13. Model try with 3 layers: 3.655e+00
    14. Model resnet18 with 20 layers: 6.953e+00
    15. Model vgg16 with 13 layers: 6.873e+00
    16. Model densenet with 160 layers: 8.150e+00
    17. Model T5_m with 6 layers: 4.245e+00
    18. Model resnext50_32x4d with 53 layers: 9.148e+00
    19. Model BERT_m with 6 layers: 3.276e+00
    20. Model ALBERT_m with 5 layers: 6.062e+00

Final result with all models and fixed hardware = 7.227433503382949

67. Using architecture PEs=32, L1=32, L2=256
    1. Model mnasnet with 52 layers: 1.431e+01
    2. Model ncf_m with 12 layers: 1.306e+01
    3. Model mobilenet_v2 with 52 layers: 1.539e+01
    4. Model googlenet with 59 layers: 1.564e+01
    5. Model dlrmRMC1_m with 6 layers: 1.386e+01
    6. Model alexnet with 5 layers: 1.724e+01
    7. Model transformer with 96 layers: 1.542e+01
    8. Model resnet50 with 53 layers: 1.566e+01
    9. Model wide_resnet50 with 53 layers: 1.533e+01
    10. Model manual with 3 layers: 1.923e+01
    11. Model shufflenet_v2 with 56 layers: 1.398e+01
    12. Model squeezenet with 26 layers: 1.557e+01
    13. Model try with 3 layers: 1.533e+01
    14. Model resnet18 with 20 layers: 1.551e+01
    15. Model vgg16 with 13 layers: 1.508e+01
    16. Model densenet with 160 layers: 1.488e+01
    17. Model T5_m with 6 layers: 1.600e+01
    18. Model resnext50_32x4d with 53 layers: 1.560e+01
    19. Model BERT_m with 6 layers: 1.577e+01
    20. Model ALBERT_m with 5 layers: 1.600e+01

Final result with all models and fixed hardware = 15.145167686062244

68. Using architecture PEs=32, L1=32, L2=512
    1. Model mnasnet with 52 layers: 1.774e+01
    2. Model ncf_m with 12 layers: 1.731e+01
    3. Model mobilenet_v2 with 52 layers: 1.828e+01
    4. Model googlenet with 59 layers: 1.793e+01
    5. Model dlrmRMC1_m with 6 layers: 1.400e+01
    6. Model alexnet with 5 layers: 2.188e+01
    7. Model transformer with 96 layers: 1.557e+01
    8. Model resnet50 with 53 layers: 1.844e+01
    9. Model wide_resnet50 with 53 layers: 1.651e+01
    10. Model manual with 3 layers: 2.098e+01
    11. Model shufflenet_v2 with 56 layers: 1.603e+01
    12. Model squeezenet with 26 layers: 1.921e+01
    13. Model try with 3 layers: 1.453e+01
    14. Model resnet18 with 20 layers: 1.819e+01
    15. Model vgg16 with 13 layers: 1.585e+01
    16. Model densenet with 160 layers: 1.703e+01
    17. Model T5_m with 6 layers: 1.693e+01
    18. Model resnext50_32x4d with 53 layers: 1.853e+01
    19. Model BERT_m with 6 layers: 1.277e+01
    20. Model ALBERT_m with 5 layers: 1.901e+01

Final result with all models and fixed hardware = 17.22998213667118

69. Using architecture PEs=32, L1=32, L2=1024
    1. Model mnasnet with 52 layers: 2.054e+01
    2. Model ncf_m with 12 layers: 2.032e+01
    3. Model mobilenet_v2 with 52 layers: 2.194e+01
    4. Model googlenet with 59 layers: 2.143e+01
    5. Model dlrmRMC1_m with 6 layers: 1.491e+01
    6. Model alexnet with 5 layers: 1.642e+01
    7. Model transformer with 96 layers: 1.666e+01
    8. Model resnet50 with 53 layers: 2.224e+01
    9. Model wide_resnet50 with 53 layers: 2.217e+01
    10. Model manual with 3 layers: 1.832e+01
    11. Model shufflenet_v2 with 56 layers: 2.126e+01
    12. Model squeezenet with 26 layers: 2.192e+01
    13. Model try with 3 layers: 2.181e+01
    14. Model resnet18 with 20 layers: 2.308e+01
    15. Model vgg16 with 13 layers: 2.101e+01
    16. Model densenet with 160 layers: 2.143e+01
    17. Model T5_m with 6 layers: 1.826e+01
    18. Model resnext50_32x4d with 53 layers: 2.230e+01
    19. Model BERT_m with 6 layers: 1.790e+01
    20. Model ALBERT_m with 5 layers: 1.600e+01

Final result with all models and fixed hardware = 20.79182721109607

70. Using architecture PEs=32, L1=32, L2=2048
    1. Model mnasnet with 52 layers: 2.245e+01
    2. Model ncf_m with 12 layers: 1.782e+01
    3. Model mobilenet_v2 with 52 layers: 2.396e+01
    4. Model googlenet with 59 layers: 2.321e+01
    5. Model dlrmRMC1_m with 6 layers: 1.795e+01
    6. Model alexnet with 5 layers: 2.034e+01
    7. Model transformer with 96 layers: 1.982e+01
    8. Model resnet50 with 53 layers: 2.412e+01
    9. Model wide_resnet50 with 53 layers: 2.250e+01
    10. Model manual with 3 layers: 2.259e+01
    11. Model shufflenet_v2 with 56 layers: 2.142e+01
    12. Model squeezenet with 26 layers: 2.645e+01
    13. Model try with 3 layers: 2.891e+01
    14. Model resnet18 with 20 layers: 2.327e+01
    15. Model vgg16 with 13 layers: 2.397e+01
    16. Model densenet with 160 layers: 2.278e+01
    17. Model T5_m with 6 layers: 1.904e+01
    18. Model resnext50_32x4d with 53 layers: 2.244e+01
    19. Model BERT_m with 6 layers: 1.867e+01
    20. Model ALBERT_m with 5 layers: 2.117e+01

Final result with all models and fixed hardware = 22.415997376184034

71. Using architecture PEs=32, L1=64, L2=128
    1. Model mnasnet with 52 layers: 8.847e+00
    2. Model ncf_m with 12 layers: 1.677e+00
    3. Model mobilenet_v2 with 52 layers: 7.562e+00
    4. Model googlenet with 59 layers: 8.097e+00
    5. Model dlrmRMC1_m with 6 layers: 4.126e+00
    6. Model alexnet with 5 layers: 8.590e+00
    7. Model transformer with 96 layers: 2.515e+00
    8. Model resnet50 with 53 layers: 7.586e+00
    9. Model wide_resnet50 with 53 layers: 8.465e+00
    10. Model manual with 3 layers: 7.039e+00
    11. Model shufflenet_v2 with 56 layers: 8.374e+00
    12. Model squeezenet with 26 layers: 9.454e+00
    13. Model try with 3 layers: 4.152e+00
    14. Model resnet18 with 20 layers: 6.550e+00
    15. Model vgg16 with 13 layers: 7.816e+00
    16. Model densenet with 160 layers: 8.038e+00
    17. Model T5_m with 6 layers: 1.648e+00
    18. Model resnext50_32x4d with 53 layers: 6.718e+00
    19. Model BERT_m with 6 layers: 1.581e+00
    20. Model ALBERT_m with 5 layers: 5.314e+00

Final result with all models and fixed hardware = 7.009361799729365

72. Using architecture PEs=32, L1=64, L2=256
    1. Model mnasnet with 52 layers: 1.401e+01
    2. Model ncf_m with 12 layers: 1.502e+01
    3. Model mobilenet_v2 with 52 layers: 1.585e+01
    4. Model googlenet with 59 layers: 1.559e+01
    5. Model dlrmRMC1_m with 6 layers: 9.156e+00
    6. Model alexnet with 5 layers: 1.728e+01
    7. Model transformer with 96 layers: 1.548e+01
    8. Model resnet50 with 53 layers: 1.500e+01
    9. Model wide_resnet50 with 53 layers: 1.565e+01
    10. Model manual with 3 layers: 1.689e+01
    11. Model shufflenet_v2 with 56 layers: 1.440e+01
    12. Model squeezenet with 26 layers: 1.611e+01
    13. Model try with 3 layers: 1.600e+01
    14. Model resnet18 with 20 layers: 1.542e+01
    15. Model vgg16 with 13 layers: 1.478e+01
    16. Model densenet with 160 layers: 1.481e+01
    17. Model T5_m with 6 layers: 1.199e+01
    18. Model resnext50_32x4d with 53 layers: 1.560e+01
    19. Model BERT_m with 6 layers: 1.600e+01
    20. Model ALBERT_m with 5 layers: 1.410e+01

Final result with all models and fixed hardware = 15.10679994181326

73. Using architecture PEs=32, L1=64, L2=512
    1. Model mnasnet with 52 layers: 1.735e+01
    2. Model ncf_m with 12 layers: 1.344e+01
    3. Model mobilenet_v2 with 52 layers: 1.964e+01
    4. Model googlenet with 59 layers: 1.777e+01
    5. Model dlrmRMC1_m with 6 layers: 1.292e+01
    6. Model alexnet with 5 layers: 1.769e+01
    7. Model transformer with 96 layers: 1.610e+01
    8. Model resnet50 with 53 layers: 1.853e+01
    9. Model wide_resnet50 with 53 layers: 1.826e+01
    10. Model manual with 3 layers: 1.467e+01
    11. Model shufflenet_v2 with 56 layers: 1.676e+01
    12. Model squeezenet with 26 layers: 1.784e+01
    13. Model try with 3 layers: 1.271e+01
    14. Model resnet18 with 20 layers: 1.595e+01
    15. Model vgg16 with 13 layers: 1.769e+01
    16. Model densenet with 160 layers: 1.730e+01
    17. Model T5_m with 6 layers: 1.635e+01
    18. Model resnext50_32x4d with 53 layers: 1.791e+01
    19. Model BERT_m with 6 layers: 1.649e+01
    20. Model ALBERT_m with 5 layers: 1.633e+01

Final result with all models and fixed hardware = 17.35329130852503

74. Using architecture PEs=32, L1=64, L2=1024
    1. Model mnasnet with 52 layers: 2.024e+01
    2. Model ncf_m with 12 layers: 1.680e+01
    3. Model mobilenet_v2 with 52 layers: 2.140e+01
    4. Model googlenet with 59 layers: 2.097e+01
    5. Model dlrmRMC1_m with 6 layers: 2.002e+01
    6. Model alexnet with 5 layers: 1.958e+01
    7. Model transformer with 96 layers: 1.806e+01
    8. Model resnet50 with 53 layers: 2.118e+01
    9. Model wide_resnet50 with 53 layers: 2.243e+01
    10. Model manual with 3 layers: 1.975e+01
    11. Model shufflenet_v2 with 56 layers: 2.072e+01
    12. Model squeezenet with 26 layers: 2.210e+01
    13. Model try with 3 layers: 1.896e+01
    14. Model resnet18 with 20 layers: 2.045e+01
    15. Model vgg16 with 13 layers: 2.153e+01
    16. Model densenet with 160 layers: 2.157e+01
    17. Model T5_m with 6 layers: 2.117e+01
    18. Model resnext50_32x4d with 53 layers: 2.122e+01
    19. Model BERT_m with 6 layers: 2.010e+01
    20. Model ALBERT_m with 5 layers: 1.866e+01

Final result with all models and fixed hardware = 20.73558543978349

75. Using architecture PEs=32, L1=64, L2=2048
    1. Model mnasnet with 52 layers: 2.339e+01
    2. Model ncf_m with 12 layers: 1.868e+01
    3. Model mobilenet_v2 with 52 layers: 2.386e+01
    4. Model googlenet with 59 layers: 2.479e+01
    5. Model dlrmRMC1_m with 6 layers: 1.944e+01
    6. Model alexnet with 5 layers: 2.622e+01
    7. Model transformer with 96 layers: 1.935e+01
    8. Model resnet50 with 53 layers: 2.424e+01
    9. Model wide_resnet50 with 53 layers: 2.436e+01
    10. Model manual with 3 layers: 2.377e+01
    11. Model shufflenet_v2 with 56 layers: 2.157e+01
    12. Model squeezenet with 26 layers: 2.536e+01
    13. Model try with 3 layers: 2.799e+01
    14. Model resnet18 with 20 layers: 2.282e+01
    15. Model vgg16 with 13 layers: 2.542e+01
    16. Model densenet with 160 layers: 2.368e+01
    17. Model T5_m with 6 layers: 2.025e+01
    18. Model resnext50_32x4d with 53 layers: 2.302e+01
    19. Model BERT_m with 6 layers: 1.835e+01
    20. Model ALBERT_m with 5 layers: 2.118e+01

Final result with all models and fixed hardware = 22.978111125845732

76. Using architecture PEs=32, L1=128, L2=128
    1. Model mnasnet with 52 layers: 7.736e+00
    2. Model ncf_m with 12 layers: 2.665e+00
    3. Model mobilenet_v2 with 52 layers: 7.159e+00
    4. Model googlenet with 59 layers: 8.435e+00
    5. Model dlrmRMC1_m with 6 layers: 5.037e+00
    6. Model alexnet with 5 layers: 6.045e+00
    7. Model transformer with 96 layers: 2.447e+00
    8. Model resnet50 with 53 layers: 7.507e+00
    9. Model wide_resnet50 with 53 layers: 7.819e+00
    10. Model manual with 3 layers: 8.889e+00
    11. Model shufflenet_v2 with 56 layers: 8.191e+00
    12. Model squeezenet with 26 layers: 8.752e+00
    13. Model try with 3 layers: 6.044e+00
    14. Model resnet18 with 20 layers: 8.267e+00
    15. Model vgg16 with 13 layers: 7.900e+00
    16. Model densenet with 160 layers: 
8.081e+00
    17. Model T5_m with 6 layers: 2.750e+00
    18. Model resnext50_32x4d with 53 layers: 6.538e+00
    19. Model BERT_m with 6 layers: 4.423e+00
    20. Model ALBERT_m with 5 layers: 3.999e+00

Final result with all models and fixed hardware = 6.919388396481732

77. Using architecture PEs=32, L1=128, L2=256
    1. Model mnasnet with 52 layers: 1.313e+01
    2. Model ncf_m with 12 layers: 1.463e+01
    3. Model mobilenet_v2 with 52 layers: 1.552e+01
    4. Model googlenet with 59 layers: 1.525e+01
    5. Model dlrmRMC1_m with 6 layers: 1.414e+01
    6. Model alexnet with 5 layers: 1.505e+01
    7. Model transformer with 96 layers: 1.532e+01
    8. Model resnet50 with 53 layers: 1.502e+01
    9. Model wide_resnet50 with 53 layers: 1.488e+01
    10. Model manual with 3 layers: 1.600e+01
    11. Model shufflenet_v2 with 56 layers: 1.407e+01
    12. Model squeezenet with 26 layers: 1.575e+01
    13. Model try with 3 layers: 1.600e+01
    14. Model resnet18 with 20 layers: 1.537e+01
    15. Model vgg16 with 13 layers: 1.704e+01
    16. Model densenet with 160 layers: 1.431e+01
    17. Model T5_m with 6 layers: 1.600e+01
    18. Model resnext50_32x4d with 53 layers: 1.508e+01
    19. Model BERT_m with 6 layers: 1.600e+01
    20. Model ALBERT_m with 5 layers: 1.626e+01

Final result with all models and fixed hardware = 14.83806243166441

78. Using architecture PEs=32, L1=128, L2=512
    1. Model mnasnet with 52 layers: 1.756e+01
    2. Model ncf_m with 12 layers: 1.577e+01
    3. Model mobilenet_v2 with 52 layers: 1.905e+01
    4. Model googlenet with 59 layers: 1.729e+01
    5. Model dlrmRMC1_m with 6 layers: 1.501e+01
    6. Model alexnet with 5 layers: 1.781e+01
    7. Model transformer with 96 layers: 1.681e+01
    8. Model resnet50 with 53 layers: 1.871e+01
    9. Model wide_resnet50 with 53 layers: 1.771e+01
    10. Model manual with 3 layers: 1.768e+01
    11. Model shufflenet_v2 with 56 layers: 1.649e+01
    12. Model squeezenet with 26 layers: 1.828e+01
    13. Model try with 3 layers: 1.320e+01
    14. Model resnet18 with 20 layers: 2.014e+01
    15. Model vgg16 with 13 layers: 1.640e+01
    16. Model densenet with 160 layers: 1.765e+01
    17. Model T5_m with 6 layers: 1.527e+01
    18. Model resnext50_32x4d with 53 layers: 1.721e+01
    19. Model BERT_m with 6 layers: 1.689e+01
    20. Model ALBERT_m with 5 layers: 1.828e+01

Final result with all models and fixed hardware = 17.543402292286874

79. Using architecture PEs=32, L1=128, L2=1024
    1. Model mnasnet with 52 layers: 2.060e+01
    2. Model ncf_m with 12 layers: 1.653e+01
    3. Model mobilenet_v2 with 52 layers: 2.015e+01
    4. Model googlenet with 59 layers: 2.159e+01
    5. Model dlrmRMC1_m with 6 layers: 1.851e+01
    6. Model alexnet with 5 layers: 2.420e+01
    7. Model transformer with 96 layers: 1.831e+01
    8. Model resnet50 with 53 layers: 2.207e+01
    9. Model wide_resnet50 with 53 layers: 2.236e+01
    10. Model manual with 3 layers: 2.024e+01
    11. Model shufflenet_v2 with 56 layers: 2.039e+01
    12. Model squeezenet with 26 layers: 2.236e+01
    13. Model try with 3 layers: 2.429e+01
    14. Model resnet18 with 20 layers: 2.166e+01
    15. Model vgg16 with 13 layers: 2.169e+01
    16. Model densenet with 160 layers: 2.047e+01
    17. Model T5_m with 6 layers: 1.950e+01
    18. Model resnext50_32x4d with 53 layers: 2.145e+01
    19. Model BERT_m with 6 layers: 1.927e+01
    20. Model ALBERT_m with 5 layers: 2.242e+01

Final result with all models and fixed hardware = 20.65654689986468

80. Using architecture PEs=32, L1=128, L2=2048
    1. Model mnasnet with 52 layers: 2.205e+01
    2. Model ncf_m with 12 layers: 1.770e+01
    3. Model mobilenet_v2 with 52 layers: 2.461e+01
    4. Model googlenet with 59 layers: 2.372e+01
    5. Model dlrmRMC1_m with 6 layers: 2.107e+01
    6. Model alexnet with 5 layers: 1.851e+01
    7. Model transformer with 96 layers: 2.039e+01
    8. Model resnet50 with 53 layers: 2.366e+01
    9. Model wide_resnet50 with 53 layers: 2.374e+01
    10. Model manual with 3 layers: 2.437e+01
    11. Model shufflenet_v2 with 56 layers: 2.273e+01
    12. Model squeezenet with 26 layers: 2.309e+01
    13. Model try with 3 layers: 2.637e+01
    14. Model resnet18 with 20 layers: 2.403e+01
    15. Model vgg16 with 13 layers: 2.448e+01
    16. Model densenet with 160 layers: 2.244e+01
    17. Model T5_m with 6 layers: 2.058e+01
    18. Model resnext50_32x4d with 53 layers: 2.443e+01
    19. Model BERT_m with 6 layers: 2.345e+01
    20. Model ALBERT_m with 5 layers: 1.463e+01

Final result with all models and fixed hardware = 22.696522167794317

81. Using architecture PEs=64, L1=16, L2=128
    1. Model mnasnet with 52 layers: 7.663e+00
    2. Model ncf_m with 12 layers: 2.283e+00
    3. Model mobilenet_v2 with 52 layers: 7.855e+00
    4. Model googlenet with 59 layers: 8.338e+00
    5. Model dlrmRMC1_m with 6 layers: 5.090e+00
    6. Model alexnet with 5 layers: 8.205e+00
    7. Model transformer with 96 layers: 3.436e+00
    8. Model resnet50 with 53 layers: 8.013e+00
    9. Model wide_resnet50 with 53 layers: 8.806e+00
    10. Model manual with 3 layers: 8.827e+00
    11. Model shufflenet_v2 with 56 layers: 8.826e+00
    12. Model squeezenet with 26 layers: 1.046e+01
    13. Model try with 3 layers: 4.805e+00
    14. Model resnet18 with 20 layers: 7.825e+00
    15. Model vgg16 with 13 layers: 9.240e+00
    16. Model densenet with 160 layers: 7.745e+00
    17. Model T5_m with 6 layers: 4.719e+00
    18. Model resnext50_32x4d with 53 layers: 8.141e+00
    19. Model BERT_m with 6 layers: 3.319e+00
    20. Model ALBERT_m with 5 layers: 4.107e+00

Final result with all models and fixed hardware = 7.364166173207036

82. Using architecture PEs=64, L1=16, L2=256
    1. Model mnasnet with 52 layers: 1.595e+01
    2. Model ncf_m with 12 layers: 4.996e+00
    3. Model mobilenet_v2 with 52 layers: 1.427e+01
    4. Model googlenet with 59 layers: 1.355e+01
    5. Model dlrmRMC1_m with 6 layers: 6.266e+00
    6. Model alexnet with 5 layers: 1.489e+01
    7. Model transformer with 96 layers: 5.190e+00
    8. Model resnet50 with 53 layers: 1.582e+01
    9. Model wide_resnet50 with 53 layers: 1.492e+01
    10. Model manual with 3 layers: 1.233e+01
    11. Model shufflenet_v2 with 56 layers: 1.572e+01
    12. Model squeezenet with 26 layers: 1.805e+01
    13. Model try with 3 layers: 4.485e+00
    14. Model resnet18 with 20 layers: 1.363e+01
    15. Model vgg16 with 13 layers: 1.556e+01
    16. Model densenet with 160 layers: 1.691e+01
    17. Model T5_m with 6 layers: 6.035e+00
    18. Model resnext50_32x4d with 53 layers: 1.438e+01
    19. Model BERT_m with 6 layers: 4.861e+00
    20. Model ALBERT_m with 5 layers: 6.896e+00

Final result with all models and fixed hardware = 13.685517433017592

83. Using architecture PEs=64, L1=16, L2=512
    1. Model mnasnet with 52 layers: 2.649e+01
    2. Model ncf_m with 12 layers: 2.848e+01
    3. Model mobilenet_v2 with 52 layers: 2.826e+01
    4. Model googlenet with 59 layers: 2.956e+01
    5. Model dlrmRMC1_m with 6 layers: 2.752e+01
    6. Model alexnet with 5 layers: 3.019e+01
    7. Model transformer with 96 layers: 3.152e+01
    8. Model resnet50 with 53 layers: 3.099e+01
    9. Model wide_resnet50 with 53 layers: 2.745e+01
    10. Model manual with 3 layers: 3.200e+01
    11. Model shufflenet_v2 with 56 layers: 2.870e+01
    12. Model squeezenet with 26 layers: 2.835e+01
    13. Model try with 3 layers: 2.033e+01
    14. Model resnet18 with 20 layers: 2.751e+01
    15. Model vgg16 with 13 layers: 2.993e+01
    16. Model densenet with 160 layers: 2.902e+01
    17. Model T5_m with 6 layers: 3.200e+01
    18. Model resnext50_32x4d with 53 layers: 3.064e+01
    19. Model BERT_m with 6 layers: 3.200e+01
    20. Model ALBERT_m with 5 layers: 3.200e+01

Final result with all models and fixed hardware = 29.262159897158323

84. Using architecture PEs=64, L1=16, L2=1024
    1. Model mnasnet with 52 layers: 2.918e+01
    2. Model ncf_m with 12 layers: 3.150e+01
    3. Model mobilenet_v2 with 52 layers: 3.359e+01
    4. Model googlenet with 59 layers: 3.480e+01
    5. Model dlrmRMC1_m with 6 layers: 3.269e+01
    6. Model alexnet with 5 layers: 3.529e+01
    7. Model transformer with 96 layers: 3.337e+01
    8. Model resnet50 with 53 layers: 3.783e+01
    9. Model wide_resnet50 with 53 layers: 3.723e+01
    10. Model manual with 3 layers: 3.067e+01
    11. Model shufflenet_v2 with 56 layers: 3.287e+01
    12. Model squeezenet with 26 layers: 3.207e+01
    13. Model try with 3 layers: 3.620e+01
    14. Model resnet18 with 20 layers: 3.663e+01
    15. Model vgg16 with 13 layers: 3.250e+01
    16. Model densenet with 160 layers: 3.580e+01
    17. Model T5_m with 6 layers: 3.200e+01
    18. Model resnext50_32x4d with 53 layers: 3.763e+01
    19. Model BERT_m with 6 layers: 2.810e+01
    20. Model ALBERT_m with 5 layers: 3.200e+01

Final result with all models and fixed hardware = 34.53682328822734

85. Using architecture PEs=64, L1=16, L2=2048
    1. Model mnasnet with 52 layers: 3.829e+01
    2. Model ncf_m with 12 layers: 3.602e+01
    3. Model mobilenet_v2 with 52 layers: 4.160e+01
    4. Model googlenet with 59 layers: 3.999e+01
    5. Model dlrmRMC1_m with 6 layers: 3.053e+01
    6. Model alexnet with 5 layers: 3.844e+01
    7. Model transformer with 96 layers: 3.928e+01
    8. Model resnet50 with 53 layers: 3.947e+01
    9. Model wide_resnet50 with 53 layers: 4.082e+01
    10. Model manual with 3 layers: 4.018e+01
    11. Model shufflenet_v2 with 56 layers: 3.829e+01
    12. Model squeezenet with 26 layers: 3.791e+01
    13. Model try with 3 layers: 3.374e+01
    14. Model resnet18 with 20 layers: 3.695e+01
    15. Model vgg16 with 13 layers: 3.923e+01
    16. Model densenet with 160 layers: 3.996e+01
    17. Model T5_m with 6 layers: 3.471e+01
    18. Model resnext50_32x4d with 53 layers: 3.877e+01
    19. Model BERT_m with 6 layers: 3.762e+01
    20. Model ALBERT_m with 5 layers: 3.747e+01

Final result with all models and fixed hardware = 39.265956778078476

86. Using architecture PEs=64, L1=32, L2=128
    1. Model mnasnet with 52 layers: 8.072e+00
    2. Model ncf_m with 12 layers: 2.553e+00
    3. Model mobilenet_v2 with 52 layers: 7.756e+00
    4. Model googlenet with 59 layers: 9.291e+00
    5. Model dlrmRMC1_m with 6 layers: 3.415e+00
    6. Model alexnet with 5 layers: 8.958e+00
    7. Model transformer with 96 layers: 3.370e+00
    8. Model resnet50 with 53 layers: 7.866e+00
    9. Model wide_resnet50 with 53 layers: 8.172e+00
    10. Model manual with 3 layers: 4.035e+00
    11. Model shufflenet_v2 with 56 layers: 1.031e+01
    12. Model squeezenet with 26 layers: 9.827e+00
    13. Model try with 3 layers: 6.761e+00
    14. Model resnet18 with 20 layers: 9.580e+00
    15. Model vgg16 with 13 layers: 7.800e+00
    16. Model densenet with 160 layers: 8.096e+00
    17. Model T5_m with 6 layers: 5.528e+00
    18. Model resnext50_32x4d with 53 layers: 7.513e+00
    19. Model BERT_m with 6 layers: 3.056e+00
    20. Model ALBERT_m with 5 layers: 5.195e+00

Final result with all models and fixed hardware = 7.537225815967523

87. Using architecture PEs=64, L1=32, L2=256
    1. Model mnasnet with 52 layers: 1.507e+01
    2. Model ncf_m with 12 layers: 8.555e+00
    3. Model mobilenet_v2 with 52 layers: 1.459e+01
    4. Model googlenet with 59 layers: 1.542e+01
    5. Model dlrmRMC1_m with 6 layers: 9.698e+00
    6. Model alexnet with 5 layers: 1.514e+01
    7. Model transformer with 96 layers: 4.838e+00
    8. Model resnet50 with 53 layers: 1.637e+01
    9. Model wide_resnet50 with 53 layers: 1.471e+01
    10. Model manual with 3 layers: 2.031e+01
    11. Model shufflenet_v2 with 56 layers: 1.491e+01
    12. Model squeezenet with 26 layers: 1.841e+01
    13. Model try with 3 layers: 1.465e+01
    14. Model resnet18 with 20 layers: 1.682e+01
    15. Model vgg16 with 13 layers: 1.538e+01
    16. Model densenet with 160 layers: 1.689e+01
    17. Model T5_m with 6 layers: 1.645e+00
    18. Model resnext50_32x4d with 53 layers: 1.624e+01
    19. Model BERT_m with 6 layers: 4.464e+00
    20. Model ALBERT_m with 5 layers: 1.068e+01

Final result with all models and fixed hardware = 14.084684028416778

88. Using architecture PEs=64, L1=32, L2=512
    1. Model mnasnet with 52 layers: 2.761e+01
    2. Model ncf_m with 12 layers: 2.679e+01
    3. Model mobilenet_v2 with 52 layers: 3.069e+01
    4. Model googlenet with 59 layers: 2.672e+01
    5. Model dlrmRMC1_m with 6 layers: 2.515e+01
    6. Model alexnet with 5 layers: 2.881e+01
    7. Model transformer with 96 layers: 3.059e+01
    8. Model resnet50 with 53 layers: 3.006e+01
    9. Model wide_resnet50 with 53 layers: 2.926e+01
    10. Model manual with 3 layers: 2.533e+01
    11. Model shufflenet_v2 with 56 layers: 2.807e+01
    12. Model squeezenet with 26 layers: 2.753e+01
    13. Model try with 3 layers: 3.065e+01
    14. Model resnet18 with 20 layers: 3.117e+01
    15. Model vgg16 with 13 layers: 3.132e+01
    16. Model densenet with 160 layers: 2.915e+01
    17. Model T5_m with 6 layers: 3.200e+01
    18. Model resnext50_32x4d with 53 layers: 2.833e+01
    19. Model BERT_m with 6 layers: 3.200e+01
    20. Model ALBERT_m with 5 layers: 3.200e+01

Final result with all models and fixed hardware = 29.0940689661705

89. Using architecture PEs=64, L1=32, L2=1024
    1. Model mnasnet with 52 layers: 3.160e+01
    2. Model ncf_m with 12 layers: 3.459e+01
    3. Model mobilenet_v2 with 52 layers: 3.587e+01
    4. Model googlenet with 59 layers: 3.340e+01
    5. Model dlrmRMC1_m with 6 layers: 2.852e+01
    6. Model alexnet with 5 layers: 2.813e+01
    7. Model transformer with 96 layers: 2.942e+01
    8. Model resnet50 with 53 layers: 3.453e+01
    9. Model wide_resnet50 with 53 layers: 3.501e+01
    10. Model manual with 3 layers: 4.416e+01
    11. Model shufflenet_v2 with 56 layers: 3.261e+01
    12. Model squeezenet with 26 layers: 3.433e+01
    13. Model try with 3 layers: 3.491e+01
    14. Model resnet18 with 20 layers: 3.223e+01
    15. Model vgg16 with 13 layers: 3.408e+01
    16. Model densenet with 160 layers: 3.558e+01
    17. Model T5_m with 6 layers: 3.200e+01
    18. Model resnext50_32x4d with 53 layers: 3.500e+01
    19. Model BERT_m with 6 layers: 3.339e+01
    20. Model ALBERT_m with 5 layers: 3.200e+01

Final result with all models and fixed hardware = 33.63990430175913

90. Using architecture PEs=64, L1=32, L2=2048
    1. Model mnasnet with 52 layers: 3.705e+01
    2. Model ncf_m with 12 layers: 3.486e+01
    3. Model mobilenet_v2 with 52 layers: 4.106e+01
    4. Model googlenet with 59 layers: 4.203e+01
    5. Model dlrmRMC1_m with 6 layers: 4.106e+01
    6. Model alexnet with 5 layers: 3.098e+01
    7. Model transformer with 96 layers: 3.534e+01
    8. Model resnet50 with 53 layers: 4.292e+01
    9. Model wide_resnet50 with 53 layers: 3.992e+01
    10. Model manual with 3 layers: 4.447e+01
    11. Model shufflenet_v2 with 56 layers: 3.934e+01
    12. Model squeezenet with 26 layers: 3.795e+01
    13. Model try with 3 layers: 4.553e+01
    14. Model resnet18 with 20 layers: 3.937e+01
    15. Model vgg16 with 13 layers: 3.883e+01
    16. Model densenet with 160 layers: 4.027e+01
    17. Model T5_m with 6 layers: 3.500e+01
    18. Model resnext50_32x4d with 53 layers: 4.443e+01
    19. Model BERT_m with 6 layers: 3.176e+01
    20. Model ALBERT_m with 5 layers: 2.507e+01

Final result with all models and fixed hardware = 39.54125017591339

91. Using architecture PEs=64, L1=64, L2=128
    1. Model mnasnet with 52 layers: 8.053e+00
    2. Model ncf_m with 12 layers: 3.506e+00
    3. Model mobilenet_v2 with 52 layers: 8.070e+00
    4. Model googlenet with 59 layers: 8.853e+00
    5. Model dlrmRMC1_m with 6 layers: 2.282e+00
    6. Model alexnet with 5 layers: 6.171e+00
    7. Model transformer with 96 layers: 2.500e+00
    8. Model resnet50 with 53 layers: 8.638e+00
    9. Model wide_resnet50 with 53 layers: 8.057e+00
    10. Model manual with 3 layers: 4.304e+00
    11. Model shufflenet_v2 with 56 layers: 9.378e+00
    12. Model squeezenet with 26 layers: 9.789e+00
    13. Model try with 3 layers: 7.266e+00
    14. Model resnet18 with 20 layers: 8.682e+00
    15. Model vgg16 with 13 layers: 7.608e+00
    16. Model densenet with 160 layers: 8.049e+00
    17. Model T5_m with 6 layers: 4.131e+00
    18. Model resnext50_32x4d with 53 layers: 7.371e+00
    19. Model BERT_m with 6 layers: 5.618e+00
    20. Model ALBERT_m with 5 layers: 5.948e+00

Final result with all models and fixed hardware = 7.342040868741542

92. Using architecture PEs=64, L1=64, L2=256
    1. Model mnasnet with 52 layers: 1.657e+01
    2. Model ncf_m with 12 layers: 8.116e+00
    3. Model mobilenet_v2 with 52 layers: 1.427e+01
    4. Model googlenet with 59 layers: 1.390e+01
    5. Model dlrmRMC1_m with 6 layers: 6.872e+00
    6. Model alexnet with 5 layers: 1.348e+01
    7. Model transformer with 96 layers: 5.773e+00
    8. Model resnet50 with 53 layers: 1.460e+01
    9. Model wide_resnet50 with 53 layers: 1.555e+01
    10. Model manual with 3 layers: 1.950e+01
    11. Model shufflenet_v2 with 56 layers: 1.584e+01
    12. Model squeezenet with 26 layers: 2.059e+01
    13. Model try with 3 layers: 1.593e+01
    14. Model resnet18 with 20 layers: 1.742e+01
    15. Model vgg16 with 13 layers: 1.359e+01
    16. Model densenet with 160 layers: 1.776e+01
    17. Model T5_m with 6 layers: 7.678e+00
    18. Model resnext50_32x4d with 53 layers: 1.386e+01
    19. Model BERT_m with 6 layers: 7.216e+00
    20. Model ALBERT_m with 5 layers: 5.360e+00

Final result with all models and fixed hardware = 14.248040799729363

93. Using architecture PEs=64, L1=64, L2=512
    1. Model mnasnet with 52 layers: 2.778e+01
    2. Model ncf_m with 12 layers: 3.284e+01
    3. Model mobilenet_v2 with 52 layers: 2.899e+01
    4. Model googlenet with 59 layers: 2.663e+01
    5. Model dlrmRMC1_m with 6 layers: 2.854e+01
    6. Model alexnet with 5 layers: 2.266e+01
    7. Model transformer with 96 layers: 3.073e+01
    8. Model resnet50 with 53 layers: 3.055e+01
    9. Model wide_resnet50 with 53 layers: 2.843e+01
    10. Model manual with 3 layers: 1.911e+01
    11. Model shufflenet_v2 with 56 layers: 2.744e+01
    12. Model squeezenet with 26 layers: 2.839e+01
    13. Model try with 3 layers: 2.532e+01
    14. Model resnet18 with 20 layers: 3.011e+01
    15. Model vgg16 with 13 layers: 3.105e+01
    16. Model densenet with 160 layers: 2.862e+01
    17. Model T5_m with 6 layers: 3.200e+01
    18. Model resnext50_32x4d with 53 layers: 2.980e+01
    19. Model BERT_m with 6 layers: 2.683e+01
    20. Model ALBERT_m with 5 layers: 3.200e+01

Final result with all models and fixed hardware = 28.908156722598104

94. Using architecture PEs=64, L1=64, L2=1024
    1. Model mnasnet with 52 layers: 3.105e+01
    2. Model ncf_m with 12 layers: 2.961e+01
    3. Model mobilenet_v2 with 52 layers: 3.400e+01
    4. Model googlenet with 59 layers: 3.355e+01
    5. Model dlrmRMC1_m with 6 layers: 3.362e+01
    6. Model alexnet with 5 layers: 2.691e+01
    7. Model transformer with 96 layers: 3.281e+01
    8. Model resnet50 with 53 layers: 3.744e+01
    9. Model wide_resnet50 with 53 layers: 3.515e+01
    10. Model manual with 3 layers: 3.556e+01
    11. Model shufflenet_v2 with 56 layers: 3.222e+01
    12. Model squeezenet with 26 layers: 3.387e+01
    13. Model try with 3 layers: 2.918e+01
    14. Model resnet18 with 20 layers: 3.225e+01
    15. Model vgg16 with 13 layers: 3.765e+01
    16. Model densenet with 160 layers: 3.486e+01
    17. Model T5_m with 6 layers: 3.200e+01
    18. Model resnext50_32x4d with 53 layers: 3.620e+01
    19. Model BERT_m with 6 layers: 3.679e+01
    20. Model ALBERT_m with 5 layers: 3.200e+01

Final result with all models and fixed hardware = 34.00938661163735

95. Using architecture PEs=64, L1=64, L2=2048
    1. Model mnasnet with 52 layers: 3.866e+01
    2. Model ncf_m with 12 layers: 3.621e+01
    3. Model mobilenet_v2 with 52 layers: 3.869e+01
    4. Model googlenet with 59 layers: 3.863e+01
    5. Model dlrmRMC1_m with 6 layers: 3.435e+01
    6. Model alexnet with 5 layers: 3.292e+01
    7. Model transformer with 96 layers: 3.593e+01
    8. Model resnet50 with 53 layers: 4.314e+01
    9. Model wide_resnet50 with 53 layers: 4.346e+01
    10. Model manual with 3 layers: 3.970e+01
    11. Model shufflenet_v2 with 56 layers: 3.576e+01
    12. Model squeezenet with 26 layers: 4.452e+01
    13. Model try with 3 layers: 2.672e+01
    14. Model resnet18 with 20 layers: 2.956e+01
    15. Model vgg16 with 13 layers: 4.248e+01
    16. Model densenet with 160 layers: 4.270e+01
    17. Model T5_m with 6 layers: 4.025e+01
    18. Model resnext50_32x4d with 53 layers: 4.098e+01
    19. Model BERT_m with 6 layers: 3.276e+01
    20. Model ALBERT_m with 5 layers: 3.804e+01

Final result with all models and fixed hardware = 39.622305849797016

96. Using architecture PEs=64, L1=128, L2=128
    1. Model mnasnet with 52 layers: 9.431e+00
    2. Model ncf_m with 12 layers: 1.828e+00
    3. Model mobilenet_v2 with 52 layers: 9.358e+00
    4. Model googlenet with 59 layers: 9.795e+00
    5. Model dlrmRMC1_m with 6 layers: 3.787e+00
    6. Model alexnet with 5 layers: 8.523e+00
    7. Model transformer with 96 layers: 3.033e+00
    8. Model resnet50 with 53 layers: 8.238e+00
    9. Model wide_resnet50 with 53 layers: 8.852e+00
    10. Model manual with 3 layers: 6.722e+00
    11. Model shufflenet_v2 with 56 layers: 9.141e+00
    12. Model squeezenet with 26 layers: 9.187e+00
    13. Model try with 3 layers: 5.517e+00
    14. Model resnet18 with 20 layers: 7.528e+00
    15. Model vgg16 with 13 layers: 8.176e+00
    16. Model densenet with 160 layers: 8.377e+00
    17. Model T5_m with 6 layers: 4.078e+00
    18. Model resnext50_32x4d with 53 layers: 8.164e+00
    19. Model BERT_m with 6 layers: 1.375e+00
    20. Model ALBERT_m with 5 layers: 2.144e+00

Final result with all models and fixed hardware = 7.713023680649526

97. Using architecture PEs=64, L1=128, L2=256
    1. Model mnasnet with 52 layers: 1.535e+01
    2. Model ncf_m with 12 layers: 6.984e+00
    3. Model mobilenet_v2 with 52 layers: 1.522e+01
    4. Model googlenet with 59 layers: 1.578e+01
    5. Model dlrmRMC1_m with 6 layers: 1.074e+01
    6. Model alexnet with 5 layers: 1.506e+01
    7. Model transformer with 96 layers: 5.594e+00
    8. Model resnet50 with 53 layers: 1.542e+01
    9. Model wide_resnet50 with 53 layers: 1.729e+01
    10. Model manual with 3 layers: 2.033e+01
    11. Model shufflenet_v2 with 56 layers: 1.418e+01
    12. Model squeezenet with 26 layers: 2.006e+01
    13. Model try with 3 layers: 9.300e+00
    14. Model resnet18 with 20 layers: 1.551e+01
    15. Model vgg16 with 13 layers: 1.739e+01
    16. Model densenet with 160 layers: 1.720e+01
    17. Model T5_m with 6 layers: 6.155e+00
    18. Model resnext50_32x4d with 53 layers: 1.497e+01
    19. Model BERT_m with 6 layers: 5.561e+00
    20. Model ALBERT_m with 5 layers: 1.120e+01

Final result with all models and fixed hardware = 14.38195645466847

98. Using architecture PEs=64, L1=128, L2=512
    1. Model mnasnet with 52 layers: 2.856e+01
    2. Model ncf_m with 12 layers: 2.948e+01
    3. Model mobilenet_v2 with 52 layers: 2.727e+01
    4. Model googlenet with 59 layers: 2.967e+01
    5. Model dlrmRMC1_m with 6 layers: 1.943e+01
    6. Model alexnet with 5 layers: 2.756e+01
    7. Model transformer with 96 layers: 3.019e+01
    8. Model resnet50 with 53 layers: 2.836e+01
    9. Model wide_resnet50 with 53 layers: 2.926e+01
    10. Model manual with 3 layers: 2.375e+01
    11. Model shufflenet_v2 with 56 layers: 2.857e+01
    12. Model squeezenet with 26 layers: 3.045e+01
    13. Model try with 3 layers: 3.065e+01
    14. Model resnet18 with 20 layers: 3.427e+01
    15. Model vgg16 with 13 layers: 3.195e+01
    16. Model densenet with 160 layers: 2.748e+01
    17. Model T5_m with 6 layers: 2.933e+01
    18. Model resnext50_32x4d with 53 layers: 2.818e+01
    19. Model BERT_m with 6 layers: 3.093e+01
    20. Model ALBERT_m with 5 layers: 2.901e+01

Final result with all models and fixed hardware = 28.77742269012178

99. Using architecture PEs=64, L1=128, L2=1024
    1. Model mnasnet with 52 layers: 3.213e+01
    2. Model ncf_m with 12 layers: 3.413e+01
    3. Model mobilenet_v2 with 52 layers: 3.449e+01
    4. Model googlenet with 59 layers: 3.212e+01
    5. Model dlrmRMC1_m with 6 layers: 3.001e+01
    6. Model alexnet with 5 layers: 2.679e+01
    7. Model transformer with 96 layers: 3.333e+01
    8. Model resnet50 with 53 layers: 3.225e+01
    9. Model wide_resnet50 with 53 layers: 3.616e+01
    10. Model manual with 3 layers: 4.590e+01
    11. Model shufflenet_v2 with 56 layers: 3.188e+01
    12. Model squeezenet with 26 layers: 3.762e+01
    13. Model try with 3 layers: 3.279e+01
    14. Model resnet18 with 20 layers: 3.347e+01
    15. Model vgg16 with 13 layers: 3.364e+01
    16. Model densenet with 160 layers: 3.469e+01
    17. Model T5_m with 6 layers: 3.276e+01
    18. Model resnext50_32x4d with 53 layers: 3.517e+01
    19. Model BERT_m with 6 layers: 3.582e+01
    20. Model ALBERT_m with 5 layers: 3.412e+01

Final result with all models and fixed hardware = 33.84443727469554

100. Using architecture PEs=64, L1=128, L2=2048
    1. Model mnasnet with 52 layers: 3.824e+01
    2. Model ncf_m with 12 layers: 3.388e+01
    3. Model mobilenet_v2 with 52 layers: 4.050e+01
    4. Model googlenet with 59 layers: 4.096e+01
    5. Model dlrmRMC1_m with 6 layers: 3.197e+01
    6. Model alexnet with 5 layers: 4.267e+01
    7. Model transformer with 96 layers: 3.762e+01
    8. Model resnet50 with 53 layers: 4.247e+01
    9. Model wide_resnet50 with 53 layers: 4.136e+01
    10. Model manual with 3 layers: 4.315e+01
    11. Model shufflenet_v2 with 56 layers: 3.789e+01
    12. Model squeezenet with 26 layers: 4.307e+01
    13. Model try with 3 layers: 3.428e+01
    14. Model resnet18 with 20 layers: 4.541e+01
    15. Model vgg16 with 13 layers: 4.178e+01
    16. Model densenet with 160 layers: 4.167e+01
    17. Model T5_m with 6 layers: 3.369e+01
    18. Model resnext50_32x4d with 53 layers: 4.213e+01
    19. Model BERT_m with 6 layers: 3.126e+01
    20. Model ALBERT_m with 5 layers: 4.221e+01

Final result with all models and fixed hardware = 40.328087960757784

101. Using architecture PEs=128, L1=16, L2=128
    1. Model mnasnet with 52 layers: 7.332e+00
    2. Model ncf_m with 12 layers: 2.227e+00
    3. Model mobilenet_v2 with 52 layers: 7.850e+00
    4. Model googlenet with 59 layers: 9.121e+00
    5. Model dlrmRMC1_m with 6 layers: 5.858e+00
    6. Model alexnet with 5 layers: 9.357e+00
    7. Model transformer with 96 layers: 3.505e+00
    8. Model resnet50 with 53 layers: 8.921e+00
    9. Model wide_resnet50 with 53 layers: 8.397e+00
    10. Model manual with 3 layers: 4.885e+00
    11. Model shufflenet_v2 with 56 layers: 8.655e+00
    12. Model squeezenet with 26 layers: 9.565e+00
    13. Model try with 3 layers: 6.333e+00
    14. Model resnet18 with 20 layers: 9.765e+00
    15. Model vgg16 with 13 layers: 8.404e+00
    16. Model densenet with 160 layers: 8.510e+00
    17. Model T5_m with 6 layers: 1.400e+00
    18. Model resnext50_32x4d with 53 layers: 8.126e+00
    19. Model BERT_m with 6 layers: 3.038e+00
    20. Model ALBERT_m with 5 layers: 1.490e+00

Final result with all models and fixed hardware = 7.562205966170501

102. Using architecture PEs=128, L1=16, L2=256
    1. Model mnasnet with 52 layers: 1.562e+01
    2. Model ncf_m with 12 layers: 3.086e+00
    3. Model mobilenet_v2 with 52 layers: 1.419e+01
    4. Model googlenet with 59 layers: 1.617e+01
    5. Model dlrmRMC1_m with 6 layers: 1.500e+01
    6. Model alexnet with 5 layers: 1.557e+01
    7. Model transformer with 96 layers: 9.058e+00
    8. Model resnet50 with 53 layers: 1.745e+01
    9. Model wide_resnet50 with 53 layers: 1.597e+01
    10. Model manual with 3 layers: 1.489e+01
    11. Model shufflenet_v2 with 56 layers: 1.635e+01
    12. Model squeezenet with 26 layers: 1.925e+01
    13. Model try with 3 layers: 1.485e+01
    14. Model resnet18 with 20 layers: 1.527e+01
    15. Model vgg16 with 13 layers: 1.571e+01
    16. Model densenet with 160 layers: 1.621e+01
    17. Model T5_m with 6 layers: 7.729e+00
    18. Model resnext50_32x4d with 53 layers: 1.618e+01
    19. Model BERT_m with 6 layers: 4.079e+00
    20. Model ALBERT_m with 5 layers: 1.001e+01

Final result with all models and fixed hardware = 14.798117679296345

103. Using architecture PEs=128, L1=16, L2=512
    1. Model mnasnet with 52 layers: 2.759e+01
    2. Model ncf_m with 12 layers: 1.498e+01
    3. Model mobilenet_v2 with 52 layers: 3.314e+01
    4. Model googlenet with 59 layers: 3.254e+01
    5. Model dlrmRMC1_m with 6 layers: 8.661e+00
    6. Model alexnet with 5 layers: 3.445e+01
    7. Model transformer with 96 layers: 1.677e+01
    8. Model resnet50 with 53 layers: 2.875e+01
    9. Model wide_resnet50 with 53 layers: 2.703e+01
    10. Model manual with 3 layers: 2.933e+01
    11. Model shufflenet_v2 with 56 layers: 3.099e+01
    12. Model squeezenet with 26 layers: 3.184e+01
    13. Model try with 3 layers: 2.281e+01
    14. Model resnet18 with 20 layers: 2.714e+01
    15. Model vgg16 with 13 layers: 3.365e+01
    16. Model densenet with 160 layers: 2.934e+01
    17. Model T5_m with 6 layers: 1.443e+01
    18. Model resnext50_32x4d with 53 layers: 2.229e+01
    19. Model BERT_m with 6 layers: 1.593e+01
    20. Model ALBERT_m with 5 layers: 2.595e+01

Final result with all models and fixed hardware = 26.97680630581867

104. Using architecture PEs=128, L1=16, L2=1024
    1. Model mnasnet with 52 layers: 5.135e+01
    2. Model ncf_m with 12 layers: 5.460e+01
    3. Model mobilenet_v2 with 52 layers: 4.954e+01
    4. Model googlenet with 59 layers: 5.253e+01
    5. Model dlrmRMC1_m with 6 layers: 5.644e+01
    6. Model alexnet with 5 layers: 6.400e+01
    7. Model transformer with 96 layers: 6.019e+01
    8. Model resnet50 with 53 layers: 5.293e+01
    9. Model wide_resnet50 with 53 layers: 5.654e+01
    10. Model manual with 3 layers: 5.200e+01
    11. Model shufflenet_v2 with 56 layers: 5.048e+01
    12. Model squeezenet with 26 layers: 5.328e+01
    13. Model try with 3 layers: 5.169e+01
    14. Model resnet18 with 20 layers: 6.509e+01
    15. Model vgg16 with 13 layers: 5.756e+01
    16. Model densenet with 160 layers: 5.059e+01
    17. Model T5_m with 6 layers: 5.943e+01
    18. Model resnext50_32x4d with 53 layers: 5.877e+01
    19. Model BERT_m with 6 layers: 6.206e+01
    20. Model ALBERT_m with 5 layers: 6.400e+01

Final result with all models and fixed hardware = 54.22375978078484

105. Using architecture PEs=128, L1=16, L2=2048
    1. Model mnasnet with 52 layers: 6.143e+01
    2. Model ncf_m with 12 layers: 5.236e+01
    3. Model mobilenet_v2 with 52 layers: 6.078e+01
    4. Model googlenet with 59 layers: 5.995e+01
    5. Model dlrmRMC1_m with 6 layers: 5.727e+01
    6. Model alexnet with 5 layers: 6.883e+01
    7. Model transformer with 96 layers: 6.481e+01
    8. Model resnet50 with 53 layers: 6.545e+01
    9. Model wide_resnet50 with 53 layers: 6.949e+01
    10. Model manual with 3 layers: 6.393e+01
    11. Model shufflenet_v2 with 56 layers: 6.146e+01
    12. Model squeezenet with 26 layers: 6.089e+01
    13. Model try with 3 layers: 6.437e+01
    14. Model resnet18 with 20 layers: 6.764e+01
    15. Model vgg16 with 13 layers: 6.586e+01
    16. Model densenet with 160 layers: 6.404e+01
    17. Model T5_m with 6 layers: 6.400e+01
    18. Model resnext50_32x4d with 53 layers: 6.749e+01
    19. Model BERT_m with 6 layers: 6.400e+01
    20. Model ALBERT_m with 5 layers: 6.400e+01

Final result with all models and fixed hardware = 63.75046404600812

106. Using architecture PEs=128, L1=32, L2=128
    1. Model mnasnet with 52 layers: 8.740e+00
    2. Model ncf_m with 12 layers: 3.698e+00
    3. Model mobilenet_v2 with 52 layers: 8.077e+00
    4. Model googlenet with 59 layers: 9.768e+00
    5. Model dlrmRMC1_m with 6 layers: 6.406e+00
    6. Model alexnet with 5 layers: 7.384e+00
    7. Model transformer with 96 layers: 3.492e+00
    8. Model resnet50 with 53 layers: 8.833e+00
    9. Model wide_resnet50 with 53 layers: 8.593e+00
    10. Model manual with 3 layers: 1.570e+00
    11. Model shufflenet_v2 with 56 layers: 8.688e+00
    12. Model squeezenet with 26 layers: 1.030e+01
    13. Model try with 3 layers: 9.316e+00
    14. Model resnet18 with 20 layers: 1.049e+01
    15. Model vgg16 with 13 layers: 8.290e+00
    16. Model densenet with 160 layers: 8.041e+00
    17. Model T5_m with 6 layers: 5.165e+00
    18. Model resnext50_32x4d with 53 layers: 8.517e+00
    19. Model BERT_m with 6 layers: 4.388e+00
    20. Model ALBERT_m with 5 layers: 5.592e+00

Final result with all models and fixed hardware = 7.790525407307173

107. Using architecture PEs=128, L1=32, L2=256
    1. Model mnasnet with 52 layers: 1.618e+01
    2. Model ncf_m with 12 layers: 9.376e+00
    3. Model mobilenet_v2 with 52 layers: 1.593e+01
    4. Model googlenet with 59 layers: 1.460e+01
    5. Model dlrmRMC1_m with 6 layers: 9.780e+00
    6. Model alexnet with 5 layers: 1.547e+01
    7. Model transformer with 96 layers: 7.632e+00
    8. Model resnet50 with 53 layers: 1.614e+01
    9. Model wide_resnet50 with 53 layers: 1.409e+01
    10. Model manual with 3 layers: 1.400e+01
    11. Model shufflenet_v2 with 56 layers: 1.437e+01
    12. Model squeezenet with 26 layers: 2.265e+01
    13. Model try with 3 layers: 1.700e+01
    14. Model resnet18 with 20 layers: 2.294e+01
    15. Model vgg16 with 13 layers: 2.262e+01
    16. Model densenet with 160 layers: 1.717e+01
    17. Model T5_m with 6 layers: 1.730e+01
    18. Model resnext50_32x4d with 53 layers: 1.717e+01
    19. Model BERT_m with 6 layers: 9.726e+00
    20. Model ALBERT_m with 5 layers: 2.606e+00

Final result with all models and fixed hardware = 15.138072579161031

108. Using architecture PEs=128, L1=32, L2=512
    1. Model mnasnet with 52 layers: 3.182e+01
    2. Model ncf_m with 12 layers: 1.945e+01
    3. Model mobilenet_v2 with 52 layers: 3.019e+01
    4. Model googlenet with 59 layers: 2.871e+01
    5. Model dlrmRMC1_m with 6 layers: 1.625e+01
    6. Model alexnet with 5 layers: 2.053e+01
    7. Model transformer with 96 layers: 1.606e+01
    8. Model resnet50 with 53 layers: 2.429e+01
    9. Model wide_resnet50 with 53 layers: 2.425e+01
    10. Model manual with 3 layers: 3.244e+01
    11. Model shufflenet_v2 with 56 layers: 3.061e+01
    12. Model squeezenet with 26 layers: 3.357e+01
    13. Model try with 3 layers: 1.769e+01
    14. Model resnet18 with 20 layers: 3.164e+01
    15. Model vgg16 with 13 layers: 2.948e+01
    16. Model densenet with 160 layers: 2.644e+01
    17. Model T5_m with 6 layers: 1.519e+01
    18. Model resnext50_32x4d with 53 layers: 2.674e+01
    19. Model BERT_m with 6 layers: 1.249e+01
    20. Model ALBERT_m with 5 layers: 1.171e+01

Final result with all models and fixed hardware = 25.835225343707716

109. Using architecture PEs=128, L1=32, L2=1024
    1. Model mnasnet with 52 layers: 4.975e+01
    2. Model ncf_m with 12 layers: 4.557e+01
    3. Model mobilenet_v2 with 52 layers: 4.850e+01
    4. Model googlenet with 59 layers: 5.208e+01
    5. Model dlrmRMC1_m with 6 layers: 5.045e+01
    6. Model alexnet with 5 layers: 4.166e+01
    7. Model transformer with 96 layers: 6.029e+01
    8. Model resnet50 with 53 layers: 5.733e+01
    9. Model wide_resnet50 with 53 layers: 5.724e+01
    10. Model manual with 3 layers: 6.044e+01
    11. Model shufflenet_v2 with 56 layers: 4.876e+01
    12. Model squeezenet with 26 layers: 5.111e+01
    13. Model try with 3 layers: 5.916e+01
    14. Model resnet18 with 20 layers: 5.805e+01
    15. Model vgg16 with 13 layers: 5.136e+01
    16. Model densenet with 160 layers: 5.147e+01
    17. Model T5_m with 6 layers: 5.926e+01
    18. Model resnext50_32x4d with 53 layers: 5.601e+01
    19. Model BERT_m with 6 layers: 5.867e+01
    20. Model ALBERT_m with 5 layers: 6.961e+01

Final result with all models and fixed hardware = 53.594098270635996

110. Using architecture PEs=128, L1=32, L2=2048
    1. Model mnasnet with 52 layers: 6.449e+01
    2. Model ncf_m with 12 layers: 6.190e+01
    3. Model mobilenet_v2 with 52 layers: 6.157e+01
    4. Model googlenet with 59 layers: 5.836e+01
    5. Model dlrmRMC1_m with 6 layers: 4.848e+01
    6. Model alexnet with 5 layers: 7.341e+01
    7. Model transformer with 96 layers: 6.563e+01
    8. Model resnet50 with 53 layers: 6.857e+01
    9. Model wide_resnet50 with 53 layers: 6.319e+01
    10. Model manual with 3 layers: 5.680e+01
    11. Model shufflenet_v2 with 56 layers: 6.676e+01
    12. Model squeezenet with 26 layers: 5.731e+01
    13. Model try with 3 layers: 5.916e+01
    14. Model resnet18 with 20 layers: 6.143e+01
    15. Model vgg16 with 13 layers: 7.075e+01
    16. Model densenet with 160 layers: 5.745e+01
    17. Model T5_m with 6 layers: 5.938e+01
    18. Model resnext50_32x4d with 53 layers: 6.540e+01
    19. Model BERT_m with 6 layers: 6.400e+01
    20. Model ALBERT_m with 5 layers: 7.314e+01

Final result with all models and fixed hardware = 62.47875082949932

111. Using architecture PEs=128, L1=64, L2=128
    1. Model mnasnet with 52 layers: 8.191e+00
    2. Model ncf_m with 12 layers: 3.539e+00
    3. Model mobilenet_v2 with 52 layers: 7.605e+00
    4. Model googlenet with 59 layers: 8.599e+00
    5. Model dlrmRMC1_m with 6 layers: 1.624e+00
    6. Model alexnet with 5 layers: 1.318e+01
    7. Model transformer with 96 layers: 3.174e+00
    8. Model resnet50 with 53 layers: 8.195e+00
    9. Model wide_resnet50 with 53 layers: 8.516e+00
    10. Model manual with 3 layers: 9.057e+00
    11. Model shufflenet_v2 with 56 layers: 8.432e+00
    12. Model squeezenet with 26 layers: 9.260e+00
    13. Model try with 3 layers: 7.599e+00
    14. Model resnet18 with 20 layers: 7.140e+00
    15. Model vgg16 with 13 layers: 9.822e+00
    16. Model densenet with 160 layers: 8.279e+00
    17. Model T5_m with 6 layers: 3.073e+00
    18. Model resnext50_32x4d with 53 layers: 8.352e+00
    19. Model BERT_m with 6 layers: 1.739e+00
    20. Model ALBERT_m with 5 layers: 3.379e+00

Final result with all models and fixed hardware = 7.420467215155616

112. Using architecture PEs=128, L1=64, L2=256
    1. Model mnasnet with 52 layers: 1.594e+01
    2. Model ncf_m with 12 layers: 9.689e+00
    3. Model mobilenet_v2 with 52 layers: 1.441e+01
    4. Model googlenet with 59 layers: 1.558e+01
    5. Model dlrmRMC1_m with 6 layers: 8.305e+00
    6. Model alexnet with 5 layers: 1.587e+01
    7. Model transformer with 96 layers: 9.434e+00
    8. Model resnet50 with 53 layers: 1.675e+01
    9. Model wide_resnet50 with 53 layers: 1.643e+01
    10. Model manual with 3 layers: 1.932e+01
    11. Model shufflenet_v2 with 56 layers: 1.555e+01
    12. Model squeezenet with 26 layers: 2.073e+01
    13. Model try with 3 layers: 4.825e+00
    14. Model resnet18 with 20 layers: 1.681e+01
    15. Model vgg16 with 13 layers: 1.532e+01
    16. Model densenet with 160 layers: 1.677e+01
    17. Model T5_m with 6 layers: 1.122e+01
    18. Model resnext50_32x4d with 53 layers: 1.619e+01
    19. Model BERT_m with 6 layers: 6.700e+00
    20. Model ALBERT_m with 5 layers: 1.249e+01

Final result with all models and fixed hardware = 15.06931121650879

113. Using architecture PEs=128, L1=64, L2=512
    1. Model mnasnet with 52 layers: 3.110e+01
    2. Model ncf_m with 12 layers: 1.673e+01
    3. Model mobilenet_v2 with 52 layers: 2.721e+01
    4. Model googlenet with 59 layers: 2.943e+01
    5. Model dlrmRMC1_m with 6 layers: 2.000e+01
    6. Model alexnet with 5 layers: 2.208e+01
    7. Model transformer with 96 layers: 1.711e+01
    8. Model resnet50 with 53 layers: 2.669e+01
    9. Model wide_resnet50 with 53 layers: 2.645e+01
    10. Model manual with 3 layers: 3.389e+01
    11. Model shufflenet_v2 with 56 layers: 3.236e+01
    12. Model squeezenet with 26 layers: 2.625e+01
    13. Model try with 3 layers: 2.740e+01
    14. Model resnet18 with 20 layers: 3.177e+01
    15. Model vgg16 with 13 layers: 2.978e+01
    16. Model densenet with 160 layers: 2.466e+01
    17. Model T5_m with 6 layers: 1.729e+01
    18. Model resnext50_32x4d with 53 layers: 2.499e+01
    19. Model BERT_m with 6 layers: 1.324e+01
    20. Model ALBERT_m with 5 layers: 1.664e+01

Final result with all models and fixed hardware = 25.568498227334228

114. Using architecture PEs=128, L1=64, L2=1024
    1. Model mnasnet with 52 layers: 5.185e+01
    2. Model ncf_m with 12 layers: 6.119e+01
    3. Model mobilenet_v2 with 52 layers: 5.609e+01
    4. Model googlenet with 59 layers: 5.044e+01
    5. Model dlrmRMC1_m with 6 layers: 4.529e+01
    6. Model alexnet with 5 layers: 4.402e+01
    7. Model transformer with 96 layers: 6.072e+01
    8. Model resnet50 with 53 layers: 5.841e+01
    9. Model wide_resnet50 with 53 layers: 5.631e+01
    10. Model manual with 3 layers: 4.726e+01
    11. Model shufflenet_v2 with 56 layers: 5.248e+01
    12. Model squeezenet with 26 layers: 5.476e+01
    13. Model try with 3 layers: 3.324e+01
    14. Model resnet18 with 20 layers: 5.744e+01
    15. Model vgg16 with 13 layers: 6.607e+01
    16. Model densenet with 160 layers: 5.180e+01
    17. Model T5_m with 6 layers: 6.400e+01
    18. Model resnext50_32x4d with 53 layers: 5.596e+01
    19. Model BERT_m with 6 layers: 5.881e+01
    20. Model ALBERT_m with 5 layers: 5.973e+01

Final result with all models and fixed hardware = 54.97238709742896

115. Using architecture PEs=128, L1=64, L2=2048
    1. Model mnasnet with 52 layers: 6.239e+01
    2. Model ncf_m with 12 layers: 6.172e+01
    3. Model mobilenet_v2 with 52 layers: 6.360e+01
    4. Model googlenet with 59 layers: 5.824e+01
    5. Model dlrmRMC1_m with 6 layers: 4.609e+01
    6. Model alexnet with 5 layers: 6.518e+01
    7. Model transformer with 96 layers: 6.670e+01
    8. Model resnet50 with 53 layers: 6.816e+01
    9. Model wide_resnet50 with 53 layers: 7.250e+01
    10. Model manual with 3 layers: 5.850e+01
    11. Model shufflenet_v2 with 56 layers: 6.542e+01
    12. Model squeezenet with 26 layers: 5.832e+01
    13. Model try with 3 layers: 5.670e+01
    14. Model resnet18 with 20 layers: 6.509e+01
    15. Model vgg16 with 13 layers: 6.644e+01
    16. Model densenet with 160 layers: 6.017e+01
    17. Model T5_m with 6 layers: 6.313e+01
    18. Model resnext50_32x4d with 53 layers: 6.859e+01
    19. Model BERT_m with 6 layers: 6.552e+01
    20. Model ALBERT_m with 5 layers: 5.160e+01

Final result with all models and fixed hardware = 63.83179154262517

116. Using architecture PEs=128, L1=128, L2=128
    1. Model mnasnet with 52 layers: 8.196e+00
    2. Model ncf_m with 12 layers: 6.173e+00
    3. Model mobilenet_v2 with 52 layers: 8.215e+00
    4. Model googlenet with 59 layers: 8.915e+00
    5. Model dlrmRMC1_m with 6 layers: 5.681e+00
    6. Model alexnet with 5 layers: 7.721e+00
    7. Model transformer with 96 layers: 2.666e+00
    8. Model resnet50 with 53 layers: 7.764e+00
    9. Model wide_resnet50 with 53 layers: 7.910e+00
    10. Model manual with 3 layers: 7.672e+00
    11. Model shufflenet_v2 with 56 layers: 8.625e+00
    12. Model squeezenet with 26 layers: 9.737e+00
    13. Model try with 3 layers: 7.118e+00
    14. Model resnet18 with 20 layers: 9.395e+00
    15. Model vgg16 with 13 layers: 6.402e+00
    16. Model densenet with 160 layers: 8.684e+00
    17. Model T5_m with 6 layers: 1.501e+00
    18. Model resnext50_32x4d with 53 layers: 7.999e+00
    19. Model BERT_m with 6 layers: 3.416e+00
    20. Model ALBERT_m with 5 layers: 6.929e+00

Final result with all models and fixed hardware = 7.49927394993234

117. Using architecture PEs=128, L1=128, L2=256
    1. Model mnasnet with 52 layers: 1.541e+01
    2. Model ncf_m with 12 layers: 5.992e+00
    3. Model mobilenet_v2 with 52 layers: 1.491e+01
    4. Model googlenet with 59 layers: 1.833e+01
    5. Model dlrmRMC1_m with 6 layers: 1.325e+01
    6. Model alexnet with 5 layers: 1.359e+01
    7. Model transformer with 96 layers: 7.975e+00
    8. Model resnet50 with 53 layers: 1.944e+01
    9. Model wide_resnet50 with 53 layers: 1.681e+01
    10. Model manual with 3 layers: 2.499e+01
    11. Model shufflenet_v2 with 56 layers: 1.583e+01
    12. Model squeezenet with 26 layers: 1.748e+01
    13. Model try with 3 layers: 1.428e+01
    14. Model resnet18 with 20 layers: 1.754e+01
    15. Model vgg16 with 13 layers: 1.821e+01
    16. Model densenet with 160 layers: 1.687e+01
    17. Model T5_m with 6 layers: 7.206e+00
    18. Model resnext50_32x4d with 53 layers: 1.503e+01
    19. Model BERT_m with 6 layers: 3.773e+00
    20. Model ALBERT_m with 5 layers: 4.630e+00

Final result with all models and fixed hardware = 15.149628055480377

118. Using architecture PEs=128, L1=128, L2=512
    1. Model mnasnet with 52 layers: 3.016e+01
    2. Model ncf_m with 12 layers: 1.373e+01
    3. Model mobilenet_v2 with 52 layers: 2.623e+01
    4. Model googlenet with 59 layers: 3.224e+01
    5. Model dlrmRMC1_m with 6 layers: 1.060e+01
    6. Model alexnet with 5 layers: 1.648e+01
    7. Model transformer with 96 layers: 1.583e+01
    8. Model resnet50 with 53 layers: 2.604e+01
    9. Model wide_resnet50 with 53 layers: 2.361e+01
    10. Model manual with 3 layers: 3.418e+01
    11. Model shufflenet_v2 with 56 layers: 3.216e+01
    12. Model squeezenet with 26 layers: 3.321e+01
    13. Model try with 3 layers: 3.226e+01
    14. Model resnet18 with 20 layers: 2.605e+01
    15. Model vgg16 with 13 layers: 3.192e+01
    16. Model densenet with 160 layers: 2.650e+01
    17. Model T5_m with 6 layers: 2.589e+01
    18. Model resnext50_32x4d with 53 layers: 2.644e+01
    19. Model BERT_m with 6 layers: 1.918e+01
    20. Model ALBERT_m with 5 layers: 2.135e+01

Final result with all models and fixed hardware = 25.866419050067666

119. Using architecture PEs=128, L1=128, L2=1024
    1. Model mnasnet with 52 layers: 5.189e+01
    2. Model ncf_m with 12 layers: 5.423e+01
    3. Model mobilenet_v2 with 52 layers: 4.969e+01
    4. Model googlenet with 59 layers: 5.241e+01
    5. Model dlrmRMC1_m with 6 layers: 4.720e+01
    6. Model alexnet with 5 layers: 4.799e+01
    7. Model transformer with 96 layers: 6.269e+01
    8. Model resnet50 with 53 layers: 5.906e+01
    9. Model wide_resnet50 with 53 layers: 5.139e+01
    10. Model manual with 3 layers: 4.917e+01
    11. Model shufflenet_v2 with 56 layers: 4.962e+01
    12. Model squeezenet with 26 layers: 5.229e+01
    13. Model try with 3 layers: 5.859e+01
    14. Model resnet18 with 20 layers: 5.566e+01
    15. Model vgg16 with 13 layers: 5.906e+01
    16. Model densenet with 160 layers: 5.122e+01
    17. Model T5_m with 6 layers: 5.738e+01
    18. Model resnext50_32x4d with 53 layers: 5.597e+01
    19. Model BERT_m with 6 layers: 5.867e+01
    20. Model ALBERT_m with 5 layers: 5.760e+01

Final result with all models and fixed hardware = 54.00464809201624

120. Using architecture PEs=128, L1=128, L2=2048
    1. Model mnasnet with 52 layers: 5.768e+01
    2. Model ncf_m with 12 layers: 6.209e+01
    3. Model mobilenet_v2 with 52 layers: 5.419e+01
    4. Model googlenet with 59 layers: 5.689e+01
    5. Model dlrmRMC1_m with 6 layers: 4.653e+01
    6. Model alexnet with 5 layers: 7.017e+01
    7. Model transformer with 96 layers: 6.618e+01
    8. Model resnet50 with 53 layers: 6.661e+01
    9. Model wide_resnet50 with 53 layers: 7.252e+01
    10. Model manual with 3 layers: 4.133e+01
    11. Model shufflenet_v2 with 56 layers: 6.235e+01
    12. Model squeezenet with 26 layers: 5.833e+01
    13. Model try with 3 layers: 5.747e+01
    14. Model resnet18 with 20 layers: 6.178e+01
    15. Model vgg16 with 13 layers: 6.982e+01
    16. Model densenet with 160 layers: 5.790e+01
    17. Model T5_m with 6 layers: 7.040e+01
    18. Model resnext50_32x4d with 53 layers: 7.095e+01
    19. Model BERT_m with 6 layers: 6.727e+01
    20. Model ALBERT_m with 5 layers: 7.251e+01

Final result with all models and fixed hardware = 62.16264363058187

121. Using architecture PEs=256, L1=16, L2=128
    1. Model mnasnet with 52 layers: 8.318e+00
    2. Model ncf_m with 12 layers: 2.932e+00
    3. Model mobilenet_v2 with 52 layers: 9.197e+00
    4. Model googlenet with 59 layers: 9.546e+00
    5. Model dlrmRMC1_m with 6 layers: 5.408e+00
    6. Model alexnet with 5 layers: 5.539e+00
    7. Model transformer with 96 layers: 3.109e+00
    8. Model resnet50 with 53 layers: 8.649e+00
    9. Model wide_resnet50 with 53 layers: 7.890e+00
    10. Model manual with 3 layers: 3.509e+00
    11. Model shufflenet_v2 with 56 layers: 9.343e+00
    12. Model squeezenet with 26 layers: 1.142e+01
    13. Model try with 3 layers: 4.507e+00
    14. Model resnet18 with 20 layers: 1.042e+01
    15. Model vgg16 with 13 layers: 8.539e+00
    16. Model densenet with 160 layers: 7.973e+00
    17. Model T5_m with 6 layers: 2.480e+00
    18. Model resnext50_32x4d with 53 layers: 7.964e+00
    19. Model BERT_m with 6 layers: 5.238e+00
    20. Model ALBERT_m with 5 layers: 3.285e+00

Final result with all models and fixed hardware = 7.670138903924223

122. Using architecture PEs=256, L1=16, L2=256
    1. Model mnasnet with 52 layers: 1.583e+01
    2. Model ncf_m with 12 layers: 9.419e+00
    3. Model mobilenet_v2 with 52 layers: 1.338e+01
    4. Model googlenet with 59 layers: 1.645e+01
    5. Model dlrmRMC1_m with 6 layers: 1.313e+01
    6. Model alexnet with 5 layers: 1.195e+01
    7. Model transformer with 96 layers: 7.987e+00
    8. Model resnet50 with 53 layers: 1.657e+01
    9. Model wide_resnet50 with 53 layers: 1.565e+01
    10. Model manual with 3 layers: 1.090e+01
    11. Model shufflenet_v2 with 56 layers: 1.393e+01
    12. Model squeezenet with 26 layers: 2.229e+01
    13. Model try with 3 layers: 9.708e+00
    14. Model resnet18 with 20 layers: 1.906e+01
    15. Model vgg16 with 13 layers: 2.071e+01
    16. Model densenet with 160 layers: 1.805e+01
    17. Model T5_m with 6 layers: 1.228e+01
    18. Model resnext50_32x4d with 53 layers: 1.487e+01
    19. Model BERT_m with 6 layers: 1.106e+01
    20. Model ALBERT_m with 5 layers: 1.318e+01

Final result with all models and fixed hardware = 15.116472853856566

123. Using architecture PEs=256, L1=16, L2=512
    1. Model mnasnet with 52 layers: 3.185e+01
    2. Model ncf_m with 12 layers: 3.296e+01
    3. Model mobilenet_v2 with 52 layers: 3.281e+01
    4. Model googlenet with 59 layers: 3.182e+01
    5. Model dlrmRMC1_m with 6 layers: 1.308e+01
    6. Model alexnet with 5 layers: 3.027e+01
    7. Model transformer with 96 layers: 1.738e+01
    8. Model resnet50 with 53 layers: 3.160e+01
    9. Model wide_resnet50 with 53 layers: 2.847e+01
    10. Model manual with 3 layers: 1.932e+01
    11. Model shufflenet_v2 with 56 layers: 3.213e+01
    12. Model squeezenet with 26 layers: 3.183e+01
    13. Model try with 3 layers: 2.421e+01
    14. Model resnet18 with 20 layers: 3.314e+01
    15. Model vgg16 with 13 layers: 2.980e+01
    16. Model densenet with 160 layers: 2.819e+01
    17. Model T5_m with 6 layers: 8.825e+00
    18. Model resnext50_32x4d with 53 layers: 2.446e+01
    19. Model BERT_m with 6 layers: 1.850e+01
    20. Model ALBERT_m with 5 layers: 1.869e+01

Final result with all models and fixed hardware = 27.860434572395125

124. Using architecture PEs=256, L1=16, L2=1024
    1. Model mnasnet with 52 layers: 5.308e+01
    2. Model ncf_m with 12 layers: 4.924e+01
    3. Model mobilenet_v2 with 52 layers: 5.180e+01
    4. Model googlenet with 59 layers: 6.423e+01
    5. Model dlrmRMC1_m with 6 layers: 2.979e+01
    6. Model alexnet with 5 layers: 4.638e+01
    7. Model transformer with 96 layers: 3.160e+01
    8. Model resnet50 with 53 layers: 5.389e+01
    9. Model wide_resnet50 with 53 layers: 4.853e+01
    10. Model manual with 3 layers: 5.170e+01
    11. Model shufflenet_v2 with 56 layers: 6.200e+01
    12. Model squeezenet with 26 layers: 5.753e+01
    13. Model try with 3 layers: 4.233e+01
    14. Model resnet18 with 20 layers: 6.637e+01
    15. Model vgg16 with 13 layers: 5.403e+01
    16. Model densenet with 160 layers: 6.884e+01
    17. Model T5_m with 6 layers: 4.477e+01
    18. Model resnext50_32x4d with 53 layers: 4.295e+01
    19. Model BERT_m with 6 layers: 2.850e+01
    20. Model ALBERT_m with 5 layers: 4.213e+01

Final result with all models and fixed hardware = 54.02988072936401

125. Using architecture PEs=256, L1=16, L2=2048
    1. Model mnasnet with 52 layers: 8.871e+01
    2. Model ncf_m with 12 layers: 1.003e+02
    3. Model mobilenet_v2 with 52 layers: 9.349e+01
    4. Model googlenet with 59 layers: 9.522e+01
    5. Model dlrmRMC1_m with 6 layers: 8.846e+01
    6. Model alexnet with 5 layers: 7.319e+01
    7. Model transformer with 96 layers: 1.167e+02
    8. Model resnet50 with 53 layers: 1.182e+02
    9. Model wide_resnet50 with 53 layers: 1.161e+02
    10. Model manual with 3 layers: 1.102e+02
    11. Model shufflenet_v2 with 56 layers: 8.357e+01
    12. Model squeezenet with 26 layers: 1.089e+02
    13. Model try with 3 layers: 6.723e+01
    14. Model resnet18 with 20 layers: 1.099e+02
    15. Model vgg16 with 13 layers: 8.710e+01
    16. Model densenet with 160 layers: 9.654e+01
    17. Model T5_m with 6 layers: 1.252e+02
    18. Model resnext50_32x4d with 53 layers: 1.057e+02
    19. Model BERT_m with 6 layers: 1.280e+02
    20. Model ALBERT_m with 5 layers: 1.280e+02

Final result with all models and fixed hardware = 102.03103144384303

126. Using architecture PEs=256, L1=32, L2=128
    1. Model mnasnet with 52 layers: 8.197e+00
    2. Model ncf_m with 12 layers: 2.712e+00
    3. Model mobilenet_v2 with 52 layers: 8.967e+00
    4. Model googlenet with 59 layers: 8.913e+00
    5. Model dlrmRMC1_m with 6 layers: 4.423e+00
    6. Model alexnet with 5 layers: 7.961e+00
    7. Model transformer with 96 layers: 3.076e+00
    8. Model resnet50 with 53 layers: 7.814e+00
    9. Model wide_resnet50 with 53 layers: 7.702e+00
    10. Model manual with 3 layers: 3.211e+00
    11. Model shufflenet_v2 with 56 layers: 8.459e+00
    12. Model squeezenet with 26 layers: 1.056e+01
    13. Model try with 3 layers: 4.966e+00
    14. Model resnet18 with 20 layers: 9.990e+00
    15. Model vgg16 with 13 layers: 9.780e+00
    16. Model densenet with 160 layers: 8.049e+00
    17. Model T5_m with 6 layers: 2.990e+00
    18. Model resnext50_32x4d with 53 layers: 8.205e+00
    19. Model BERT_m with 6 layers: 1.410e+00
    20. Model ALBERT_m with 5 layers: 4.285e+00

Final result with all models and fixed hardware = 7.4493668958051416

127. Using architecture PEs=256, L1=32, L2=256
    1. Model mnasnet with 52 layers: 1.515e+01
    2. Model ncf_m with 12 layers: 4.975e+00
    3. Model mobilenet_v2 with 52 layers: 1.428e+01
    4. Model googlenet with 59 layers: 1.521e+01
    5. Model dlrmRMC1_m with 6 layers: 7.057e+00
    6. Model alexnet with 5 layers: 9.185e+00
    7. Model transformer with 96 layers: 8.755e+00
    8. Model resnet50 with 53 layers: 1.642e+01
    9. Model wide_resnet50 with 53 layers: 1.571e+01
    10. Model manual with 3 layers: 1.996e+01
    11. Model shufflenet_v2 with 56 layers: 1.604e+01
    12. Model squeezenet with 26 layers: 2.218e+01
    13. Model try with 3 layers: 9.708e+00
    14. Model resnet18 with 20 layers: 1.872e+01
    15. Model vgg16 with 13 layers: 1.585e+01
    16. Model densenet with 160 layers: 1.707e+01
    17. Model T5_m with 6 layers: 7.136e+00
    18. Model resnext50_32x4d with 53 layers: 1.480e+01
    19. Model BERT_m with 6 layers: 9.437e+00
    20. Model ALBERT_m with 5 layers: 1.476e+01

Final result with all models and fixed hardware = 14.821966294993235

128. Using architecture PEs=256, L1=32, L2=512
    1. Model mnasnet with 52 layers: 3.537e+01
    2. Model ncf_m with 12 layers: 2.813e+01
    3. Model mobilenet_v2 with 52 layers: 3.055e+01
    4. Model googlenet with 59 layers: 3.444e+01
    5. Model dlrmRMC1_m with 6 layers: 2.113e+01
    6. Model alexnet with 5 layers: 2.419e+01
    7. Model transformer with 96 layers: 1.976e+01
    8. Model resnet50 with 53 layers: 3.376e+01
    9. Model wide_resnet50 with 53 layers: 2.913e+01
    10. Model manual with 3 layers: 4.486e+01
    11. Model shufflenet_v2 with 56 layers: 3.426e+01
    12. Model squeezenet with 26 layers: 3.225e+01
    13. Model try with 3 layers: 1.949e+01
    14. Model resnet18 with 20 layers: 3.276e+01
    15. Model vgg16 with 13 layers: 3.463e+01
    16. Model densenet with 160 layers: 2.849e+01
    17. Model T5_m with 6 layers: 3.170e+01
    18. Model resnext50_32x4d with 53 layers: 3.158e+01
    19. Model BERT_m with 6 layers: 3.773e+01
    20. Model ALBERT_m with 5 layers: 2.388e+01

Final result with all models and fixed hardware = 29.90418217185386

129. Using architecture PEs=256, L1=32, L2=1024
    1. Model mnasnet with 52 layers: 5.269e+01
    2. Model ncf_m with 12 layers: 5.161e+01
    3. Model mobilenet_v2 with 52 layers: 4.758e+01
    4. Model googlenet with 59 layers: 6.512e+01
    5. Model dlrmRMC1_m with 6 layers: 3.259e+01
    6. Model alexnet with 5 layers: 7.546e+01
    7. Model transformer with 96 layers: 3.126e+01
    8. Model resnet50 with 53 layers: 5.683e+01
    9. Model wide_resnet50 with 53 layers: 5.380e+01
    10. Model manual with 3 layers: 4.693e+01
    11. Model shufflenet_v2 with 56 layers: 6.265e+01
    12. Model squeezenet with 26 layers: 7.128e+01
    13. Model try with 3 layers: 3.282e+01
    14. Model resnet18 with 20 layers: 6.448e+01
    15. Model vgg16 with 13 layers: 5.338e+01
    16. Model densenet with 160 layers: 7.040e+01
    17. Model T5_m with 6 layers: 6.030e+01
    18. Model resnext50_32x4d with 53 layers: 5.260e+01
    19. Model BERT_m with 6 layers: 2.509e+01
    20. Model ALBERT_m with 5 layers: 1.599e+01

Final result with all models and fixed hardware = 55.94327426116374

130. Using architecture PEs=256, L1=32, L2=2048
    1. Model mnasnet with 52 layers: 9.677e+01
    2. Model ncf_m with 12 layers: 9.852e+01
    3. Model mobilenet_v2 with 52 layers: 8.892e+01
    4. Model googlenet with 59 layers: 8.941e+01
    5. Model dlrmRMC1_m with 6 layers: 8.048e+01
    6. Model alexnet with 5 layers: 7.900e+01
    7. Model transformer with 96 layers: 1.153e+02
    8. Model resnet50 with 53 layers: 1.030e+02
    9. Model wide_resnet50 with 53 layers: 1.111e+02
    10. Model manual with 3 layers: 6.722e+01
    11. Model shufflenet_v2 with 56 layers: 8.495e+01
    12. Model squeezenet with 26 layers: 8.836e+01
    13. Model try with 3 layers: 1.035e+02
    14. Model resnet18 with 20 layers: 9.695e+01
    15. Model vgg16 with 13 layers: 1.014e+02
    16. Model densenet with 160 layers: 9.813e+01
    17. Model T5_m with 6 layers: 1.337e+02
    18. Model resnext50_32x4d with 53 layers: 1.099e+02
    19. Model BERT_m with 6 layers: 1.280e+02
    20. Model ALBERT_m with 5 layers: 1.107e+02

Final result with all models and fixed hardware = 99.97706137753718

131. Using architecture PEs=256, L1=64, L2=128
    1. Model mnasnet with 52 layers: 7.884e+00
    2. Model ncf_m with 12 layers: 3.788e+00
    3. Model mobilenet_v2 with 52 layers: 8.444e+00
    4. Model googlenet with 59 layers: 8.932e+00
    5. Model dlrmRMC1_m with 6 layers: 5.450e+00
    6. Model alexnet with 5 layers: 8.950e+00
    7. Model transformer with 96 layers: 3.997e+00
    8. Model resnet50 with 53 layers: 8.693e+00
    9. Model wide_resnet50 with 53 layers: 7.950e+00
    10. Model manual with 3 layers: 3.076e+00
    11. Model shufflenet_v2 with 56 layers: 9.121e+00
    12. Model squeezenet with 26 layers: 1.034e+01
    13. Model try with 3 layers: 5.926e+00
    14. Model resnet18 with 20 layers: 1.051e+01
    15. Model vgg16 with 13 layers: 8.668e+00
    16. Model densenet with 160 layers: 7.936e+00
    17. Model T5_m with 6 layers: 3.089e+00
    18. Model resnext50_32x4d with 53 layers: 7.558e+00
    19. Model BERT_m with 6 layers: 4.360e+00
    20. Model ALBERT_m with 5 layers: 3.397e+00

Final result with all models and fixed hardware = 7.6130927821380245

132. Using architecture PEs=256, L1=64, L2=256
    1. Model mnasnet with 52 layers: 1.490e+01
    2. Model ncf_m with 12 layers: 7.746e+00
    3. Model mobilenet_v2 with 52 layers: 1.464e+01
    4. Model googlenet with 59 layers: 1.491e+01
    5. Model dlrmRMC1_m with 6 layers: 1.360e+01
    6. Model alexnet with 5 layers: 2.297e+01
    7. Model transformer with 96 layers: 9.859e+00
    8. Model resnet50 with 53 layers: 1.546e+01
    9. Model wide_resnet50 with 53 layers: 1.685e+01
    10. Model manual with 3 layers: 2.183e+01
    11. Model shufflenet_v2 with 56 layers: 1.418e+01
    12. Model squeezenet with 26 layers: 1.873e+01
    13. Model try with 3 layers: 3.833e+00
    14. Model resnet18 with 20 layers: 2.058e+01
    15. Model vgg16 with 13 layers: 1.814e+01
    16. Model densenet with 160 layers: 1.726e+01
    17. Model T5_m with 6 layers: 8.509e+00
    18. Model resnext50_32x4d with 53 layers: 1.628e+01
    19. Model BERT_m with 6 layers: 1.081e+01
    20. Model ALBERT_m with 5 layers: 1.169e+01

Final result with all models and fixed hardware = 15.112812733423548

133. Using architecture PEs=256, L1=64, L2=512
    1. Model mnasnet with 52 layers: 3.440e+01
    2. Model ncf_m with 12 layers: 1.615e+01
    3. Model mobilenet_v2 with 52 layers: 2.958e+01
    4. Model googlenet with 59 layers: 3.540e+01
    5. Model dlrmRMC1_m with 6 layers: 2.678e+01
    6. Model alexnet with 5 layers: 1.866e+01
    7. Model transformer with 96 layers: 1.842e+01
    8. Model resnet50 with 53 layers: 2.587e+01
    9. Model wide_resnet50 with 53 layers: 2.685e+01
    10. Model manual with 3 layers: 3.867e+01
    11. Model shufflenet_v2 with 56 layers: 3.588e+01
    12. Model squeezenet with 26 layers: 3.344e+01
    13. Model try with 3 layers: 2.152e+01
    14. Model resnet18 with 20 layers: 3.446e+01
    15. Model vgg16 with 13 layers: 2.238e+01
    16. Model densenet with 160 layers: 2.631e+01
    17. Model T5_m with 6 layers: 3.471e+00
    18. Model resnext50_32x4d with 53 layers: 2.702e+01
    19. Model BERT_m with 6 layers: 1.215e+01
    20. Model ALBERT_m with 5 layers: 1.199e+01

Final result with all models and fixed hardware = 27.416938177266577

134. Using architecture PEs=256, L1=64, L2=1024
    1. Model mnasnet with 52 layers: 5.558e+01
    2. Model ncf_m with 12 layers: 5.547e+01
    3. Model mobilenet_v2 with 52 layers: 5.361e+01
    4. Model googlenet with 59 layers: 6.279e+01
    5. Model dlrmRMC1_m with 6 layers: 3.379e+01
    6. Model alexnet with 5 layers: 7.303e+01
    7. Model transformer with 96 layers: 3.409e+01
    8. Model resnet50 with 53 layers: 5.452e+01
    9. Model wide_resnet50 with 53 layers: 5.241e+01
    10. Model manual with 3 layers: 3.534e+01
    11. Model shufflenet_v2 with 56 layers: 6.333e+01
    12. Model squeezenet with 26 layers: 5.370e+01
    13. Model try with 3 layers: 3.233e+01
    14. Model resnet18 with 20 layers: 4.427e+01
    15. Model vgg16 with 13 layers: 4.596e+01
    16. Model densenet with 160 layers: 6.978e+01
    17. Model T5_m with 6 layers: 2.363e+01
    18. Model resnext50_32x4d with 53 layers: 4.749e+01
    19. Model BERT_m with 6 layers: 1.637e+01
    20. Model ALBERT_m with 5 layers: 1.149e+01

Final result with all models and fixed hardware = 54.34966520433017

135. Using architecture PEs=256, L1=64, L2=2048
    1. Model mnasnet with 52 layers: 9.127e+01
    2. Model ncf_m with 12 layers: 1.003e+02
    3. Model mobilenet_v2 with 52 layers: 9.093e+01
    4. Model googlenet with 59 layers: 8.686e+01
    5. Model dlrmRMC1_m with 6 layers: 8.640e+01
    6. Model alexnet with 5 layers: 9.979e+01
    7. Model transformer with 96 layers: 1.117e+02
    8. Model resnet50 with 53 layers: 1.110e+02
    9. Model wide_resnet50 with 53 layers: 1.112e+02
    10. Model manual with 3 layers: 8.344e+01
    11. Model shufflenet_v2 with 56 layers: 8.737e+01
    12. Model squeezenet with 26 layers: 9.030e+01
    13. Model try with 3 layers: 5.732e+01
    14. Model resnet18 with 20 layers: 1.011e+02
    15. Model vgg16 with 13 layers: 1.118e+02
    16. Model densenet with 160 layers: 9.063e+01
    17. Model T5_m with 6 layers: 1.328e+02
    18. Model resnext50_32x4d with 53 layers: 1.068e+02
    19. Model BERT_m with 6 layers: 1.267e+02
    20. Model ALBERT_m with 5 layers: 1.072e+02

Final result with all models and fixed hardware = 98.38153140730714

136. Using architecture PEs=256, L1=128, L2=128
    1. Model mnasnet with 52 layers: 7.492e+00
    2. Model ncf_m with 12 layers: 4.158e+00
    3. Model mobilenet_v2 with 52 layers: 8.679e+00
    4. Model googlenet with 59 layers: 8.628e+00
    5. Model dlrmRMC1_m with 6 layers: 4.552e+00
    6. Model alexnet with 5 layers: 9.410e+00
    7. Model transformer with 96 layers: 3.465e+00
    8. Model resnet50 with 53 layers: 9.165e+00
    9. Model wide_resnet50 with 53 layers: 7.980e+00
    10. Model manual with 3 layers: 1.244e+01
    11. Model shufflenet_v2 with 56 layers: 8.369e+00
    12. Model squeezenet with 26 layers: 1.129e+01
    13. Model try with 3 layers: 4.775e+00
    14. Model resnet18 with 20 layers: 8.326e+00
    15. Model vgg16 with 13 layers: 7.836e+00
    16. Model densenet with 160 layers: 8.489e+00
    17. Model T5_m with 6 layers: 4.029e+00
    18. Model resnext50_32x4d with 53 layers: 7.945e+00
    19. Model BERT_m with 6 layers: 2.821e+00
    20. Model ALBERT_m with 5 layers: 5.177e+00

Final result with all models and fixed hardware = 7.637688620433018

137. Using architecture PEs=256, L1=128, L2=256
    1. Model mnasnet with 52 layers: 1.427e+01
    2. Model ncf_m with 12 layers: 4.206e+00
    3. Model mobilenet_v2 with 52 layers: 1.652e+01
    4. Model googlenet with 59 layers: 1.448e+01
    5. Model dlrmRMC1_m with 6 layers: 1.480e+01
    6. Model alexnet with 5 layers: 5.763e+00
    7. Model transformer with 96 layers: 9.488e+00
    8. Model resnet50 with 53 layers: 1.855e+01
    9. Model wide_resnet50 with 53 layers: 1.627e+01
    10. Model manual with 3 layers: 2.166e+01
    11. Model shufflenet_v2 with 56 layers: 1.446e+01
    12. Model squeezenet with 26 layers: 2.144e+01
    13. Model try with 3 layers: 1.701e+01
    14. Model resnet18 with 20 layers: 1.636e+01
    15. Model vgg16 with 13 layers: 1.744e+01
    16. Model densenet with 160 layers: 1.667e+01
    17. Model T5_m with 6 layers: 1.432e+01
    18. Model resnext50_32x4d with 53 layers: 1.490e+01
    19. Model BERT_m with 6 layers: 9.087e+00
    20. Model ALBERT_m with 5 layers: 1.380e+01

Final result with all models and fixed hardware = 14.998425649526386

138. Using architecture PEs=256, L1=128, L2=512
    1. Model mnasnet with 52 layers: 3.231e+01
    2. Model ncf_m with 12 layers: 2.729e+01
    3. Model mobilenet_v2 with 52 layers: 3.013e+01
    4. Model googlenet with 59 layers: 3.307e+01
    5. Model dlrmRMC1_m with 6 layers: 2.752e+01
    6. Model alexnet with 5 layers: 2.688e+01
    7. Model transformer with 96 layers: 1.894e+01
    8. Model resnet50 with 53 layers: 2.751e+01
    9. Model wide_resnet50 with 53 layers: 3.206e+01
    10. Model manual with 3 layers: 4.147e+01
    11. Model shufflenet_v2 with 56 layers: 3.307e+01
    12. Model squeezenet with 26 layers: 3.466e+01
    13. Model try with 3 layers: 2.368e+01
    14. Model resnet18 with 20 layers: 2.891e+01
    15. Model vgg16 with 13 layers: 2.739e+01
    16. Model densenet with 160 layers: 3.052e+01
    17. Model T5_m with 6 layers: 1.738e+01
    18. Model resnext50_32x4d with 53 layers: 2.388e+01
    19. Model BERT_m with 6 layers: 2.525e+01
    20. Model ALBERT_m with 5 layers: 1.739e+01

Final result with all models and fixed hardware = 28.65316378619757

139. Using architecture PEs=256, L1=128, L2=1024
    1. Model mnasnet with 52 layers: 5.925e+01
    2. Model ncf_m with 12 layers: 4.041e+01
    3. Model mobilenet_v2 with 52 layers: 5.871e+01
    4. Model googlenet with 59 layers: 5.443e+01
    5. Model dlrmRMC1_m with 6 layers: 3.087e+01
    6. Model alexnet with 5 layers: 5.729e+01
    7. Model transformer with 96 layers: 3.039e+01
    8. Model resnet50 with 53 layers: 4.963e+01
    9. Model wide_resnet50 with 53 layers: 5.032e+01
    10. Model manual with 3 layers: 2.933e+01
    11. Model shufflenet_v2 with 56 layers: 6.663e+01
    12. Model squeezenet with 26 layers: 7.311e+01
    13. Model try with 3 layers: 1.110e+01
    14. Model resnet18 with 20 layers: 5.064e+01
    15. Model vgg16 with 13 layers: 5.168e+01
    16. Model densenet with 160 layers: 7.360e+01
    17. Model T5_m with 6 layers: 1.706e+01
    18. Model resnext50_32x4d with 53 layers: 4.863e+01
    19. Model BERT_m with 6 layers: 1.776e+01
    20. Model ALBERT_m with 5 layers: 1.062e+01

Final result with all models and fixed hardware = 54.897416400541275

140. Using architecture PEs=256, L1=128, L2=2048
    1. Model mnasnet with 52 layers: 8.970e+01
    2. Model ncf_m with 12 layers: 9.166e+01
    3. Model mobilenet_v2 with 52 layers: 9.065e+01
    4. Model googlenet with 59 layers: 9.559e+01
    5. Model dlrmRMC1_m with 6 layers: 7.616e+01
    6. Model alexnet with 5 layers: 1.124e+02
    7. Model transformer with 96 layers: 1.245e+02
    8. Model resnet50 with 53 layers: 1.104e+02
    9. Model wide_resnet50 with 53 layers: 1.024e+02
    10. Model manual with 3 layers: 9.546e+01
    11. Model shufflenet_v2 with 56 layers: 8.022e+01
    12. Model squeezenet with 26 layers: 9.513e+01
    13. Model try with 3 layers: 9.189e+01
    14. Model resnet18 with 20 layers: 1.102e+02
    15. Model vgg16 with 13 layers: 1.114e+02
    16. Model densenet with 160 layers: 9.257e+01
    17. Model T5_m with 6 layers: 1.214e+02
    18. Model resnext50_32x4d with 53 layers: 1.021e+02
    19. Model BERT_m with 6 layers: 1.067e+02
    20. Model ALBERT_m with 5 layers: 1.373e+02

Final result with all models and fixed hardware = 99.89313702300406

141. Using architecture PEs=512, L1=16, L2=128
    1. Model mnasnet with 52 layers: 8.373e+00
    2. Model ncf_m with 12 layers: 3.931e+00
    3. Model mobilenet_v2 with 52 layers: 8.658e+00
    4. Model googlenet with 59 layers: 9.088e+00
    5. Model dlrmRMC1_m with 6 layers: 7.421e+00
    6. Model alexnet with 5 layers: 7.696e+00
    7. Model transformer with 96 layers: 3.771e+00
    8. Model resnet50 with 53 layers: 8.734e+00
    9. Model wide_resnet50 with 53 layers: 9.294e+00
    10. Model manual with 3 layers: 5.255e+00
    11. Model shufflenet_v2 with 56 layers: 9.065e+00
    12. Model squeezenet with 26 layers: 1.108e+01
    13. Model try with 3 layers: 9.082e+00
    14. Model resnet18 with 20 layers: 9.406e+00
    15. Model vgg16 with 13 layers: 7.355e+00
    16. Model densenet with 160 layers: 8.275e+00
    17. Model T5_m with 6 layers: 3.265e+00
    18. Model resnext50_32x4d with 53 layers: 7.867e+00
    19. Model BERT_m with 6 layers: 3.540e+00
    20. Model ALBERT_m with 5 layers: 3.981e+00

Final result with all models and fixed hardware = 7.839803324763193

142. Using architecture PEs=512, L1=16, L2=256
    1. Model mnasnet with 52 layers: 1.405e+01
    2. Model ncf_m with 12 layers: 1.370e+01
    3. Model mobilenet_v2 with 52 layers: 1.453e+01
    4. Model googlenet with 59 layers: 1.682e+01
    5. Model dlrmRMC1_m with 6 layers: 1.177e+01
    6. Model alexnet with 5 layers: 1.649e+01
    7. Model transformer with 96 layers: 8.254e+00
    8. Model resnet50 with 53 layers: 1.531e+01
    9. Model wide_resnet50 with 53 layers: 1.543e+01
    10. Model manual with 3 layers: 1.960e+01
    11. Model shufflenet_v2 with 56 layers: 1.504e+01
    12. Model squeezenet with 26 layers: 2.323e+01
    13. Model try with 3 layers: 1.093e+01
    14. Model resnet18 with 20 layers: 1.686e+01
    15. Model vgg16 with 13 layers: 1.832e+01
    16. Model densenet with 160 layers: 1.696e+01
    17. Model T5_m with 6 layers: 1.574e+01
    18. Model resnext50_32x4d with 53 layers: 1.415e+01
    19. Model BERT_m with 6 layers: 9.082e+00
    20. Model ALBERT_m with 5 layers: 1.813e+01

Final result with all models and fixed hardware = 14.930658740189447

143. Using architecture PEs=512, L1=16, L2=512
    1. Model mnasnet with 52 layers: 3.077e+01
    2. Model ncf_m with 12 layers: 2.475e+01
    3. Model mobilenet_v2 with 52 layers: 2.773e+01
    4. Model googlenet with 59 layers: 3.251e+01
    5. Model dlrmRMC1_m with 6 layers: 2.516e+01
    6. Model alexnet with 5 layers: 2.589e+01
    7. Model transformer with 96 layers: 1.782e+01
    8. Model resnet50 with 53 layers: 2.737e+01
    9. Model wide_resnet50 with 53 layers: 2.543e+01
    10. Model manual with 3 layers: 4.559e+01
    11. Model shufflenet_v2 with 56 layers: 2.916e+01
    12. Model squeezenet with 26 layers: 3.837e+01
    13. Model try with 3 layers: 1.013e+01
    14. Model resnet18 with 20 layers: 2.691e+01
    15. Model vgg16 with 13 layers: 3.248e+01
    16. Model densenet with 160 layers: 3.060e+01
    17. Model T5_m with 6 layers: 2.320e+01
    18. Model resnext50_32x4d with 53 layers: 3.161e+01
    19. Model BERT_m with 6 layers: 9.846e+00
    20. Model ALBERT_m with 5 layers: 1.502e+01

Final result with all models and fixed hardware = 27.942109327469552

144. Using architecture PEs=512, L1=16, L2=1024
    1. Model mnasnet with 52 layers: 5.707e+01
    2. Model ncf_m with 12 layers: 7.119e+01
    3. Model mobilenet_v2 with 52 layers: 5.208e+01
    4. Model googlenet with 59 layers: 7.020e+01
    5. Model dlrmRMC1_m with 6 layers: 6.793e+01
    6. Model alexnet with 5 layers: 8.853e+01
    7. Model transformer with 96 layers: 3.925e+01
    8. Model resnet50 with 53 layers: 6.988e+01
    9. Model wide_resnet50 with 53 layers: 4.714e+01
    10. Model manual with 3 layers: 1.187e+02
    11. Model shufflenet_v2 with 56 layers: 6.541e+01
    12. Model squeezenet with 26 layers: 5.737e+01
    13. Model try with 3 layers: 2.479e+01
    14. Model resnet18 with 20 layers: 5.648e+01
    15. Model vgg16 with 13 layers: 7.552e+01
    16. Model densenet with 160 layers: 7.394e+01
    17. Model T5_m with 6 layers: 4.946e+01
    18. Model resnext50_32x4d with 53 layers: 6.191e+01
    19. Model BERT_m with 6 layers: 2.989e+01
    20. Model ALBERT_m with 5 layers: 2.210e+01

Final result with all models and fixed hardware = 60.739493240866054

145. Using architecture PEs=512, L1=16, L2=2048
    1. Model mnasnet with 52 layers: 8.886e+01
    2. Model ncf_m with 12 layers: 8.976e+01
    3. Model mobilenet_v2 with 52 layers: 1.071e+02
    4. Model googlenet with 59 layers: 9.899e+01
    5. Model dlrmRMC1_m with 6 layers: 8.301e+01
    6. Model alexnet with 5 layers: 1.777e+02
    7. Model transformer with 96 layers: 8.768e+01
    8. Model resnet50 with 53 layers: 1.093e+02
    9. Model wide_resnet50 with 53 layers: 9.705e+01
    10. Model manual with 3 layers: 8.719e+01
    11. Model shufflenet_v2 with 56 layers: 9.557e+01
    12. Model squeezenet with 26 layers: 1.298e+02
    13. Model try with 3 layers: 2.392e+01
    14. Model resnet18 with 20 layers: 8.664e+01
    15. Model vgg16 with 13 layers: 1.314e+02
    16. Model densenet with 160 layers: 1.027e+02
    17. Model T5_m with 6 layers: 6.844e+01
    18. Model resnext50_32x4d with 53 layers: 1.082e+02
    19. Model BERT_m with 6 layers: 6.527e+01
    20. Model ALBERT_m with 5 layers: 6.755e+01

Final result with all models and fixed hardware = 99.67013808389713

146. Using architecture PEs=512, L1=32, L2=128
    1. Model mnasnet with 52 layers: 8.926e+00
    2. Model ncf_m with 12 layers: 5.195e+00
    3. Model mobilenet_v2 with 52 layers: 8.863e+00
    4. Model googlenet with 59 layers: 9.070e+00
    5. Model dlrmRMC1_m with 6 layers: 4.541e+00
    6. Model alexnet with 5 layers: 6.235e+00
    7. Model transformer with 96 layers: 3.931e+00
    8. Model resnet50 with 53 layers: 8.847e+00
    9. Model wide_resnet50 with 53 layers: 8.084e+00
    10. Model manual with 3 layers: 2.471e+00
    11. Model shufflenet_v2 with 56 layers: 9.536e+00
    12. Model squeezenet with 26 layers: 1.084e+01
    13. Model try with 3 layers: 4.976e+00
    14. Model resnet18 with 20 layers: 9.568e+00
    15. Model vgg16 with 13 layers: 1.022e+01
    16. Model densenet with 160 layers: 8.745e+00
    17. Model T5_m with 6 layers: 4.601e+00
    18. Model resnext50_32x4d with 53 layers: 8.608e+00
    19. Model BERT_m with 6 layers: 2.751e+00
    20. Model ALBERT_m with 5 layers: 7.407e+00

Final result with all models and fixed hardware = 8.057307205683358

147. Using architecture PEs=512, L1=32, L2=256
    1. Model mnasnet with 52 layers: 1.347e+01
    2. Model ncf_m with 12 layers: 1.151e+01
    3. Model mobilenet_v2 with 52 layers: 1.590e+01
    4. Model googlenet with 59 layers: 1.832e+01
    5. Model dlrmRMC1_m with 6 layers: 6.702e+00
    6. Model alexnet with 5 layers: 1.580e+01
    7. Model transformer with 96 layers: 7.590e+00
    8. Model resnet50 with 53 layers: 1.641e+01
    9. Model wide_resnet50 with 53 layers: 1.440e+01
    10. Model manual with 3 layers: 1.500e+01
    11. Model shufflenet_v2 with 56 layers: 1.512e+01
    12. Model squeezenet with 26 layers: 2.038e+01
    13. Model try with 3 layers: 5.599e+00
    14. Model resnet18 with 20 layers: 1.768e+01
    15. Model vgg16 with 13 layers: 1.481e+01
    16. Model densenet with 160 layers: 1.742e+01
    17. Model T5_m with 6 layers: 7.899e+00
    18. Model resnext50_32x4d with 53 layers: 1.527e+01
    19. Model BERT_m with 6 layers: 7.456e+00
    20. Model ALBERT_m with 5 layers: 1.005e+01

Final result with all models and fixed hardware = 14.817670893098782

148. Using architecture PEs=512, L1=32, L2=512
    1. Model mnasnet with 52 layers: 2.925e+01
    2. Model ncf_m with 12 layers: 2.053e+01
    3. Model mobilenet_v2 with 52 layers: 2.616e+01
    4. Model googlenet with 59 layers: 3.569e+01
    5. Model dlrmRMC1_m with 6 layers: 3.548e+01
    6. Model alexnet with 5 layers: 1.530e+01
    7. Model transformer with 96 layers: 1.648e+01
    8. Model resnet50 with 53 layers: 2.739e+01
    9. Model wide_resnet50 with 53 layers: 2.465e+01
    10. Model manual with 3 layers: 2.933e+01
    11. Model shufflenet_v2 with 56 layers: 3.504e+01
    12. Model squeezenet with 26 layers: 3.276e+01
    13. Model try with 3 layers: 3.137e+01
    14. Model resnet18 with 20 layers: 3.342e+01
    15. Model vgg16 with 13 layers: 3.939e+01
    16. Model densenet with 160 layers: 2.897e+01
    17. Model T5_m with 6 layers: 2.037e+01
    18. Model resnext50_32x4d with 53 layers: 2.785e+01
    19. Model BERT_m with 6 layers: 1.082e+01
    20. Model ALBERT_m with 5 layers: 1.729e+01

Final result with all models and fixed hardware = 27.639028209742893

149. Using architecture PEs=512, L1=32, L2=1024
    1. Model mnasnet with 52 layers: 4.904e+01
    2. Model ncf_m with 12 layers: 6.864e+01
    3. Model mobilenet_v2 with 52 layers: 5.037e+01
    4. Model googlenet with 59 layers: 6.092e+01
    5. Model dlrmRMC1_m with 6 layers: 5.244e+01
    6. Model alexnet with 5 layers: 6.787e+01
    7. Model transformer with 96 layers: 4.377e+01
    8. Model resnet50 with 53 layers: 6.767e+01
    9. Model wide_resnet50 with 53 layers: 4.655e+01
    10. Model manual with 3 layers: 4.840e+01
    11. Model shufflenet_v2 with 56 layers: 5.947e+01
    12. Model squeezenet with 26 layers: 6.044e+01
    13. Model try with 3 layers: 5.162e+01
    14. Model resnet18 with 20 layers: 7.094e+01
    15. Model vgg16 with 13 layers: 6.662e+01
    16. Model densenet with 160 layers: 7.298e+01
    17. Model T5_m with 6 layers: 6.840e+01
    18. Model resnext50_32x4d with 53 layers: 6.097e+01
    19. Model BERT_m with 6 layers: 3.281e+01
    20. Model ALBERT_m with 5 layers: 2.431e+01

Final result with all models and fixed hardware = 59.02525852368065

150. Using architecture PEs=512, L1=32, L2=2048
    1. Model mnasnet with 52 layers: 1.184e+02
    2. Model ncf_m with 12 layers: 8.176e+01
    3. Model mobilenet_v2 with 52 layers: 1.015e+02
    4. Model googlenet with 59 layers: 1.112e+02
    5. Model dlrmRMC1_m with 6 layers: 7.971e+01
    6. Model alexnet with 5 layers: 1.547e+02
    7. Model transformer with 96 layers: 7.526e+01
    8. Model resnet50 with 53 layers: 9.534e+01
    9. Model wide_resnet50 with 53 layers: 1.015e+02
    10. Model manual with 3 layers: 9.052e+01
    11. Model shufflenet_v2 with 56 layers: 1.062e+02
    12. Model squeezenet with 26 layers: 9.838e+01
    13. Model try with 3 layers: 1.030e+02
    14. Model resnet18 with 20 layers: 1.197e+02
    15. Model vgg16 with 13 layers: 8.836e+01
    16. Model densenet with 160 layers: 9.889e+01
    17. Model T5_m with 6 layers: 1.908e+01
    18. Model resnext50_32x4d with 53 layers: 8.696e+01
    19. Model BERT_m with 6 layers: 7.230e+01
    20. Model ALBERT_m with 5 layers: 5.520e+01

Final result with all models and fixed hardware = 97.12143177266576

151. Using architecture PEs=512, L1=64, L2=128
    1. Model mnasnet with 52 layers: 8.716e+00
    2. Model ncf_m with 12 layers: 3.695e+00
    3. Model mobilenet_v2 with 52 layers: 8.859e+00
    4. Model googlenet with 59 layers: 9.381e+00
    5. Model dlrmRMC1_m with 6 layers: 3.840e+00
    6. Model alexnet with 5 layers: 7.844e+00
    7. Model transformer with 96 layers: 4.120e+00
    8. Model resnet50 with 53 layers: 9.290e+00
    9. Model wide_resnet50 with 53 layers: 8.466e+00
    10. Model manual with 3 layers: 1.192e+01
    11. Model shufflenet_v2 with 56 layers: 8.894e+00
    12. Model squeezenet with 26 layers: 1.089e+01
    13. Model try with 3 layers: 5.828e+00
    14. Model resnet18 with 20 layers: 9.042e+00
    15. Model vgg16 with 13 layers: 1.144e+01
    16. Model densenet with 160 layers: 9.084e+00
    17. Model T5_m with 6 layers: 3.255e+00
    18. Model resnext50_32x4d with 53 layers: 8.028e+00
    19. Model BERT_m with 6 layers: 4.020e+00
    20. Model ALBERT_m with 5 layers: 7.460e+00

Final result with all models and fixed hardware = 8.165905077131256

152. Using architecture PEs=512, L1=64, L2=256
    1. Model mnasnet with 52 layers: 1.554e+01
    2. Model ncf_m with 12 layers: 7.897e+00
    3. Model mobilenet_v2 with 52 layers: 1.445e+01
    4. Model googlenet with 59 layers: 1.406e+01
    5. Model dlrmRMC1_m with 6 layers: 1.070e+01
    6. Model alexnet with 5 layers: 1.507e+01
    7. Model transformer with 96 layers: 1.095e+01
    8. Model resnet50 with 53 layers: 1.578e+01
    9. Model wide_resnet50 with 53 layers: 1.426e+01
    10. Model manual with 3 layers: 1.899e+01
    11. Model shufflenet_v2 with 56 layers: 1.447e+01
    12. Model squeezenet with 26 layers: 2.002e+01
    13. Model try with 3 layers: 9.151e+00
    14. Model resnet18 with 20 layers: 1.735e+01
    15. Model vgg16 with 13 layers: 1.909e+01
    16. Model densenet with 160 layers: 1.741e+01
    17. Model T5_m with 6 layers: 1.116e+01
    18. Model resnext50_32x4d with 53 layers: 1.590e+01
    19. Model BERT_m with 6 layers: 1.309e+01
    20. Model ALBERT_m with 5 layers: 2.274e+01

Final result with all models and fixed hardware = 15.106871419485792

153. Using architecture PEs=512, L1=64, L2=512
    1. Model mnasnet with 52 layers: 2.963e+01
    2. Model ncf_m with 12 layers: 2.839e+01
    3. Model mobilenet_v2 with 52 layers: 2.648e+01
    4. Model googlenet with 59 layers: 3.400e+01
    5. Model dlrmRMC1_m with 6 layers: 1.619e+01
    6. Model alexnet with 5 layers: 2.479e+01
    7. Model transformer with 96 layers: 1.559e+01
    8. Model resnet50 with 53 layers: 2.928e+01
    9. Model wide_resnet50 with 53 layers: 2.819e+01
    10. Model manual with 3 layers: 2.349e+01
    11. Model shufflenet_v2 with 56 layers: 3.031e+01
    12. Model squeezenet with 26 layers: 3.599e+01
    13. Model try with 3 layers: 2.392e+01
    14. Model resnet18 with 20 layers: 3.046e+01
    15. Model vgg16 with 13 layers: 3.513e+01
    16. Model densenet with 160 layers: 2.898e+01
    17. Model T5_m with 6 layers: 9.650e+00
    18. Model resnext50_32x4d with 53 layers: 3.164e+01
    19. Model BERT_m with 6 layers: 1.633e+01
    20. Model ALBERT_m with 5 layers: 1.992e+01

Final result with all models and fixed hardware = 27.65712908254397

154. Using architecture PEs=512, L1=64, L2=1024
    1. Model mnasnet with 52 layers: 5.531e+01
    2. Model ncf_m with 12 layers: 7.439e+01
    3. Model mobilenet_v2 with 52 layers: 6.062e+01
    4. Model googlenet with 59 layers: 6.143e+01
    5. Model dlrmRMC1_m with 6 layers: 6.268e+01
    6. Model alexnet with 5 layers: 9.824e+01
    7. Model transformer with 96 layers: 3.163e+01
    8. Model resnet50 with 53 layers: 7.088e+01
    9. Model wide_resnet50 with 53 layers: 6.054e+01
    10. Model manual with 3 layers: 2.775e+01
    11. Model shufflenet_v2 with 56 layers: 5.925e+01
    12. Model squeezenet with 26 layers: 6.615e+01
    13. Model try with 3 layers: 3.800e+01
    14. Model resnet18 with 20 layers: 5.216e+01
    15. Model vgg16 with 13 layers: 7.823e+01
    16. Model densenet with 160 layers: 7.737e+01
    17. Model T5_m with 6 layers: 6.809e+01
    18. Model resnext50_32x4d with 53 layers: 7.168e+01
    19. Model BERT_m with 6 layers: 2.027e+01
    20. Model ALBERT_m with 5 layers: 5.497e+01

Final result with all models and fixed hardware = 61.831471151556165

155. Using architecture PEs=512, L1=64, L2=2048
    1. Model mnasnet with 52 layers: 1.074e+02
    2. Model ncf_m with 12 layers: 1.091e+02
    3. Model mobilenet_v2 with 52 layers: 9.422e+01
    4. Model googlenet with 59 layers: 1.141e+02
    5. Model dlrmRMC1_m with 6 layers: 9.340e+01
    6. Model alexnet with 5 layers: 1.355e+02
    7. Model transformer with 96 layers: 6.783e+01
    8. Model resnet50 with 53 layers: 1.299e+02
    9. Model wide_resnet50 with 53 layers: 9.977e+01
    10. Model manual with 3 layers: 5.374e+01
    11. Model shufflenet_v2 with 56 layers: 9.555e+01
    12. Model squeezenet with 26 layers: 1.068e+02
    13. Model try with 3 layers: 7.811e+01
    14. Model resnet18 with 20 layers: 1.155e+02
    15. Model vgg16 with 13 layers: 9.731e+01
    16. Model densenet with 160 layers: 1.037e+02
    17. Model T5_m with 6 layers: 1.010e+02
    18. Model resnext50_32x4d with 53 layers: 9.398e+01
    19. Model BERT_m with 6 layers: 5.302e+01
    20. Model ALBERT_m with 5 layers: 5.185e+01

Final result with all models and fixed hardware = 99.20324617050069

156. Using architecture PEs=512, L1=128, L2=128
    1. Model mnasnet with 52 layers: 8.415e+00
    2. Model ncf_m with 12 layers: 3.982e+00
    3. Model mobilenet_v2 with 52 layers: 9.260e+00
    4. Model googlenet with 59 layers: 9.187e+00
    5. Model dlrmRMC1_m with 6 layers: 4.778e+00
    6. Model alexnet with 5 layers: 6.800e+00
    7. Model transformer with 96 layers: 4.890e+00
    8. Model resnet50 with 53 layers: 8.399e+00
    9. Model wide_resnet50 with 53 layers: 8.121e+00
    10. Model manual with 3 layers: 6.626e+00
    11. Model shufflenet_v2 with 56 layers: 8.294e+00
    12. Model squeezenet with 26 layers: 1.147e+01
    13. Model try with 3 layers: 7.884e+00
    14. Model resnet18 with 20 layers: 1.004e+01
    15. Model vgg16 with 13 layers: 9.063e+00
    16. Model densenet with 160 layers: 8.768e+00
    17. Model T5_m with 6 layers: 3.725e+00
    18. Model resnext50_32x4d with 53 layers: 8.976e+00
    19. Model BERT_m with 6 layers: 4.861e+00
    20. Model ALBERT_m with 5 layers: 6.793e+00

Final result with all models and fixed hardware = 8.126643879566984

157. Using architecture PEs=512, L1=128, L2=256
    1. Model mnasnet with 52 layers: 1.511e+01
    2. Model ncf_m with 12 layers: 7.847e+00
    3. Model mobilenet_v2 with 52 layers: 1.450e+01
    4. Model googlenet with 59 layers: 1.681e+01
    5. Model dlrmRMC1_m with 6 layers: 1.199e+01
    6. Model alexnet with 5 layers: 1.015e+01
    7. Model transformer with 96 layers: 8.687e+00
    8. Model resnet50 with 53 layers: 1.599e+01
    9. Model wide_resnet50 with 53 layers: 1.503e+01
    10. Model manual with 3 layers: 2.065e+01
    11. Model shufflenet_v2 with 56 layers: 1.587e+01
    12. Model squeezenet with 26 layers: 1.991e+01
    13. Model try with 3 layers: 7.881e+00
    14. Model resnet18 with 20 layers: 2.039e+01
    15. Model vgg16 with 13 layers: 1.641e+01
    16. Model densenet with 160 layers: 1.740e+01
    17. Model T5_m with 6 layers: 4.678e+00
    18. Model resnext50_32x4d with 53 layers: 1.504e+01
    19. Model BERT_m with 6 layers: 6.077e+00
    20. Model ALBERT_m with 5 layers: 1.166e+01

Final result with all models and fixed hardware = 14.94365500135318

158. Using architecture PEs=512, L1=128, L2=512
    1. Model mnasnet with 52 layers: 3.111e+01
    2. Model ncf_m with 12 layers: 2.106e+01
    3. Model mobilenet_v2 with 52 layers: 2.408e+01
    4. Model googlenet with 59 layers: 3.185e+01
    5. Model dlrmRMC1_m with 6 layers: 2.552e+01
    6. Model alexnet with 5 layers: 1.598e+01
    7. Model transformer with 96 layers: 1.924e+01
    8. Model resnet50 with 53 layers: 2.913e+01
    9. Model wide_resnet50 with 53 layers: 2.627e+01
    10. Model manual with 3 layers: 3.289e+01
    11. Model shufflenet_v2 with 56 layers: 3.417e+01
    12. Model squeezenet with 26 layers: 4.289e+01
    13. Model try with 3 layers: 3.681e+01
    14. Model resnet18 with 20 layers: 2.615e+01
    15. Model vgg16 with 13 layers: 3.285e+01
    16. Model densenet with 160 layers: 2.558e+01
    17. Model T5_m with 6 layers: 2.170e+01
    18. Model resnext50_32x4d with 53 layers: 3.044e+01
    19. Model BERT_m with 6 layers: 1.584e+01
    20. Model ALBERT_m with 5 layers: 1.766e+01

Final result with all models and fixed hardware = 27.367221999999998

159. Using architecture PEs=512, L1=128, L2=1024
    1. Model mnasnet with 52 layers: 4.856e+01
    2. Model ncf_m with 12 layers: 7.589e+01
    3. Model mobilenet_v2 with 52 layers: 6.311e+01
    4. Model googlenet with 59 layers: 6.273e+01
    5. Model dlrmRMC1_m with 6 layers: 5.688e+01
    6. Model alexnet with 5 layers: 7.835e+01
    7. Model transformer with 96 layers: 3.287e+01
    8. Model resnet50 with 53 layers: 6.159e+01
    9. Model wide_resnet50 with 53 layers: 5.731e+01
    10. Model manual with 3 layers: 3.244e+01
    11. Model shufflenet_v2 with 56 layers: 6.442e+01
    12. Model squeezenet with 26 layers: 6.114e+01
    13. Model try with 3 layers: 3.866e+01
    14. Model resnet18 with 20 layers: 5.260e+01
    15. Model vgg16 with 13 layers: 7.054e+01
    16. Model densenet with 160 layers: 7.133e+01
    17. Model T5_m with 6 layers: 2.781e+01
    18. Model resnext50_32x4d with 53 layers: 6.221e+01
    19. Model BERT_m with 6 layers: 2.036e+01
    20. Model ALBERT_m with 5 layers: 1.902e+01

Final result with all models and fixed hardware = 58.29894944248985

160. Using architecture PEs=512, L1=128, L2=2048
    1. Model mnasnet with 52 layers: 1.159e+02
    2. Model ncf_m with 12 layers: 8.109e+01
    3. Model mobilenet_v2 with 52 layers: 9.161e+01
    4. Model googlenet with 59 layers: 1.195e+02
    5. Model dlrmRMC1_m with 6 layers: 8.442e+01
    6. Model alexnet with 5 layers: 9.322e+01
    7. Model transformer with 96 layers: 8.666e+01
    8. Model resnet50 with 53 layers: 9.613e+01
    9. Model wide_resnet50 with 53 layers: 9.965e+01
    10. Model manual with 3 layers: 1.427e+02
    11. Model shufflenet_v2 with 56 layers: 9.665e+01
    12. Model squeezenet with 26 layers: 1.071e+02
    13. Model try with 3 layers: 3.337e+01
    14. Model resnet18 with 20 layers: 1.154e+02
    15. Model vgg16 with 13 layers: 6.867e+01
    16. Model densenet with 160 layers: 1.104e+02
    17. Model T5_m with 6 layers: 7.593e+01
    18. Model resnext50_32x4d with 53 layers: 8.993e+01
    19. Model BERT_m with 6 layers: 9.993e+01
    20. Model ALBERT_m with 5 layers: 1.050e+02

Final result with all models and fixed hardware = 100.70624503382952
